# 比较

|                         | ActiveMQ         | RabbitMQ         | RocketMQ                              | Kafka                                                |
| ----------------------- | ---------------- | ---------------- | ------------------------------------- | ---------------------------------------------------- |
| 功能                    | MQ功能极其完备   | MQ功能完备       | MQ功能较为完善                        | MQ功能较为简单，主要使用在大数据的实时计算和日志采集 |
| 单机吞吐量              | 万级             | 万级             | 十万级                                | 十万级                                               |
| 时效性                  | ms级             | μs级（延迟最低） | ms级                                  | ms级以内                                             |
| 可用性                  | 高，基于主从架构 | 高，基于主从架构 | 非常高，分布式架构                    | 非常高，分布式架构，一个数据多个副本                 |
| 消息可靠性              |                  |                  |                                       | 会丢数据                                             |
| topic数量对吞吐量的影响 |                  |                  | topic达到百级时，吞吐量会有小幅度下降 | topic达到千级时，吞吐量会大幅下降                    |



# Q：消息队列如何保证消息顺序性？

## rabbitMQ

**局部顺序性**

- 消费者层面：多个消费者，每个消费者读取一个queue，queue内肯定是有序的，则每个消费者拿到的消息也有序
- topic层面：业务可以hash切分为多topic，每个topic只有一个生产者和一个消费者，则topic内有序

所以一般要求的顺序性都指全局顺序性

**全局顺序性**

对某个topic只能是一个生产者，一个消费者。要求全局顺序性必然无法并发，损失性能。

## kafka

每个消费者**只能消费一个**partition，若消费者比partition多，则有消费者拿不到数据，没有意义

写入同一个partition的数据一定是有顺序的，因此生产者写入时，可以指定一个key，则相同key一定会分发到同一个partition

![image-20220318015558871](images\消息队列\image-20220318015558871.png)





# Q：如何保证消息不丢失（数据一致性）？

## Kafka

**情形1：消费者丢数据**

kafka消费者会自动提交offset（记为i），broker就认为i号消息已被消费，若此时消费者出问题，则下次请求broker给的就是i+1号消息了，i号消息丢失。

解决：改为手动提交

```
request.required.asks=0
# 0:相当于异步的, 不需要leader给予回复, producer立即返回, 发送就是成功,
那么发送消息网络超时或broker crash(1.Partition的Leader还没有commit消息 2.Leader与
Follower数据不同步), 既有可能丢失也可能会重发
# 1：当leader接收到消息之后发送ack, 丢会重发, 丢的概率很小
# -1：当所有的follower都同步消息成功后发送ack. 不会丢失消息
```

**情形2：broker丢数据**

某个broker宕机，重新选举leader，此时follower数据未同步完，leader也挂了，则leader上的数据丢失。

解决：给这个topic设置`replication.factor`大于1，即每个partition至少有2个副本

broker设置`min.insync.replicas`大于1，要求leader至少有一个follower与自己保持同步中

生产者设置`acks = all`，要求每条数据必须写入所有replica后，才认为写成功

生产者设置`retries = MAX（最大整数）`，要求写入失败时，无限重试

**Q：生产者是否会丢数据？**

按照情形2的解决办法，能保证生产者一定将数据发送到broker，且存有2个以上副本，若不满足，生产者会不断重试

## RocketMQ



# Q：如何保证消息不重复（幂等性）？

kafka消费者会在获取消息后提交offset（相当于序号）给zk，告诉broker消费到哪了，从而保证消费者获取消息的基本顺序性，当消费者宕机重启后，还能从上次消费的地方继续开始

然而消费者并不是每条消息都提交offset，而是定时批量提交。若消费到中间某个消息（序号i），还未提交offset就宕机，则下次重启时无法继续从消息i开始，而是从i之前的某条开始，这就会出现重复消息

**解决**

1. 用redis记录消息id（流水号），重复就跳过
2. 用数据库唯一主键约束
3. 加分布式锁（实际项目），一条消息从生产到消费全程加锁



# Kafka

## Broker 

就是Server。 包含多个 Topic , Partition, 和 Replica. 负责协调 Producer 和 Consumer 主从结构为: 主节点为 Controller, 从节点为从节点 Kafka 启动是会往 Zookeeper 中注册当前 Broker 信息. 谁先注册谁就是 Controller. 读取注册上来的从节点的数据(通过监听机制), 生成集群 的元数据信息, 之后把这些信息都分发给其他的服务器, 让其他服务器能感知到集群中其它成员的 存在

## Topic 

标准 MQ模型 中的 Queue。Kafka 中一个 Topic 的消息会保存在不同的 Partition (不同的 Broker)来保证高可用

## Partition （分区） 

可以理解为将标准 MQ 的 Queue 的消息进行拆分，来实现高可用 Producer 发送的 Message，根据 key 和 partition 数进行 hash，然后进行投递。

一个分区只能被同一个 Consumer Group （消费者组）中的一个 Consumer 消费，分区内消费有序。因此消费者组可用于实现某个topic的并行消费，n个消费者组同时消费某topic的n个分区，且不会互相干扰

## Replica （副本）

每一个 Partition 都可以设置多个副本，但 Replica 的数量应不超过 Broker 的数量 

Leader：Partition 的所有副本中只能有一个 Leader 节点(Broker)。Producer 写数据只往 Leader 中写。Consumer 读数据也是从 Leader 中读

Follower：只用于**备份**Leader，采用 pull 模式

## Producer

标准 MQ 中的发送方，一个Producer通常只发送一类消息（同一个topic）。发送给 Broker 使用**push** (推)模式

## Consumer Group （消费者组）

一类Consumer的集合名称，这类Consumer通常消费一类消息（同一个topic），且消费逻辑一致。



## Controller

kafka也是主从式的架构，主节点就叫controller，其余的为从节点，controller是需要和zookeeper进行配合管理整个kafka集群。

## Zookeeper

kafka严重依赖于zookeeper集群（所以之前的zookeeper文章还是有点用的）。所有的broker在启动的时候都会往zookeeper进行注册，目的就是选举出一个controller【先到先得】

controller会监听zookeeper里面的多个目录，例如有一个目录/brokers/，其他从节点往这个目录上**注册（就是往这个目录上创建属于自己的子目录而已）**自己，这时命名规则一般是它们的id编号，比如/brokers/0、/brokers/1、/brokers/2

注册时各个节点必定会暴露自己的主机名，端口号等等的信息，此时controller就要去**读取注册上来的从节点的数据（通过监听机制），生成集群的元数据信息，之后把这些信息都分发给其他的服务器，让其他服务器能感知到集群中其它成员的存在**。

此时模拟一个场景，我们创建一个主题（其实就是在zookeeper上/topics/topicA这样创建一个目录而已），kafka会把分区方案生成在这个目录中，此时controller就监听到了这一改变，它会去同步这个目录的元信息，然后同样下放给它的从节点，通过这个方法让整个集群都得知这个分区方案，此时从节点就各自创建好目录等待创建分区副本即可。这也是整个集群的管理机制。

## Q：高可用？

<img src="images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20220420105234912.png" alt="image-20220420105234912" style="zoom: 67%;" />

## Q：Kafka为何能做到高性能？

### 1 顺序写

追加写磁盘，顺序写的性能极高

### 2 零拷贝

先来看看非零拷贝的情况，数据从内存拷贝到kafka服务进程那块，又拷贝到socket缓存那块，整个过程耗费的时间比较高

<img src="images/消息队列/640-1679328162013-3.jpeg" alt="图片" style="zoom:50%;" />

kafka利用了Linux的sendFile技术（NIO），省去了进程切换和一次数据拷贝，让性能变得更好。

<img src="images/消息队列/640-1679328175176-6.png" alt="图片" style="zoom:50%;" />

## Kafka网络设计

kafka的网络设计和Kafka的调优有关，这也是为什么它能支持高并发的原因

![图片](images/消息队列/640.png)

首先客户端发送请求全部会先发送给一个Acceptor，broker里面会存在3个线程（默认是3个），这3个线程都是叫做processor，Acceptor不会对客户端的请求做任何的处理，直接封装成一个个socketChannel发送给这些processor形成一个队列，发送的方式是轮询，就是先给第一个processor发送，然后再给第二个，第三个，然后又回到第一个。消费者线程去消费这些socketChannel时，会获取一个个request请求，这些request请求中就会伴随着数据。

线程池里面默认有8个线程，这些线程是用来处理request的，解析请求，如果request是写请求，就写到磁盘里。读的话返回结果。
processor会从response中读取响应数据，然后再返回给客户端。这就是Kafka的网络三层架构。

所以如果我们需要对kafka进行增强调优，增加processor并增加线程池里面的处理线程，就可以达到效果。request和response那一块部分其实就是起到了一个缓存的效果，是考虑到processor们生成请求太快，线程数不够不能及时处理的问题。

所以这就是一个加强版的reactor网络线程模型。

# CTG-MQ

基于RocketMQ，提供高性能、高可用服务

## Name Server

一个几乎无状态节点，可集群部署，节点之间无同步信息。 它主要提供broker注册、Topic路由管理等功能

## Broker

消息中转角色，负责存储消息，转发消息，一般也称Server。

CTG-MQ一般在多个服务器部署broker集群

## Topic 

在ctg-mq中，topic类似于JMS规范中的队列，所有消息都是存放在不同的 topic中，**每个topic都有与之对应的生产者和消费者**。

broker与topic是多对多关系，broker里可能有多个topic，一个Topic可以分片（分成多个Queue）存在多个broker上（分布式）。

## Queue

每个Topic由多个队列Queue组成（类似kafka的分区），Queue内有序。



![image-20220426204242838](images/消息队列/image-20220426204242838.png)

## 生产者

生产组：一类Producer的集合名称，这类Producer通常发送一类消息（同一个topic），且发送逻辑一致，一般由业务系统负责产生消息。

生产者实例： 一个生产者实例代表**生产者的一员**，不同的生产者用不同的实例名字创建。

## 消费者

消费组：一类Consumer的集合名称，这类Consumer通常消费一类消息（同一个topic），且消费逻辑一致，一般是后台系统负责异步消费。消费进度由存储在消费组上。

消费者实例 ：一个消费者实例代表**消费组的一员**，不同的消费者用不同的实例名字创建。

## 消费模型

主要有push和pull两种

### PUSH模型

推送模型（被动），是一个“发布-订阅”模型，由consumer封装了轮询过程，并注册MessageListener监听器，consumer接收消息后，回调监听器接口，唤醒监听器来消费，对用户而言，感觉消息是被推送过来的。

优点是实时性好，缺点是需要维护一个长连接，资源消耗大。该模型适合于的场景：client数量不多，server数据变化频繁。

在ctg-mq中，客户端会自动开启线程消费消息，线程数是5-64，即listener里面的方法，会被多线程执行。

客户端内部可以根据堆积量进行调整，使用者不需要新启、管理消费线程。并有流控机制，当客户端缓存一定量消息，导致消费不及时，会停止推送新消息。

### PULL模型

拉取模型（主动），应用通常主动调用Consumer的拉消息方法从Broker拉 消息，主动权由应用控制，但实时性取决于应用主动拉取的频率。在PULL消费中，线程由应用自主决定。

consumer在pull的时候，告诉broker自己buffer中可用的容量，整个流程如下：

1、consumer请求broker，告诉broker本地的可承载量，比如500
2、broker在收到消息后，如果没有消息则进入long polling状态
3、当有消息的时候，broker直接向consumer进行push，总共push的数据量为500
4、在整个push期间，consumer无需重新pull，即可获取数据
5、由于broker知道最大容量，所以无需担心被冲垮。

### 广播消费和集群消费

**广播消费** 

注意：使用消费模式，在很多使用场景都会带来影响或限制，在CTG-MQ中， 应尽量避免使用此消费模式。

在广播消费模式下，一条消息被多个Consumer消费，即使这些 Consumer属于同一个Consumer Group，消息也会被Consumer Group中 的每个Consumer都消费一次，广播消费中的Consumer Group概念可以认 为在消息划分方面无意义。 V1.x版本由于广播消费的消费进度，是保存在客户端的，对于很多使用场景 会带来影响，在ctg-mq中，并不推荐使用此消费模式。 V2.x版本在服务端存储消费状态，不支持此消费模式。推荐通过多消费组 （订阅组）的方式进行消费。

**集群消费** 

一个Topic 可以被一个或多个 Consumer Group 消费 ， 每个Consumer Group有自己独立的消费进度，消费进度是保存在服务端的。 一个Consumer Group中的消费者实例可以平均分摊消费消息，做到负载均衡。例如某个Topic有9条消息，其中一个Consumer Group有3个不同的消 费者实例（可能是3个进程，或者3台机器），那么每个实例只消费其中的3 条消息。 在此消费模式下，可以做到Point-To-Point的消费，也可以做到JMS里面广播消费，能满足绝大部分场景，推荐使用此消费模式。



## 原生RocketMQ的问题

- 功能不完善：功能比较单一，针对不同应用场景无法有效支 持，如消息轨迹查询，严格消费机制，数据自动删除策略等。

- 可维护性差：缺乏配套监控运维能力，难以迅速发现解决如 消息堆积、队列堵塞等问题。 
- 可靠性较低：消息服务不提供主备切换能力，存在单点故障， 无法保证服务高可用

## CTG-MQ的改进

高可用、高可靠改进： 

- 实现自动主备切换、自动拉起功能，保证服务高可用 

- 实现消息删除策略，按不同的场景优先保证服务可用性或者 数据安全性。


 可维护性改进： 

- 实现按生产者、消费者、数据节点、队列4种维度的运行状态 监控，方便快速发现问题
- 实现可视化的监控、配置、管理界面 
- 实现自动化测试，以快速迭代 

新增功能： 

- 消息轨迹收集、分析与查询，做到可查可追踪

- 严格的消费机制，满足消费严格不重复的应用需求 

- 重新封装SDK，简化应用使用，并提供按hash算法实现消息 局部有序生产消费


## 分布式

## 消息模式

### 有序消息

消费消息的顺序要同发送消息的顺序一致，在CTG-MQ中，主要有两种：普通和严格

**普通有序消息** 

在正常情况下可以保证完全的顺序消息，但是一旦发生通 信异常，Broker重启，由于队列总数发生变化，哈希取模后定位的队列会变 化，产生短暂的消息顺序不一致。 如果业务能容忍在集群异常情况（如某个Broker宕机或者重启）下，消息短 暂的乱序，使用普通顺序方式比较合适。

**严格有序消息** 

无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集群中只要有一台机器不可用，则整个集群都不可 用（或者影响hash值对应队列的使用），服务可用性大大降低。 如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不 过仍然会存在几分钟的服务不可用。 若业务能容忍短暂乱序，推荐普通有序消费。

在CTG-MQ中，消息模式选择的优先顺序为：**无序消息>普通有序消息>严格有序消息**。在业务场景允许的情况下，优先选择无序消息，或者 在业务能变通的情况下，将有序消息转化为无序消息。

 **有序消息的缺点** & 必须注意事项：

1. 对于生产者，因为要保证顺序，所以一般单线程串行发送， 性能较低。对一个Topic有多个Queue的场景，可增加生产者数，每个生产者发送固定的Queue，提高性能。 

2. 对于消费者，因为要保证顺序，所以一般单线程串行消费，消费性能较低。对一个Topic有多个Queue的场景，可以通过增加消费者 实例数，提高性能，但应用必须考虑消息者实例数量变化，由于负载均 衡带来的短时间数据乱序问题。

3. 对于普通有序消息，当节点故障时，由于Queue数的变化，导致hash 值的变化，产生与消费都会出现短暂的消息顺序不一致；对于严格有序 消息，当节点故障时，Queue数不会变化，产生与消费都会出现异常， 直到故障节点恢复。

4. 对于普通有序消息，意味着业务能接受短时间消息乱序，所以一般情 况下可以在线态扩容；对于严格有序消息，需要将所有消息消费完，并且停止服务，才能扩容。

5. 有一种场景，同一Topic所有消息必须是有序生产与有序消费，可以使 用多Queue然后在生产消费端做顺序处理，也可以拆分多个Topic然后 使用单Queue进行处理，但在设计时，应用必须考虑单Queue的处理性 能是否能满足。对于单Queue，只要对应的broker故障，则服务中断。

### 无序消息

优点：

1. 生产者可以使用多进程、多线程往同一个TOPIC发送，性能较好
2. 消费者可以使用多进程、多线程同时消费，性能较好 
3. 可以充分使用集群的 failover（故障转移）特点，无须依赖自动主备切换（切换过期服务中断），包括：  当集群中某一broker节点故障时，不影响业务消息生产， 消息将failover发送到其它节点  当集群中某一broker节点故障时，不影响其它节点数据 消费，故障恢复后既可消费  * 充分利用failover特点，可不部署自动切换组件，减少 部署复杂度，减少运维难度
4. 能动态地扩容



