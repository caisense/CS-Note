(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{285:function(v,s,t){"use strict";t.r(s);var _=t(14),e=Object(_.a)({},(function(){var v=this,s=v._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[s("h1",{attrs:{id:"基本架构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#基本架构"}},[v._v("#")]),v._v(" 基本架构")]),v._v(" "),s("p",[v._v("单体redis分为0~15号DB（配置文件设置），每个DB相当于命名空间，并不是传统意义上的DB。")]),v._v(" "),s("p",[v._v("DB内key不能重复，不同DB互不影响")]),v._v(" "),s("p",[v._v("redis集群模式只能使用一个数据库空间：db0")]),v._v(" "),s("h1",{attrs:{id:"数据结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#数据结构"}},[v._v("#")]),v._v(" 数据结构")]),v._v(" "),s("p",[v._v("Redis本质都是"),s("strong",[v._v("k-v键值对")]),v._v("，用一个唯一的字符串key来标识存储，数据结构指value的存储结构。")]),v._v(" "),s("ul",[s("li",[v._v("Key的大小上限为"),s("strong",[v._v("512MB")]),v._v("，但建议不超过1KB，这样既节约存储空间，也利于检索。")]),v._v(" "),s("li",[v._v("value大小上限为"),s("strong",[v._v("512M")]),v._v("（对String类型而言）。")]),v._v(" "),s("li",[v._v("k-v对上限："),s("strong",[v._v("2^32-1")]),v._v("个。")]),v._v(" "),s("li",[v._v("Hash、List、Set、ZSet的元素上限是"),s("strong",[v._v("2^32-1")]),v._v("个。")])]),v._v(" "),s("p",[s("strong",[v._v("基本数据结构")]),v._v("共有5种：字符串string、列表list、字典hash、集合set、有序集合zset。")]),v._v(" "),s("p",[v._v("此外还有3种"),s("strong",[v._v("特殊类型")]),v._v("：")]),v._v(" "),s("ul",[s("li",[v._v("Geo：地理位置定位，用于存储地理位置信息，并对存储的信息进行操作（Redis 3.2 推出）。")]),v._v(" "),s("li",[v._v("HyperLogLog：用来做基数统计算法的数据结构，如统计网站的 UV。")]),v._v(" "),s("li",[v._v("Bitmaps：用一个比特位来映射某个元素的状态，在 Redis 中，它的底层是基于字符串类型实现的，可以把 bitmaps 成作一个以比特位为单位的数组。")])]),v._v(" "),s("img",{staticStyle:{zoom:"80%"},attrs:{src:"images/Redis/image-20220419002910447.png",alt:"image-20220419002910447"}}),v._v(" "),s("h2",{attrs:{id:"string-字符串"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#string-字符串"}},[v._v("#")]),v._v(" String（字符串）")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("简介：最常用的数据结构，是一个k-v键值对，v是字符串。它是二进制安全的，value大小上限为 512M")])]),v._v(" "),s("li",[s("p",[v._v("简单使用举例：set key value、get key 等")])]),v._v(" "),s("li",[s("p",[v._v("应用场景：共享session、分布式锁，计数器、限流、存储图片或序列化的对象")])]),v._v(" "),s("li",[s("p",[v._v("内部编码有 3 种：")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("int（8 字节，java的Long）")])]),v._v(" "),s("li",[s("p",[v._v("embstr（小于等于 39 字节字符串）")])]),v._v(" "),s("li",[s("p",[v._v("raw（大于 39 个字节字符串）")])])])])]),v._v(" "),s("h2",{attrs:{id:"hash-哈希"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hash-哈希"}},[v._v("#")]),v._v(" Hash（哈希）")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("简介：存储二级map，无序，第一级是 k - v 键值对，其中 v 本身又是一个 k-v 键值对")])]),v._v(" "),s("li",[s("p",[v._v("简单使用举例：")]),v._v(" "),s("ol",[s("li",[s("p",[s("strong",[v._v("hset")]),v._v(" key field value：设置map（key对应的map，下文不再强调）中的k-v为 field value")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("hget")]),v._v(" key field：获取map中的k = field的v")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("hgetall")]),v._v(" key：获取map中所有k-v")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("hlen")]),v._v(" key：得到map的k-v对总数")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("hdel")]),v._v(" key ：删除map")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("hincrby")]),v._v(" key filed inc：map中k=field的值加上inc")])])])]),v._v(" "),s("li",[s("p",[v._v("内部编码：ziplist（压缩列表） 、hashtable（哈希表）")])]),v._v(" "),s("li",[s("p",[v._v("应用场景：存对象（k为对象唯一id，v为map，恰好存放对象的所有属性）")])])]),v._v(" "),s("h2",{attrs:{id:"list-列表"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#list-列表"}},[v._v("#")]),v._v(" List（列表）")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("简介：k-v 键值对，v是列表（list）类型，从左向右存储多个有序的字符串，一个列表最多可存储 "),s("strong",[v._v("2^32-1")]),v._v(" 个元素")])]),v._v(" "),s("li",[s("p",[v._v("简单使用举例：")]),v._v(" "),s("ol",[s("li",[s("p",[s("strong",[v._v("lpush")]),v._v(" key value [value ...]：列表（key对应的列表，下文不再强调）头插一个（或多个）")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("rpush")]),v._v(" key value [value ...]：列表尾插一个（或多个）")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("lpop")]),v._v(" key：从列表头部弹出")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("rpop")]),v._v(" key：从列表尾部弹出")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("blpop")]),v._v(" key [key ...] timeout：从列表头部弹出一个（或多个）元素，若"),s("strong",[v._v("列表空")]),v._v("则阻塞等待timeout秒，若=0则一直阻塞")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("brpop")]),v._v(" key [key ...] timeout：从列表尾部弹出一个（或多个）元素，若"),s("strong",[v._v("列表空")]),v._v("则阻塞等待timeout秒，若=0则一直阻塞")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("lindex")]),v._v(" key idx：通过索引取值：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("若下标（idx）为非负数，返回"),s("code",[v._v("list[idx]")]),v._v("元素，idx=0为最左元素。")])]),v._v(" "),s("li",[s("p",[v._v("若下标为负，从右向左，idx=-1为最右元素。")])]),v._v(" "),s("li",[s("p",[v._v("若下标超过数组长度，返回nil")])])]),v._v(" "),s("img",{staticStyle:{zoom:"67%"},attrs:{src:"images/Redis/image-20220419093351771.png",alt:"image-20220419093351771"}})]),v._v(" "),s("li",[s("p",[s("strong",[v._v("lset")]),v._v(" key idx val：通过索引设值："),s("code",[v._v("list[idx] = val")])])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("lrange")]),v._v(" key start end：获取"),s("code",[v._v("[start, stop]")]),v._v("区间元素，与java数组不同，右边是闭区间（stop号元素也能取到）。")])])])]),v._v(" "),s("li",[s("p",[v._v("内部编码：ziplist（压缩列表）、linkedlist（链表）")])]),v._v(" "),s("li",[s("p",[v._v("应用场景：栈（lpush+lpop）、消息队列（lpush+rpop）、阻塞队列（lpush+brpop）")]),v._v(" "),s("p",[s("strong",[v._v("公众号文章列表（或微博信息流）")]),v._v("：分库分表分布式的db，order by 本来就很耗时，再聚合排序更耗时。")]),v._v(" "),s("p",[v._v("利用redis全局一致的特性，对每个用户id，博主发布一条就 lpush msg:{用户id} 消息id，则顺序读list就是最新的消息。查看最新的5条消息列表用 lrange msg:{用户id} 0 5")]),v._v(" "),s("p",[s("strong",[v._v("异步队列")]),v._v("：将需要延后处理的任务结构体序列化为字符串，放入Redis列表，再用一个线程从列表中轮询处理。")])])]),v._v(" "),s("h2",{attrs:{id:"set-集合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#set-集合"}},[v._v("#")]),v._v(" Set（集合）")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("简介：k-v 键值对，其中v是字符串集合（元素不重复），无序")])]),v._v(" "),s("li",[s("p",[v._v("简单使用举例：")]),v._v(" "),s("ol",[s("li",[s("strong",[v._v("sadd")]),v._v(" key member1 [member2 ...]：（key对应的，下文不再强调）集合添加一个（或多个）成员")]),v._v(" "),s("li",[s("strong",[v._v("srem")]),v._v(" key member1 [member2 ...]：集合删除一个或多个成员")])])])]),v._v(" "),s("ol",{attrs:{start:"3"}},[s("li",[s("strong",[v._v("sismember")]),v._v(" key member：判断member是否在集合中，若在返回1；若不在或key不存在，返回0")]),v._v(" "),s("li",[s("strong",[v._v("smembers")]),v._v(" key：返回集合所有成员")]),v._v(" "),s("li",[s("strong",[v._v("scard")]),v._v(" key：返回集合成员数量")]),v._v(" "),s("li",[s("strong",[v._v("srandmember")]),v._v(" key [count]：返回随机count个成员，不加count则默认一个")]),v._v(" "),s("li",[s("strong",[v._v("spop")]),v._v(" key [count]：弹出随机count个成员，不加count则默认一个")]),v._v(" "),s("li",[s("strong",[v._v("sdiff")]),v._v(" key1 key2：求两个集合的差集")]),v._v(" "),s("li",[s("strong",[v._v("SINTER")]),v._v(" key1 [key2 … ]：求两个及以上集合的交集")]),v._v(" "),s("li",[s("strong",[v._v("SUNION")]),v._v(" key1 [key2]：求几个集合并集")])]),v._v(" "),s("ul",[s("li",[s("p",[v._v("内部编码：intset（整数集合）、hashtable（哈希表）")])]),v._v(" "),s("li",[s("p",[v._v("应用场景：用户标签、社交需求")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("生成随机数抽奖")]),v._v(" "),s("p",[v._v("添加抽奖人：sadd key {userID}；查看所有参与抽奖用户：smembers key；")]),v._v(" "),s("p",[v._v("抽取n名中奖者：srandmember key n 或者spop key n")])]),v._v(" "),s("li",[s("p",[v._v("朋友圈点赞")]),v._v(" "),s("p",[v._v("点赞，把对某条朋友圈点赞的用户id存在一个集合里：sadd like:{消息id} {用户id}；")]),v._v(" "),s("p",[v._v("取消点赞：srem  like:{消息id} {用户id};")]),v._v(" "),s("p",[v._v("检查用户是否点过赞：sismember  like:{消息id} {用户id}；")]),v._v(" "),s("p",[v._v("获取点赞的用户列表：smembers  like:{消息id}；获取点赞用户数：scard  like:{消息id}；")])]),v._v(" "),s("li",[s("p",[v._v("微博关注模型")]),v._v(" "),s("p",[v._v("a关注的人：aSet -> {w, x, y, z}")]),v._v(" "),s("p",[v._v("b关注的人：bSet -> {u, v, w, x}")]),v._v(" "),s("p",[v._v("求a和b的共同关注，用交集：sinter aSet bSet; 返回{w, x}")]),v._v(" "),s("p",[v._v("a和b是好友，则a可能认识的人，用差集：sdiff bSet aSet；返回{u, v}")]),v._v(" "),s("p",[v._v("判断a关注的人也关注x，看x是否在集合a：sismember aSet x")])])])])]),v._v(" "),s("h2",{attrs:{id:"zset-有序集合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#zset-有序集合"}},[v._v("#")]),v._v(" zset（有序集合）")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("简介：k-v 键值对，v是"),s("strong",[v._v("已排序")]),v._v("的字符串集合，排序依据是元素的score")]),v._v(" "),s("p",[s("strong",[v._v("注意")]),v._v("：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("score相同时，redis对元素使用"),s("strong",[v._v("字典排序")])])]),v._v(" "),s("li",[s("p",[v._v("score 值可以是整数值或"),s("strong",[v._v("双精度浮点数")]),v._v("。")])])])]),v._v(" "),s("li",[s("p",[v._v("简单格式举例：")]),v._v(" "),s("ol",[s("li",[s("p",[s("strong",[v._v("zadd")]),v._v(" key score member [[score2 member2] ...]：有序集合中加入一个（或多个）带分值元素")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zrem")]),v._v(" key member [member ...]：从有序集合中删除元素")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zscore")]),v._v(" key member：返回member的分值")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zincrby")]),v._v(" key increment member：将member的分值加上increment，increment可以为负数；当key不存在 ，或member不再集合中，该命令等同于"),s("strong",[v._v("zadd")]),v._v(" key increment member")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zrank")]),v._v(" key member：返回member在集合中的排名")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zrange")]),v._v(" key start stop [withscores]：顺序返回排名在"),s("code",[v._v("[start, stop]")]),v._v("区间的元素；带withscores则带上分值，以value1,score1, ..., valueN,scoreN格式返回")]),v._v(" "),s("p",[v._v("下标为负数则从最后排名开始，-1为倒数第一，以此类推")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zrevrange")]),v._v(" key start stop [withscores]：倒序")])]),v._v(" "),s("li",[s("p",[s("strong",[v._v("zrangebyscore")]),v._v(" key min max [WITHSCORES] [LIMIT offset count] ：返回score介于"),s("code",[v._v("[min, max]")]),v._v("区间的元素，顺序根据分值排名（从小到大）。可选的 LIMIT 参数指定返回结果的数量及区间（就像 SQL 中的 SELECT LIMIT offset,  count )")])])])]),v._v(" "),s("li",[s("p",[v._v("底层内部编码：")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("ziplist（压缩列表）")]),v._v(" "),s("p",[v._v("类似数组，但本质上是链表，根据socre排序")]),v._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/Redis/image-20220419160219909.png",alt:"image-20220419160219909"}})]),v._v(" "),s("li",[s("p",[v._v("skiplist（跳跃表）")]),v._v(" "),s("p",[v._v("将有序链表改造为多层索引，元素较多时，查找效率接近二分（OlogN）")]),v._v(" "),s("p",[s("img",{attrs:{src:"images/Redis/image-20220419112349770.png",alt:"image-20220419112349770"}})])])])]),v._v(" "),s("li",[s("p",[v._v("应用场景：用户点赞排序。")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("热门排行榜")]),v._v(" "),s("p",[v._v("点击新闻：zincrby hotNews:20220419 1 总理记者会")]),v._v(" "),s("p",[v._v("展示当日排行前十：zrevrange hotNews:20220419 0 9 withscores")])])])])]),v._v(" "),s("h2",{attrs:{id:"bitmap"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#bitmap"}},[v._v("#")]),v._v(" Bitmap")]),v._v(" "),s("p",[v._v("本质上就是一个string类型的bit数组，数组每个元素都是二进制0或1。")]),v._v(" "),s("ol",[s("li",[s("strong",[v._v("SETBIT命令")]),v._v(" "),s("code",[v._v("SETBIT <key> <offset> <value>")]),v._v("：将指定bit数组中的offset位置（下标从0开始）置为value（0或1）")]),v._v(" "),s("li",[s("strong",[v._v("GETBIT命令")]),v._v(" "),s("code",[v._v("GETBIT <key> <offset>")]),v._v("：读取指定bit数组中offset位置的bit")]),v._v(" "),s("li",[s("strong",[v._v("BITCOUNT命令")]),v._v(" "),s("code",[v._v("BITCOUNT key")]),v._v("：统计指定bit数组中，1的个数。")])]),v._v(" "),s("p",[v._v("应用：统计10亿用户的在线状态")]),v._v(" "),s("p",[v._v("用数据库肯定撑不住，因此考虑bitmap。只需要一个 key = login_status 的bit数组，存储所有用户登陆状态，长度为10亿，占用内存仅100MB。将用户id作为offset，在线置1，离线置0。")]),v._v(" "),s("p",[v._v("例如用户id=10086，用"),s("code",[v._v("SETBIT login_status 10086 1")]),v._v("将其上线状态写入。统计时用"),s("code",[v._v("BITCOUNT login_status")]),v._v(" 即可得到10亿用户的在线数。")]),v._v(" "),s("p",[s("strong",[v._v("缺点")]),v._v("是id必须连续或集中，否则浪费空间。可以考虑改用set存放在线的用户id。")]),v._v(" "),s("h1",{attrs:{id:"存储结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#存储结构"}},[v._v("#")]),v._v(" 存储结构")]),v._v(" "),s("p",[v._v("dict是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。Redis的一个database中所有key到value的映射，就是使用一个dict来维护的。dict本质上是为了解决查找问题(Searching)。")]),v._v(" "),s("div",{staticClass:"language-c line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-c"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//dict字典的数据结构")]),v._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("typedef")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("struct")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("dict")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("{")]),v._v("\n    dictType "),s("span",{pre:!0,attrs:{class:"token operator"}},[v._v("*")]),v._v("type"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//直线dictType结构，dictType结构中包含自定义的函数，这些函数使得key和value能够存储任何类型的数据")]),v._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("void")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[v._v("*")]),v._v("privdata"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//私有数据，保存着dictType结构中函数的 参数")]),v._v("\n    dictht ht"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[v._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//两张哈希表")]),v._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("long")]),v._v(" rehashidx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//rehash的标记，rehashidx=-1表示没有进行rehash，rehash时每迁移一个桶就对rehashidx加一")]),v._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("int")]),v._v(" itreators"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//正在迭代的迭代器数量")]),v._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("}")]),v._v("\n \n"),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//dict结构中ht[0]、ht[1]哈希表的数据结构")]),v._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("typedef")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("struct")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("dictht")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("{")]),v._v("\n    dictEntry"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),v._v(" table"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("        "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//数组中存放哈希节点dictEntry的地址")]),v._v("\n    unsingned "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("long")]),v._v(" size"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//哈希表table的大小，出始大小为4")]),v._v("\n    unsingned "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("long")]),v._v("  sizemask"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//用于将hash值映射到table位置的索引，大小为（size-1）")]),v._v("\n    unsingned "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("long")]),v._v("  used"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//记录哈希表已有节点（键值对）的数量")]),v._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("}")]),v._v("\n")])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br"),s("span",{staticClass:"line-number"},[v._v("2")]),s("br"),s("span",{staticClass:"line-number"},[v._v("3")]),s("br"),s("span",{staticClass:"line-number"},[v._v("4")]),s("br"),s("span",{staticClass:"line-number"},[v._v("5")]),s("br"),s("span",{staticClass:"line-number"},[v._v("6")]),s("br"),s("span",{staticClass:"line-number"},[v._v("7")]),s("br"),s("span",{staticClass:"line-number"},[v._v("8")]),s("br"),s("span",{staticClass:"line-number"},[v._v("9")]),s("br"),s("span",{staticClass:"line-number"},[v._v("10")]),s("br"),s("span",{staticClass:"line-number"},[v._v("11")]),s("br"),s("span",{staticClass:"line-number"},[v._v("12")]),s("br"),s("span",{staticClass:"line-number"},[v._v("13")]),s("br"),s("span",{staticClass:"line-number"},[v._v("14")]),s("br"),s("span",{staticClass:"line-number"},[v._v("15")]),s("br"),s("span",{staticClass:"line-number"},[v._v("16")]),s("br")])]),s("p",[v._v("redis存储k-v使用哈希表，求key的hash值以确定放数组哪个位置（桶），对hash冲突的k-v，使用拉链法解决。")]),v._v(" "),s("p",[v._v("dict维护两张哈希表，只有在重哈希的过程中，ht[0]和ht[1]才都有效。平常情况下只有ht[0]有效。")]),v._v(" "),s("h1",{attrs:{id:"rehash-扩容-收缩-原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#rehash-扩容-收缩-原理"}},[v._v("#")]),v._v(" Rehash（扩容/收缩）原理？")]),v._v(" "),s("p",[v._v("背景：当数据增多超过负载因子后，为降低冲突概率需要扩容哈希表，原有的k-v需要rehash。")]),v._v(" "),s("blockquote",[s("p",[v._v("扩容：table直接翻倍，原理与HashMap类似，因为取模使用位运算")]),v._v(" "),s("p",[v._v("负载因子 = 哈希表已保存节点数量 / 哈希表大小，"),s("code",[v._v("load_factor = ht[0].used / ht[0].size")])]),v._v(" "),s("p",[s("strong",[v._v("渐进式")]),v._v("rehash：同时保留新旧两个hash结构，在后续的定时任务和hash操作中，逐渐将旧hash的内容转移到新hash中。原因是，如果哈希表里保存的键值对数量很大时，集中rehash可能会导致服务器在一段时间内停止服务（redis单线程）。")])]),v._v(" "),s("p",[v._v("在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]下标rehashidx的元素（桶）上的链表移动到扩容后的ht[1]上，然后将rehashidx++，表示下一次要迁移链表所在桶的位置。")]),v._v(" "),s("p",[v._v("当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表），释放 ht[0] 。 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， rehashidx置为-1，为下一次 rehash 做准备。")]),v._v(" "),s("p",[v._v("触发扩容：满足以下两种情况")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("当redis没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，且负载因子>=1")])]),v._v(" "),s("li",[s("p",[v._v("当redis执行 BGSAVE 命令或者 BGREWRITEAOF 命令，且负载因子>=5")]),v._v(" "),s("blockquote",[s("p",[v._v("两种情况判断的负载因子不同，是因为在执行 BGSAVE 命令或 BGREWRITEAOF命令的过程中， Redis会fork一个子进程，而大多数操作系统都采用写时复制（copy-on-write）技术来优化子进程的使用效率，所以在子进程存在期间，服务器会提高执行扩展操作所需的负载因子，从而尽可能地避免在"),s("strong",[v._v("子进程存在期间进行扩容")]),v._v("操作，这可以避免不必要的内存写入操作， 最大限度地节约内存。")])])])]),v._v(" "),s("p",[v._v("触发收缩：当负载因子<0.1。")]),v._v(" "),s("p",[v._v("Rehash进行期间的添加、删除和查询操作：")]),v._v(" "),s("ol",[s("li",[v._v("添加：如果正在Rehash，会把数据插入到ht[1]（平常情况插入到ht[0]），这样时为了保证ht[0]不再新增数据，随着rehash操作最终变空。")]),v._v(" "),s("li",[v._v("查询：先在ht[0]上进行查找，再判断当前是否正在Rehash，如果没有，那么在ht[0]上的查找结果就是最终结果。否则，在ht[1]上进行查找。查询时会先根据key计算出桶的位置，在到桶里的链表上寻找key。")]),v._v(" "),s("li",[v._v("删除：判断当前是不是在重哈希过程中，如果是只在ht[0]中查找要删除的key；否则ht[0]和ht[1]它都要查找删除。")])]),v._v(" "),s("h1",{attrs:{id:"redis为何高效"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#redis为何高效"}},[v._v("#")]),v._v(" Redis为何高效？")]),v._v(" "),s("p",[v._v("官方数据是10万+的QPS（每秒内查询次数）")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("单线程")]),v._v(" "),s("p",[v._v("单线程避免了多线程的竞争，省去了多线程切换带来的时间和性能开销，并且不会出现死锁。")]),v._v(" "),s("blockquote",[s("p",[v._v("多线程的本质就是 CPU 模拟出来多个线程的情况，这种模拟出来的情况代价就是上下文的切换，对于一个内存的系统来说，没有上下文的切换就是效率最高的。")])]),v._v(" "),s("ul",[s("li",[s("p",[v._v("4.0之前是单线程，具体而言 "),s("strong",[v._v("网络I/O 、Get/Set")]),v._v(" 操作是单线程。持久化、集群同步还是用其他线程完成")])]),v._v(" "),s("li",[s("p",[v._v("4.0之后添加多线程，将耗时的命令异步化，避免阻塞单线程的事件循环。具体是大数据的异步删除功能，例如 "),s("code",[v._v("unlink key")]),v._v("、"),s("code",[v._v("flushdb async")]),v._v("、"),s("code",[v._v("flushall async")]),v._v(" 等")])]),v._v(" "),s("li",[s("p",[v._v("6.0开始用多线程处理网络IO")])])])]),v._v(" "),s("li",[s("p",[v._v("基于内存存储实现，省去磁盘IO开销")])]),v._v(" "),s("li",[s("p",[v._v("文件事件Proc使用"),s("strong",[v._v("IO多路复用程序")]),v._v("监听多个socket，基于非阻塞IO模型，实现高性能网络通信模型。")]),v._v(" "),s("p",[v._v("对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不会是 CPU 密集型的，而是 I/O 密集型。Redis真正的性能瓶颈在于网络 I/O，也就是客户端和服务端之间的网络传输延迟")])])]),v._v(" "),s("h1",{attrs:{id:"如何实现数据不丢失"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何实现数据不丢失"}},[v._v("#")]),v._v(" 如何实现数据不丢失？")]),v._v(" "),s("p",[v._v("把数据从内存存储到磁盘上（持久化），三种方式")]),v._v(" "),s("ol",[s("li",[v._v("AOF 日志（Append Only File，文件追加方式）：记录所有的操作命令，并以文本的形式追加到文件中。")]),v._v(" "),s("li",[v._v("RDB 快照（Redis DataBase）：将某一个时刻的内存数据，以二进制的方式写入磁盘。")]),v._v(" "),s("li",[v._v("混合持久化方式：Redis 4.0 新增了混合持久化的方式，集成了 RDB 和 AOF 的优点。")])]),v._v(" "),s("h1",{attrs:{id:"持久化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#持久化"}},[v._v("#")]),v._v(" 持久化")]),v._v(" "),s("p",[v._v("Redis 是基于内存，为避免数据丢失，需要持久化到磁盘，有两种方式")]),v._v(" "),s("h2",{attrs:{id:"_1-rdb"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-rdb"}},[v._v("#")]),v._v(" 1. RDB")]),v._v(" "),s("p",[v._v("是 "),s("strong",[v._v("Redis 默认 "),s("strong",[v._v("的持久化方式。把内存数据以")]),v._v("快照")]),v._v("的形式保存到磁盘上。在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中")]),v._v(" "),s("p",[v._v("执行完操作后，在指定目录下会生成一个 dump.rdb 文件，Redis 重启的时候，通过加载 dump.rdb 文件来恢复数据。")]),v._v(" "),s("p",[v._v("优点：适合大规模的数据恢复场景，如备份，全量复制等。")]),v._v(" "),s("p",[v._v("缺点：没办法做到实时持久化/秒级持久化；新老版本存在 RDB 格式兼容问题")]),v._v(" "),s("h3",{attrs:{id:"q-写后日志的风险"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-写后日志的风险"}},[v._v("#")]),v._v(" Q：写后日志的风险？")]),v._v(" "),s("ul",[s("li",[v._v("数据可能会丢失：如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险（未持久化）。")]),v._v(" "),s("li",[v._v("可能阻塞其他操作：AOF 日志其实也是在"),s("strong",[v._v("主线程")]),v._v("中执行（主进程中fork一个子进程AOF），所以当 Redis 把日志文件写入磁盘的时候，还是会"),s("strong",[v._v("阻塞")]),v._v("后续的操作无法执行。")])]),v._v(" "),s("h3",{attrs:{id:"q-rdb做快照时会阻塞线程吗"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-rdb做快照时会阻塞线程吗"}},[v._v("#")]),v._v(" Q：RDB做快照时会阻塞线程吗？")]),v._v(" "),s("p",[v._v("Redis 提供了两个命令，用于手动生成 "),s("strong",[v._v("RDB 快照文件")]),v._v("，分别是 "),s("code",[v._v("save")]),v._v(" 和 "),s("code",[v._v("bgsave")]),v._v("。")]),v._v(" "),s("ul",[s("li",[s("p",[s("code",[v._v("save")]),v._v(" ："),s("strong",[v._v("同步")]),v._v("命令，在主线程中执行，会导致"),s("strong",[v._v("阻塞")]),v._v("（因此快照时不能写）。")])]),v._v(" "),s("li",[s("p",[s("code",[v._v("bgsave")]),v._v(" ："),s("strong",[v._v("异步")]),v._v("命令，fork操作创建一个子进程，用于写入 RDB 文件的操作，避免了对主线程的阻塞：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("当主线程读，则主线程和 bgsave 子进程互相不影响；")])]),v._v(" "),s("li",[s("p",[v._v("当主线程写，被修改的数据会复制一份副本，然后 bgsave子进程会把副本数据写入 RDB 文件")])])])])]),v._v(" "),s("p",[v._v("此外还有自动触发命令 "),s("code",[v._v("sava m n")]),v._v("，表示m秒内数据集存在n次修改时，自动触发"),s("code",[v._v("bgsave")]),v._v("。")]),v._v(" "),s("h2",{attrs:{id:"_2-aof"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-aof"}},[v._v("#")]),v._v(" 2. AOF")]),v._v(" "),s("p",[v._v("AOF（append only file） 持久化，采用"),s("strong",[v._v("日志")]),v._v("记录每个操作命令，追加到文件中，重启时再重新执行 AOF 文件中的命令来恢复数据。它主要解决数据持久化的"),s("strong",[v._v("实时性")]),v._v("问题。")]),v._v(" "),s("p",[v._v("优点：数据的一致性和完整性更高。")]),v._v(" "),s("p",[v._v("缺点：实时写文件还是会损耗性能；AOF 记录的内容越多，文件越大，数据恢复变慢。")]),v._v(" "),s("p",[v._v("随着AOF文件会越来越大，为避免出现此种情况，新增了"),s("strong",[v._v("重写机制")]),v._v("。")]),v._v(" "),s("blockquote",[s("p",[v._v("重写机制：当AOF文件的大小超过所设定的阈值时， Redis就会启动AOF文件的内容"),s("strong",[v._v("压缩")]),v._v("，只保留可以恢复数据的最小指令集。")])]),v._v(" "),s("p",[v._v("AOF提供三种策略：")]),v._v(" "),s("ol",[s("li",[v._v("Always：每次写命令后，同步写AOF")]),v._v(" "),s("li",[v._v("Everysec：每次写明了先写入AOF文件的内核缓冲区，然后"),s("strong",[v._v("每秒")]),v._v("将缓冲区内容刷入磁盘")]),v._v(" "),s("li",[v._v("No："),s("strong",[v._v("默认")]),v._v("策略，相当于不开启AOF。不是由Redis控制刷盘时机，而是由"),s("strong",[v._v("操作系统")]),v._v("控制。")])]),v._v(" "),s("h2",{attrs:{id:"_3-混合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-混合"}},[v._v("#")]),v._v(" 3. 混合")]),v._v(" "),s("p",[v._v("Redis 4.0 后，增加了 AOF 和 RDB 混合的机制： 把数据以 RDB 的方式写入文件，再将后续的操作命令以 AOF 的格式存入文件，既保证了 Redis 重启速度，又降低数据丢失风险。")]),v._v(" "),s("p",[v._v("缺点是兼容性差，一旦开启了混合持久化，在4.0之前版本都不识别该混合文件，同时由于前部分是RDB格式，阅读性较差。")]),v._v(" "),s("h2",{attrs:{id:"比较"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#比较"}},[v._v("#")]),v._v(" 比较")]),v._v(" "),s("table",[s("thead",[s("tr",[s("th"),v._v(" "),s("th",[v._v("RDB")]),v._v(" "),s("th",[v._v("AOF")])])]),v._v(" "),s("tbody",[s("tr",[s("td",[v._v("使用时机")]),v._v(" "),s("td",[v._v("重启时")]),v._v(" "),s("td",[v._v("重启时")])]),v._v(" "),s("tr",[s("td",[v._v("记录时机")]),v._v(" "),s("td",[v._v("指定间隔")]),v._v(" "),s("td",[v._v("实时")])]),v._v(" "),s("tr",[s("td"),v._v(" "),s("td"),v._v(" "),s("td")])])]),v._v(" "),s("h1",{attrs:{id:"q-大key有什么问题-如何解决"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-大key有什么问题-如何解决"}},[v._v("#")]),v._v(" Q：大key有什么问题？如何解决？")]),v._v(" "),s("p",[v._v("大key指值或value特别大的键值对。对字符串类型，一般认为超过 10k 的就是 bigkey；对非字符串类型，体现在哈希，列表，集合类型的元素过多。")]),v._v(" "),s("h2",{attrs:{id:"_1、阻塞持久化"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1、阻塞持久化"}},[v._v("#")]),v._v(" 1、阻塞持久化")]),v._v(" "),s("p",[v._v("有两个阶段会导致阻塞父进程：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("创建子进程的过程中，由于要复制父进程的页表等数据结构，阻塞时间跟"),s("strong",[v._v("页表的大小")]),v._v("有关：页表越大，阻塞时间越长；")])]),v._v(" "),s("li",[s("p",[v._v("创建完子进程后，如果父进程修改了共享数据中的大 Key，就会发生写时复制，这期间会拷贝物理内存，由于大 Key 占用的物理内存很大，"),s("strong",[v._v("拷贝物理内存这一过程会比较耗时")]),v._v("，有可能会阻塞父进程。")]),v._v(" "),s("blockquote",[s("p",[v._v("AOF 重写机制和 RDB 快照（bgsave 命令）的过程，都会分别通过 "),s("code",[v._v("fork()")]),v._v(" 函数创建一个子进程来处理任务。")]),v._v(" "),s("p",[v._v("在创建子进程的过程中，操作系统会把父进程的「页表」复制一份给子进程，这个页表记录着虚拟地址和物理地址映射关系，而不会复制物理内存，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。")]),v._v(" "),s("p",[v._v("于是子进程就共享了父进程的物理内存数据了，这样能够"),s("strong",[v._v("节约物理内存资源")]),v._v("，页表对应的页表项的属性会标记该物理内存的权限为"),s("strong",[v._v("只读")]),v._v("。")]),v._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/Redis/06657cb93ffa4a24b8fc5b3069cb29bf.png",alt:"img"}}),v._v(" "),s("p",[v._v("随着Redis存在越来越多的大 Key，占用内存也会增大，对应的页表就会越大。在通过 "),s("code",[v._v("fork()")]),v._v(" 函数创建子进程的时候，虽然不会复制父进程的物理内存，但是"),s("strong",[v._v("内核会把父进程的页表复制一份给子进程，如果页表很大，那么这个复制过程是会很耗时的，那么在执行 fork 函数的时候就会发生阻塞现象")]),v._v("。")]),v._v(" "),s("p",[v._v("而"),s("code",[v._v("fork()")]),v._v("是由 Redis 主线程调用的，如果 fork 发生阻塞，那么意味着就会阻塞 Redis 主线程，进而阻塞客户端。")]),v._v(" "),s("p",[v._v("何时发生物理内存的复制？")]),v._v(" "),s("p",[v._v("当父进程或者子进程在向共享内存发起写操作时，CPU 就会触发"),s("strong",[v._v("写保护中断")]),v._v("，这个「写保护中断」是由于违反权限导致的，然后操作系统会在「写保护中断处理函数」里进行物理内存的复制，并重新设置其内存映射关系，将父子进程的内存读写权限设置为可读写，最后才会对内存进行写操作，这个过程被称为"),s("strong",[v._v("写时复制(Copy On Write)")]),v._v("。\n写时复制顾名思义，在发生写操作的时候，操作系统才会去复制物理内存，这样是为了防止 fork 创建子进程时，由于物理内存数据的复制时间过长，而导致父进程长时间阻塞的问题。")]),v._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/Redis/451024fe10374431aff6f93a8fed4638.png",alt:"img"}})])])]),v._v(" "),s("p",[v._v("用"),s("code",[v._v("info")]),v._v(" 命令可以获取到 latest_fork_usec 指标，表示 Redis 最近一次 fork 操作耗时。")]),v._v(" "),s("div",{staticClass:"language-sql line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-sql"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("# 最近一次 fork 操作耗时（ms）")]),v._v("\nlatest_fork_usec:"),s("span",{pre:!0,attrs:{class:"token number"}},[v._v("315")]),v._v("\n")])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br"),s("span",{staticClass:"line-number"},[v._v("2")]),s("br")])]),s("p",[v._v("如果 fork 耗时很大，比如超过1秒，则需要做出优化调整：")]),v._v(" "),s("ul",[s("li",[v._v("单个实例的内存占用控制在 10 GB 以下，这样 fork 函数就能很快返回。")]),v._v(" "),s("li",[v._v("如果 Redis 只是当作纯缓存使用，不关心 Redis 数据安全性问题，可以考虑关闭 AOF 和 AOF 重写，这样就不会调用 fork 函数了。")]),v._v(" "),s("li",[v._v("在主从架构中，要适当调大 repl-backlog-size，避免因为 repl_backlog_buffer 不够大，导致主节点频繁地使用全量同步的方式，全量同步的时候，是会创建 RDB 文件的，也就是会调用 fork 函数。")])]),v._v(" "),s("h2",{attrs:{id:"_2、阻塞线程-导致客户端超时。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2、阻塞线程-导致客户端超时。"}},[v._v("#")]),v._v(" 2、阻塞线程，导致客户端超时。")]),v._v(" "),s("p",[v._v("由于 Redis 执行命令是单线程处理，操作大 key （增删改）比较耗时，会阻塞 Redis 工作线程。对客户端而言，将长时间没有响应。")]),v._v(" "),s("h2",{attrs:{id:"_3、引发网络阻塞。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3、引发网络阻塞。"}},[v._v("#")]),v._v(" 3、引发网络阻塞。")]),v._v(" "),s("p",[v._v("每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。")]),v._v(" "),s("h2",{attrs:{id:"_4、内存分布不均。"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4、内存分布不均。"}},[v._v("#")]),v._v(" 4、内存分布不均。")]),v._v(" "),s("p",[v._v("集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。")]),v._v(" "),s("h2",{attrs:{id:"解决办法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#解决办法"}},[v._v("#")]),v._v(" 解决办法")]),v._v(" "),s("ol",[s("li",[v._v("设计阶段把大 key 拆分成一个一个小 key。")]),v._v(" "),s("li",[v._v("定时检查 Redis 是否存在大 key ，如果该大 key 是可以删除的，不要使用 DEL 命令（因为该命令会阻塞主线程），而是用 "),s("strong",[v._v("unlink")]),v._v(" 命令（Redis 4.0+）删除大 key（因为该命令的删除过程是异步的，不会阻塞主线程）")]),v._v(" "),s("li",[v._v("实在无法避免大key，用java自带的GZIPOutputStream对字符进行压缩（String转byte[])，读取时用GZIPInputStream解压")])]),v._v(" "),s("h1",{attrs:{id:"主从复制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#主从复制"}},[v._v("#")]),v._v(" 主从复制")]),v._v(" "),s("p",[v._v("是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master/leader)，后者称为从节点(slave/follower)；")]),v._v(" "),s("p",[v._v("数据的复制是"),s("strong",[v._v("单向")]),v._v("的，只能由主节点到从节点。")]),v._v(" "),s("p",[v._v("Master可写可读，Slave 只能读。")]),v._v(" "),s("h2",{attrs:{id:"优点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#优点"}},[v._v("#")]),v._v(" 优点")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。")])]),v._v(" "),s("li",[s("p",[v._v("故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务冗余。")])]),v._v(" "),s("li",[s("p",[v._v("负载均衡：在主从复制的基础上，配合"),s("strong",[v._v("读写分离")]),v._v("（即写主节点，读从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis集群的并发量。")])]),v._v(" "),s("li",[s("p",[v._v("高可用基石：除了上述作用以外，主从复制还是"),s("strong",[v._v("哨兵和集群")]),v._v("能够实施的基础，因此说主从复制是Redis高可用的基础。")])])]),v._v(" "),s("h2",{attrs:{id:"典型架构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#典型架构"}},[v._v("#")]),v._v(" 典型架构")]),v._v(" "),s("ol",[s("li",[v._v("一主多从，一对多。")])]),v._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"images\\Redis\\GetImage.png",alt:"GetImage"}}),v._v(" "),s("ol",{attrs:{start:"2"}},[s("li",[v._v("特殊的"),s("strong",[v._v("链式")]),v._v("架构，中间的结点整体作为从机，但同时也是最右边从机的主机。")])]),v._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"images\\Redis\\GetImage-16442891132211.png",alt:"GetImage"}}),v._v(" "),s("h2",{attrs:{id:"复制原理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#复制原理"}},[v._v("#")]),v._v(" 复制原理")]),v._v(" "),s("p",[v._v("Slave 启动成功连接到 master 后会发送一个sync命令")]),v._v(" "),s("p",[v._v("Master 接到命令，启动后台的存盘进程，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个数据文件到slave，并完成一次完全同步。")]),v._v(" "),s("p",[v._v("全量复制：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中。")]),v._v(" "),s("p",[v._v("增量复制：Master 继续将新的所有收集到的修改命令依次传给slave，完成同步。")]),v._v(" "),s("p",[v._v("但是只要是重新连接master，一次完全同步（全量复制）将被自动执行")]),v._v(" "),s("h2",{attrs:{id:"哨兵模式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#哨兵模式"}},[v._v("#")]),v._v(" 哨兵模式")]),v._v(" "),s("p",[v._v("主从切换的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，需要人工干预，不推荐。Redis2.8开始正式提供了Sentinel（哨兵） 架构来解决这个问题。")]),v._v(" "),s("p",[v._v("哨兵是一个"),s("strong",[v._v("独立的进程")]),v._v("。通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。")]),v._v(" "),s("p",[v._v("哨兵有两个作用：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("通过发送命令，让Redis服务器返回其运行状态，包括主服务器和从服务器。")])]),v._v(" "),s("li",[s("p",[v._v("当哨兵监测到master宕机，会根据"),s("strong",[v._v("投票算法")]),v._v("，自动决定将哪个slave切换成master，然后通过"),s("strong",[v._v("发布订阅模式")]),v._v("通知其他的从服务器，修改配置文件，让它们切换主机。之前的master恢复后，也只能做slave。")])])]),v._v(" "),s("p",[v._v("缺点：只有一个哨兵，网络出问题时可能会误判。")]),v._v(" "),s("p",[v._v("解决：部署多个哨兵，每间隔一段时间，询问 master 是否正常。一旦有某个哨兵判定 master 异常，哨兵之间发起协商判定master是否真的异常。通过"),s("strong",[v._v("共识算法")]),v._v("（Raft）选举新master。")]),v._v(" "),s("blockquote",[s("p",[v._v("共识算法：分布式系统中多个节点如何就一个问题达成共识的算法，如 Paxos、Raft。")])]),v._v(" "),s("img",{staticStyle:{zoom:"67%"},attrs:{src:"images/Redis/640-1689529039407-6.jpeg",alt:"图片"}}),v._v(" "),s("h2",{attrs:{id:"实战"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#实战"}},[v._v("#")]),v._v(" 实战")]),v._v(" "),s("p",[s("strong",[v._v("主要配置")])]),v._v(" "),s("p",[v._v("编辑sentinel.conf 文件")]),v._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[v._v('# 哨兵sentinel监控的redis主节点的 ip port\n# master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符".-_"组成。\n# quorum 配置多少个sentinel哨兵统一认为master主节点失联 那么这时客观上认为主节点失联了\n# sentinel monitor <master-name> <ip> <redis-port> <quorum>\nsentinel monitor mymaster 127.0.0.1 6379 2\n')])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br"),s("span",{staticClass:"line-number"},[v._v("2")]),s("br"),s("span",{staticClass:"line-number"},[v._v("3")]),s("br"),s("span",{staticClass:"line-number"},[v._v("4")]),s("br"),s("span",{staticClass:"line-number"},[v._v("5")]),s("br")])]),s("p",[s("strong",[v._v("启动")])]),v._v(" "),s("p",[v._v("linux下，使用命令（sentinel.conf是配置文件名，可自定义）：")]),v._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[v._v("$ redis-sentinel sentinel.conf \n")])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br")])]),s("h1",{attrs:{id:"redis集群"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#redis集群"}},[v._v("#")]),v._v(" Redis集群")]),v._v(" "),s("p",[v._v("Redis Cluster 是一种分布式去中心化的运行模式，是Redis 3.0 版本中推出，集群由多个redis节点组成，它将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖，从而提高 Redis 服务的读写性能。")]),v._v(" "),s("p",[v._v("Redis集群系统满足"),s("strong",[v._v("CAP理论中的CP")]),v._v("，cp系统还有zookeeper。")]),v._v(" "),s("h2",{attrs:{id:"集群的演进"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群的演进"}},[v._v("#")]),v._v(" 集群的演进")]),v._v(" "),s("p",[v._v("一个实例扛不住写压力，那我们是否可以部署多个实例，然后把这些实例按照一定规则组织起来，把它们当成一个整体，对外提供服务，这样不就可以解决集中写一个实例的瓶颈。")]),v._v(" "),s("p",[v._v("为了组织这些实例，我们制定规则如下：")]),v._v(" "),s("ol",[s("li",[v._v("每个节点各自存储一部分数据，所有节点数据之和才是全量数据")]),v._v(" "),s("li",[v._v("制定一个路由规则，对于不同的 key，把它路由到固定一个实例上进行读写")])]),v._v(" "),s("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/Redis/640-1689529270931-8.jpeg",alt:"图片"}}),v._v(" "),s("p",[v._v("这种方案也叫做「客户端分片」，缺点是，"),s("strong",[v._v("客户端需要维护这个路由规则，你需要把路由规则写到你的业务代码中。")])]),v._v(" "),s("p",[v._v("优化：加proxy层，维护路由规则，客户端就无需关心服务端有多少个 Redis 节点了，只需要和这个 Proxy 交互即可。开源方案：Twemproxy、Codis 。")]),v._v(" "),s("img",{staticStyle:{zoom:"67%"},attrs:{src:"images/Redis/640-1689529362444-11.jpeg",alt:"图片"}}),v._v(" "),s("p",[v._v("直到Redis 3.0 ，官方推出了解决方案：Redis Cluster，无需部署哨兵集群，集群内 Redis 节点通过 "),s("strong",[v._v("Gossip 协议")]),v._v("互相探测健康状态，在故障时可发起自动切换。路由转发规则也不需要客户端自己维护，使用SDK即可。")]),v._v(" "),s("h2",{attrs:{id:"如何确定节点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#如何确定节点"}},[v._v("#")]),v._v(" 如何确定节点")]),v._v(" "),s("p",[v._v("使用"),s("strong",[v._v("类一致性哈希算法")]),v._v("。Redis Cluster将自己分成了"),s("strong",[v._v("16384")]),v._v("个Slot（槽位），哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。集群模式不再分多db，只使用一个db0")]),v._v(" "),s("p",[v._v("计算方式：")]),v._v(" "),s("ol",[s("li",[v._v("根据键值对的 key，按照 CRC16 算法计算一个 16 bit 的值。")]),v._v(" "),s("li",[v._v("再用 16bit 值对 16384 取模，结果就是该key对应的哈希槽。")])]),v._v(" "),s("p",[v._v("每个Redis节点负责处理一部分槽位，加入你有三个master节点 ABC，每个节点负责的槽位如下：节点A：0-5000，节点B：5001-10000，节点C：10001-16383")]),v._v(" "),s("h2",{attrs:{id:"集群脑裂"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#集群脑裂"}},[v._v("#")]),v._v(" 集群脑裂")]),v._v(" "),s("p",[v._v("因为网络问题，导致 Redis master 节点跟 slave 节点和 sentinel 集群处于不同的网络分区，因为 sentinel 集群无法感知到 master 的存在，所以将 slave 节点提升为 master 节点，此时存在"),s("strong",[v._v("两个")]),v._v("不同的 master 节点。Redis Cluster 集群部署方式同理。")]),v._v(" "),s("img",{staticStyle:{zoom:"67%"},attrs:{src:"images/Redis/redis-lock-08.png",alt:"img"}}),v._v(" "),s("h1",{attrs:{id:"淘汰策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#淘汰策略"}},[v._v("#")]),v._v(" 淘汰策略")]),v._v(" "),s("p",[v._v("由前面我们知道redis放内存，然而内存是有限的，"),s("strong",[v._v("内存满")]),v._v("时就会执行淘汰（回收）")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("no-eviction：不删除")])]),v._v(" "),s("li",[s("p",[v._v("allkeys-lru")])]),v._v(" "),s("li",[s("p",[v._v("volatile-lru")])]),v._v(" "),s("li",[s("p",[v._v("allkeys-random")])]),v._v(" "),s("li",[s("p",[v._v("volatile-random")])]),v._v(" "),s("li",[s("p",[v._v("volatile-ttl：从已设置过期时间的哈希表中随机挑选多个 Key，然后选择"),s("strong",[v._v("剩余时间最短")]),v._v("的数据淘汰掉")])])]),v._v(" "),s("p",[s("strong",[v._v("Redis 4.0后增加以下两种")]),v._v("：")]),v._v(" "),s("ol",{attrs:{start:"7"}},[s("li",[s("p",[v._v("volatile-lfu：从已设置过期时间的数据集中挑选最不经常使用的数据淘汰算法，也就是最频繁被访问的数据将来最有可能被访问到)")])]),v._v(" "),s("li",[s("p",[v._v("allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。")])])]),v._v(" "),s("p",[v._v("说明：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("allkeys前缀：从所有 Key 的数据集（"),s("code",[v._v("server.db[i].dict")]),v._v("）中挑选")])]),v._v(" "),s("li",[s("p",[v._v("volatile前缀：从已设置过期时间的数据集（"),s("code",[v._v("server.db[i].expires")]),v._v("）中挑选")])]),v._v(" "),s("li",[s("p",[v._v("带-lru后缀的：先随机挑，再从挑出的用"),s("strong",[v._v("lru算法")]),v._v("（Least Recently Used）淘汰最近最少使用")])]),v._v(" "),s("li",[s("p",[v._v("带-random后缀的：直接随机")])]),v._v(" "),s("li",[s("p",[v._v("带-lfu后缀的：先随机挑，再从挑出的用lfu算法(Least Frequently Used)淘汰最不经常使用")])])]),v._v(" "),s("h1",{attrs:{id:"q-如何实现定时机制"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-如何实现定时机制"}},[v._v("#")]),v._v(" Q：如何实现定时机制？")]),v._v(" "),s("p",[v._v("Redis server是"),s("strong",[v._v("事件驱动")]),v._v("的程序，要处理两种事件：")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("文件事件：server对"),s("strong",[v._v("socket")]),v._v("的抽象")])]),v._v(" "),s("li",[s("p",[v._v("时间事件：server对"),s("strong",[v._v("定时操作")]),v._v("的抽象")])])]),v._v(" "),s("p",[v._v("定时机制通过"),s("strong",[v._v("时间事件")]),v._v("实现，由三个属性组成：")]),v._v(" "),s("ol",[s("li",[v._v("id：时间事件标识")]),v._v(" "),s("li",[v._v("when：记录时间事件的到达时刻")]),v._v(" "),s("li",[v._v("timeProc：时间事件处理器")])]),v._v(" "),s("h1",{attrs:{id:"过期删除策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#过期删除策略"}},[v._v("#")]),v._v(" 过期删除策略")]),v._v(" "),s("p",[v._v("redis数据可以设定过期时间，到期后执行删除。Redis的过期删除策略是："),s("strong",[v._v("惰性删除")]),v._v(" 和 "),s("strong",[v._v("定期删除")]),v._v("，两种策略配合使用。")]),v._v(" "),s("ol",[s("li",[s("p",[v._v("（"),s("strong",[v._v("被动")]),v._v("触发）惰性删除：由"),s("code",[v._v("db.c/expireIfNeeded")]),v._v("函数实现，所有键读写命令执行之前都会调用 "),s("code",[v._v("expireIfNeeded")]),v._v("函数对其进行检查，如果过期，则删除该键，然后执行键不存在的操作；未过期则不作操作，继续执行原有的命令。")]),v._v(" "),s("p",[v._v("优点：节省计算资源")]),v._v(" "),s("p",[v._v("缺点：占用内存大，若某个key已过期却一直未读写，则一直存在")])]),v._v(" "),s("li",[s("p",[v._v("（"),s("strong",[v._v("主动")]),v._v("触发）定期删除：由"),s("code",[v._v("Redis.c/activeExpireCycle")]),v._v(" 函数实现，函数以一定的频率运行，每次运行时，都从一定数量的数据库中取出一定数量的"),s("strong",[v._v("随机键")]),v._v("进行检查，并删除其中的过期键。")]),v._v(" "),s("p",[v._v("优点：有效释放过期key占用内存")]),v._v(" "),s("p",[v._v("缺点：计算开销大，而且触发的时机难以确定（每个key的过期时间不一样，如何定批处理时机？）")])]),v._v(" "),s("li",[s("p",[v._v("（"),s("strong",[v._v("主动")]),v._v("触发）定时删除：对每个设置过期时间的key，都创建一个定时器")]),v._v(" "),s("p",[v._v("缺点：计算开销很大")])])]),v._v(" "),s("h1",{attrs:{id:"q-如何实现分布式锁"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-如何实现分布式锁"}},[v._v("#")]),v._v(" Q：如何实现分布式锁")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("加锁：用一个唯一标识做key，uuid做value（区分加锁者，解锁要用）")]),v._v(" "),s("p",[v._v("1）先用setnx命令设置k-v")]),v._v(" "),s("p",[v._v("2）再设置锁过期时间：EXPIRE key timeout，避免资源被永远锁住。")]),v._v(" "),s("p",[v._v("两条都成功则说明加锁成功。失败则说明key被其他客户端占用，轮询等待。")]),v._v(" "),s("p",[v._v("然而这两条命令不是原子的，高并发环境会出问题。用lua脚本执行两条命令，保证原子性")]),v._v(" "),s("p",[s("strong",[v._v("注意")])]),v._v(" "),s("p",[v._v("redis2.6.12版本增加新命令，一条就可以完成")]),v._v(" "),s("div",{staticClass:"language- line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[v._v("SET product:10001 true EX 10 NX  // 当且仅当product:10001不存在时，设product:10001值为true，10秒过期\n")])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br")])])]),v._v(" "),s("li",[s("p",[v._v("解锁：传入k、v，用k查询redis得到v1，判断v1==v？如果相等，说明是同一个客户端上的锁，可以解锁；若不相等不能解锁。解锁操作就是del key。")]),v._v(" "),s("p",[v._v("del key之前需要看key是否存在，然后再用del命令删，redis没有执行这两个功能的命令，必须用lua脚本保证原子性：")]),v._v(" "),s("div",{staticClass:"language-lua line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-lua"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("if")]),v._v(" redis"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[v._v("call")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[v._v("'get'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(",")]),v._v(" KEYS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[v._v("==")]),v._v(" ARGV"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),v._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("then")]),v._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("return")]),v._v(" redis"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[v._v("call")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[v._v("'del'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(",")]),v._v(" KEYS"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("[")]),s("span",{pre:!0,attrs:{class:"token number"}},[v._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),v._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("else")]),v._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("return")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[v._v("0")]),v._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[v._v("end")]),v._v("\n")])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br"),s("span",{staticClass:"line-number"},[v._v("2")]),s("br"),s("span",{staticClass:"line-number"},[v._v("3")]),s("br"),s("span",{staticClass:"line-number"},[v._v("4")]),s("br"),s("span",{staticClass:"line-number"},[v._v("5")]),s("br"),s("span",{staticClass:"line-number"},[v._v("6")]),s("br")])])]),v._v(" "),s("li",[s("p",[v._v("锁续期：开一个定时任务，在分线程里检查主线程的锁（key）是否还存在，存在则续期。")])])]),v._v(" "),s("h1",{attrs:{id:"缓存穿透问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#缓存穿透问题"}},[v._v("#")]),v._v(" 缓存穿透问题")]),v._v(" "),s("p",[v._v("用户短时间内频繁的请求"),s("strong",[v._v("一定不存在")]),v._v("的数据（一定未命中redis），这些请求必然直接落在"),s("strong",[v._v("数据库")]),v._v("上，导致数据库性能急剧下降，最终影响服务整体的性能。")]),v._v(" "),s("p",[v._v("这个在实际项目很容易遇到，如抢购活动、秒杀活动的接口 API 被大量的恶意用户刷，导致短时间内数据库宕机。")]),v._v(" "),s("p",[s("strong",[v._v("解决方案")])]),v._v(" "),s("ol",[s("li",[s("p",[v._v("给不存在的数据（作为key）缓存一个自定义的"),s("strong",[v._v("空值")]),v._v("（什么值无所谓，有value就行）。下次读到这个空值就知道数据不存在，顶多查redis，不会查db。")])]),v._v(" "),s("li",[s("p",[v._v("使用分布式互斥锁排队。当从缓存中获取数据失败时，给当前接口加上锁，从数据库中加载完数据并写入后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。")]),v._v(" "),s("blockquote",[s("p",[v._v("该方式将高并发压力从db转移到分布式锁，对分布式锁考验很大。")]),v._v(" "),s("p",[v._v("再优化：集群扩容、二级缓存等")])])]),v._v(" "),s("li",[s("p",[v._v("使用"),s("strong",[v._v("布隆过滤器")]),v._v("。将所有可能存在的key放到布隆过滤器中，先过滤掉肯定不存在的key，之后再走缓存和DB。")]),v._v(" "),s("blockquote",[s("p",[v._v("但还是有缺点：无法保证过滤器包含所有key，并不能完全过滤不存在的key。")])])])]),v._v(" "),s("blockquote",[s("p",[s("strong",[v._v("布隆过滤器")])]),v._v(" "),s("p",[v._v("是一种数据结构，对所有可能查询的参数以hash形式存储，可以高效地判断某个元素"),s("strong",[v._v("一定不存在或有概率存在")]),v._v("。")]),v._v(" "),s("p",[v._v("实际使用时在Controller先用布隆过滤器进行校验，一定不存在的直接丢弃，从而避免了对底层存储系统的查询压力；")]),v._v(" "),s("p",[s("img",{attrs:{src:"images/Redis/%E6%9C%AA%E5%91%BD%E5%90%8D%E5%9B%BE%E7%89%87.png",alt:"未命名图片"}})])]),v._v(" "),s("h1",{attrs:{id:"缓存雪崩问题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#缓存雪崩问题"}},[v._v("#")]),v._v(" 缓存雪崩问题")]),v._v(" "),s("p",[v._v("在短时间内有大量缓存失效。")]),v._v(" "),s("p",[v._v("如果这期间有大量的请求发生，大量查询直接请求db也有可能导致db宕机。")]),v._v(" "),s("p",[v._v("在 Redis 集群的数据分布算法上如果使用的是传统的 hash 取模，在增加或移除 Redis 节点的时候就会出现大量的缓存失效的情形。")]),v._v(" "),s("p",[s("strong",[v._v("解决方案")])]),v._v(" "),s("ol",[s("li",[s("p",[v._v("某个key失效时，像解决缓存穿透一样加分布式锁排队。")])]),v._v(" "),s("li",[s("p",[v._v("加机器。建立备份缓存A和B，A 设置超时时间，B 不设值超时时间，先从 A 读缓存，A 没有读 B，并且更新 A 缓存和 B 缓存。")])]),v._v(" "),s("li",[s("p",[v._v("计算数据缓存节点的时候采用"),s("strong",[v._v("一致性hash")]),v._v(" 算法，这样在节点数量发生改变时不会存在大量的缓存数据需要迁移的情况发生。")])]),v._v(" "),s("li",[s("p",[v._v("数据"),s("strong",[v._v("预热")]),v._v("（本质是使过期时间分散）")]),v._v(" "),s("p",[v._v("在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间。")]),v._v(" "),s("p",[v._v("或者给缓存失效的时间取随机值。")])])]),v._v(" "),s("h1",{attrs:{id:"q-如何保证双写一致性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-如何保证双写一致性"}},[v._v("#")]),v._v(" Q：如何保证双写一致性？")]),v._v(" "),s("p",[v._v("双写一致性：缓存和数据库一致。")]),v._v(" "),s("p",[v._v("要保证缓存一致性需要付出很大的代价，缓存数据最好是那些对一致性要求不高的数据，允许缓存数据存在一些脏数据。")]),v._v(" "),s("h2",{attrs:{id:"常用方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#常用方案"}},[v._v("#")]),v._v(" "),s("strong",[v._v("常用方案")])]),v._v(" "),s("p",[v._v("查询时先查缓存，没有才查库，并用库数据更新缓存。数据库更新（或删除）时删缓存，并且先更新库，再删缓存。")]),v._v(" "),s("p",[v._v("优点：实现简单")]),v._v(" "),s("p",[v._v("缺点：查库与更新缓存不是原子操作，若查库后库又更新了，则写入的缓存不是最新的。同理数据库更新和删缓存也不是原子操作。这会导致数据库和缓存有概率不一致。")]),v._v(" "),s("h3",{attrs:{id:"q-为什么先更新库再删缓存"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-为什么先更新库再删缓存"}},[v._v("#")]),v._v(" Q：为什么先更新库再删缓存？")]),v._v(" "),s("p",[v._v("考虑 2 个线程并发「读写」数据：")]),v._v(" "),s("ol",[s("li",[v._v("缓存中 X 不存在（数据库 X = 1）")]),v._v(" "),s("li",[v._v("线程 A 读取数据库，得到旧值（X = 1）")]),v._v(" "),s("li",[v._v("线程 B 更新数据库（X = 2)")]),v._v(" "),s("li",[v._v("线程 B 删除缓存")]),v._v(" "),s("li",[v._v("线程 A 将旧值写入缓存（X = 1）")])]),v._v(" "),s("p",[v._v("最终 X 的值在缓存中是 1（旧值），在数据库中是 2（新值），产生不一致。")]),v._v(" "),s("p",[v._v("这种情况「理论」来说是可能发生的，但其实概率「很低」，这是因为它必须满足 3 个条件：")]),v._v(" "),s("ol",[s("li",[v._v("缓存刚好已失效")]),v._v(" "),s("li",[v._v("读请求 + 写请求并发")]),v._v(" "),s("li",[v._v("更新数据库 + 删除缓存的时间（步骤 3-4），要比读数据库 + 写缓存时间短（步骤 2 和 5）。这种概率极低，一般第4步要晚于第5步，此时数据库是2（新值），且缓存删除，未产生不一致。")])]),v._v(" "),s("p",[v._v("若要完全避免不一致，只能采用最终一致性，用延迟双删，")]),v._v(" "),s("h2",{attrs:{id:"最终一致性方案"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#最终一致性方案"}},[v._v("#")]),v._v(" 最终一致性方案")]),v._v(" "),s("p",[v._v("要保证严格一致性，只能采用"),s("strong",[v._v("最终一致性")]),v._v("。")]),v._v(" "),s("h3",{attrs:{id:"_1-延迟双删"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-延迟双删"}},[v._v("#")]),v._v(" 1) 延迟双删")]),v._v(" "),s("p",[v._v("基于上面的"),s("strong",[v._v("先更新库再删缓存")]),v._v("方案。若删缓存失败，则定时重试（即"),s("strong",[v._v("延迟双删")]),v._v("）。但要注意延迟时间的设置，要大于「主从复制」的延迟时间，且大于线程 B 读取数据库 + 写入缓存的时间，考虑到如下情况：")]),v._v(" "),s("ol",[s("li",[v._v("线程 A 更新主库 X = 2（原值 X = 1）")]),v._v(" "),s("li",[v._v("线程 A 删除缓存")]),v._v(" "),s("li",[v._v("线程 B 查询缓存，没有命中，查询「从库」得到旧值（从库 X = 1）")]),v._v(" "),s("li",[v._v("从库「同步」完成（主从库 X = 2）")]),v._v(" "),s("li",[v._v("线程 B 将「旧值」写入缓存（X = 1）。")])]),v._v(" "),s("h4",{attrs:{id:"q-延迟双删后如果有查询请求需要写缓存怎么办"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-延迟双删后如果有查询请求需要写缓存怎么办"}},[v._v("#")]),v._v(" "),s("strong",[v._v("Q：延迟双删后如果有查询请求需要写缓存怎么办？")])]),v._v(" "),s("p",[v._v("因为延迟双删最终目的是保证缓存删掉，所以即使延迟过程中有其他写请求也不影响，最后删掉就行。")]),v._v(" "),s("h4",{attrs:{id:"改进-基于mq的异步重试"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#改进-基于mq的异步重试"}},[v._v("#")]),v._v(" 改进：基于mq的异步重试")]),v._v(" "),s("p",[v._v("将删缓存请求发送mq事务消息，由消费者完成删缓存。")]),v._v(" "),s("p",[s("strong",[v._v("Q：为什么要异步？")])]),v._v(" "),s("p",[v._v("同步重试会一直「占用」这个线程资源，无法服务其它客户端请求，影响吞吐量。优点：利用消息队列的可靠性（不丢失）保证投递。")]),v._v(" "),s("h3",{attrs:{id:"_2-订阅变更日志"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-订阅变更日志"}},[v._v("#")]),v._v(" 2) 订阅变更日志")]),v._v(" "),s("p",[v._v("通过Canal组件，监控Mysql中binlog的日志，把更新后的数据同步到Redis（也可以照上面发mq操作）")]),v._v(" "),s("p",[v._v("优点：")]),v._v(" "),s("ul",[s("li",[v._v("无需考虑写消息队列失败情况：只要写 MySQL 成功，Binlog 肯定会有；")]),v._v(" "),s("li",[v._v("自动投递到下游队列：canal 自动把数据库变更日志「投递」给下游的消息队列")])]),v._v(" "),s("p",[v._v("缺点：需要投入精力去维护 canal 的高可用和稳定性")]),v._v(" "),s("h3",{attrs:{id:"_3-加锁保证强一致"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-加锁保证强一致"}},[v._v("#")]),v._v(" 3) 加锁保证强一致")]),v._v(" "),s("p",[v._v("查库和写缓存、库更新和删缓存，这个过程都加redis锁保证原子性")]),v._v(" "),s("p",[v._v("优点：极端情况下也完全一致")]),v._v(" "),s("p",[v._v("缺点：损失性能")]),v._v(" "),s("h3",{attrs:{id:"_4-分布式协议保证强一致"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-分布式协议保证强一致"}},[v._v("#")]),v._v(" 4) 分布式协议保证强一致")]),v._v(" "),s("p",[v._v("2PC、3PC、Paxos、Raft")]),v._v(" "),s("h1",{attrs:{id:"q-如何实现数据冷热分离"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#q-如何实现数据冷热分离"}},[v._v("#")]),v._v(" Q：如何实现数据冷热分离？")]),v._v(" "),s("p",[v._v("例：对于用户信息user，写库时写一份redis，过期时间一天。查询时对每个key，先查redis，有则返回，并给key延期； 没有再查库，并写redis")]),v._v(" "),s("h1",{attrs:{id:"各种用到缓存思想的场景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#各种用到缓存思想的场景"}},[v._v("#")]),v._v(" 各种用到缓存思想的场景")]),v._v(" "),s("p",[s("strong",[v._v("浏览器")]),v._v("\n当 HTTP 响应允许进行缓存时，浏览器会将 HTML、CSS、JavaScript、图片等静态资源进行缓存。")]),v._v(" "),s("p",[s("strong",[v._v("ISP")]),v._v("\n网络服务提供商（ISP）是网络访问的第一跳，通过将数据缓存在 ISP 中能够大大提高用户的访问速度。")]),v._v(" "),s("p",[s("strong",[v._v("反向代理")]),v._v("\n反向代理位于服务器之前，请求与响应都需要经过反向代理。通过将数据缓存在反向代理，在用户请求反向代理时就可以直接使用缓存进行响应。")]),v._v(" "),s("p",[s("strong",[v._v("本地缓存")]),v._v("\n使用 Guava Cache 将数据缓存在服务器本地内存中，服务器代码可以直接读取本地内存中的缓存，速度非常快。")]),v._v(" "),s("p",[s("strong",[v._v("分布式缓存")]),v._v("\n使用 Redis、Memcache 等分布式缓存将数据缓存在分布式缓存系统中。")]),v._v(" "),s("p",[v._v("相对于本地缓存来说，分布式缓存单独部署，可以根据需求分配硬件资源。不仅如此，服务器集群都可以访问分布式缓存，而本地缓存需要在服务器集群之间进行同步，实现难度和性能开销上都非常大。")]),v._v(" "),s("p",[s("strong",[v._v("数据库缓存")]),v._v("\nMySQL 等数据库管理系统具有自己的查询缓存机制来提高查询效率。")]),v._v(" "),s("p",[s("strong",[v._v("Java 内部的缓存")]),v._v("\nJava 为了优化空间，提高字符串、基本数据类型包装类的创建效率，设计了字符串常量池及 Byte、Short、Character、Integer、Long、Boolean 这六种包装类缓冲池。")]),v._v(" "),s("p",[s("strong",[v._v("CPU 多级缓存")]),v._v("\nCPU 为了解决运算速度与主存 IO 速度不匹配的问题，引入了多级缓存结构，同时使用 MESI 等缓存一致性协议来解决多核 CPU 缓存数据一致性的问题。")]),v._v(" "),s("h1",{attrs:{id:"redis与memcached比较"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#redis与memcached比较"}},[v._v("#")]),v._v(" Redis与Memcached比较")]),v._v(" "),s("table",[s("thead",[s("tr",[s("th"),v._v(" "),s("th",[v._v("Redis")]),v._v(" "),s("th",[v._v("Memcached")])])]),v._v(" "),s("tbody",[s("tr",[s("td",[v._v("数据类型")]),v._v(" "),s("td",[v._v("多种")]),v._v(" "),s("td",[v._v("只有字符串")])]),v._v(" "),s("tr",[s("td",[v._v("持久化")]),v._v(" "),s("td",[v._v("有")]),v._v(" "),s("td",[v._v("无")])]),v._v(" "),s("tr",[s("td",[v._v("网络IO模型")]),v._v(" "),s("td",[v._v("单线程的多路 IO 复用")]),v._v(" "),s("td",[v._v("多线程的非阻塞IO")])])])]),v._v(" "),s("h1",{attrs:{id:"jcs"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#jcs"}},[v._v("#")]),v._v(" JCS")]),v._v(" "),s("p",[v._v("本地缓存")]),v._v(" "),s("p",[v._v("主要实现类：package org.apache.jcs下，JCS类")]),v._v(" "),s("p",[v._v("配置文件：cache.ccf")]),v._v(" "),s("p",[v._v("主要api：")]),v._v(" "),s("div",{staticClass:"language-java line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[s("span",{pre:!0,attrs:{class:"token class-name"}},[v._v("JCS")]),v._v(" cache "),s("span",{pre:!0,attrs:{class:"token operator"}},[v._v("=")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[v._v("JCS")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[v._v("getInstance")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("//获取缓存实例")]),v._v("\ncache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[v._v("get")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("// 用key查询元素")]),v._v("\ncache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[v._v("put")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v("(")]),v._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(",")]),v._v(" ele"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[v._v(";")]),v._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[v._v("// 放入元素")]),v._v("\n")])]),v._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[v._v("1")]),s("br"),s("span",{staticClass:"line-number"},[v._v("2")]),s("br"),s("span",{staticClass:"line-number"},[v._v("3")]),s("br")])]),s("p",[s("strong",[v._v("优点")])]),v._v(" "),s("ol",[s("li",[v._v("缓存和应用在同一个进程（本地）内，请求缓存非常快，"),s("strong",[v._v("没有网络开销")]),v._v("。")]),v._v(" "),s("li",[v._v("轻量级，几乎不依赖其他库。")])]),v._v(" "),s("p",[s("strong",[v._v("缺点")])]),v._v(" "),s("ol",[s("li",[v._v("不适用于存在分布式事务的系统。")]),v._v(" "),s("li",[v._v("缓存跟应用程序耦合性较高。")]),v._v(" "),s("li",[v._v("分布式的支持较简单，不适合特别大型的分布式项目。")])])])}),[],!1,null,null,null);s.default=e.exports}}]);