<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>比较 | 个人主页</title>
    <meta name="generator" content="VuePress 1.9.9">
    
    <meta name="description" content="CZT的博客">
    
    <link rel="preload" href="/assets/css/0.styles.e8e4f3a3.css" as="style"><link rel="preload" href="/assets/js/app.c780e1b6.js" as="script"><link rel="preload" href="/assets/js/2.f44a4f26.js" as="script"><link rel="preload" href="/assets/js/26.f37e9ddb.js" as="script"><link rel="prefetch" href="/assets/js/10.207c4431.js"><link rel="prefetch" href="/assets/js/11.747359fa.js"><link rel="prefetch" href="/assets/js/12.6c286f4f.js"><link rel="prefetch" href="/assets/js/13.c0822fad.js"><link rel="prefetch" href="/assets/js/14.75e13154.js"><link rel="prefetch" href="/assets/js/15.cf4291c4.js"><link rel="prefetch" href="/assets/js/16.babfb68b.js"><link rel="prefetch" href="/assets/js/17.600473bc.js"><link rel="prefetch" href="/assets/js/18.0b6e0252.js"><link rel="prefetch" href="/assets/js/19.cfc57187.js"><link rel="prefetch" href="/assets/js/20.dec901f2.js"><link rel="prefetch" href="/assets/js/21.bfa49832.js"><link rel="prefetch" href="/assets/js/22.a31f4be5.js"><link rel="prefetch" href="/assets/js/23.7019856d.js"><link rel="prefetch" href="/assets/js/24.45adeb21.js"><link rel="prefetch" href="/assets/js/25.43428e77.js"><link rel="prefetch" href="/assets/js/27.241fb6ed.js"><link rel="prefetch" href="/assets/js/28.1bf839c4.js"><link rel="prefetch" href="/assets/js/29.bbb07d62.js"><link rel="prefetch" href="/assets/js/3.1aa3be4a.js"><link rel="prefetch" href="/assets/js/30.7ca7bc7e.js"><link rel="prefetch" href="/assets/js/4.7ac2b204.js"><link rel="prefetch" href="/assets/js/5.f702624b.js"><link rel="prefetch" href="/assets/js/6.c76c0e1e.js"><link rel="prefetch" href="/assets/js/7.414750dc.js"><link rel="prefetch" href="/assets/js/8.bc490d6c.js"><link rel="prefetch" href="/assets/js/9.0cb2026c.js">
    <link rel="stylesheet" href="/assets/css/0.styles.e8e4f3a3.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">个人主页</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java" class="dropdown-title"><span class="title">Java</span> <span class="arrow down"></span></button> <button type="button" aria-label="Java" class="mobile-dropdown-title"><span class="title">Java</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/Java基础.html" class="nav-link">
  Java基础
</a></li><li class="dropdown-item"><!----> <a href="/Java高级.html" class="nav-link">
  Java高级
</a></li><li class="dropdown-item"><!----> <a href="/Java并发.html" class="nav-link">
  Java并发
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据库" class="dropdown-title"><span class="title">数据库</span> <span class="arrow down"></span></button> <button type="button" aria-label="数据库" class="mobile-dropdown-title"><span class="title">数据库</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/MySQL.html" class="nav-link">
  MySQL
</a></li><li class="dropdown-item"><!----> <a href="/数据库.html" class="nav-link">
  数据库
</a></li><li class="dropdown-item"><!----> <a href="/Redis.html" class="nav-link">
  Redis
</a></li><li class="dropdown-item"><!----> <a href="/存储.html" class="nav-link">
  存储
</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="Java" class="dropdown-title"><span class="title">Java</span> <span class="arrow down"></span></button> <button type="button" aria-label="Java" class="mobile-dropdown-title"><span class="title">Java</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/Java基础.html" class="nav-link">
  Java基础
</a></li><li class="dropdown-item"><!----> <a href="/Java高级.html" class="nav-link">
  Java高级
</a></li><li class="dropdown-item"><!----> <a href="/Java并发.html" class="nav-link">
  Java并发
</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="数据库" class="dropdown-title"><span class="title">数据库</span> <span class="arrow down"></span></button> <button type="button" aria-label="数据库" class="mobile-dropdown-title"><span class="title">数据库</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/MySQL.html" class="nav-link">
  MySQL
</a></li><li class="dropdown-item"><!----> <a href="/数据库.html" class="nav-link">
  数据库
</a></li><li class="dropdown-item"><!----> <a href="/Redis.html" class="nav-link">
  Redis
</a></li><li class="dropdown-item"><!----> <a href="/存储.html" class="nav-link">
  存储
</a></li></ul></div></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="比较"><a href="#比较" class="header-anchor">#</a> 比较</h1> <table><thead><tr><th></th> <th>ActiveMQ</th> <th>RabbitMQ</th> <th>RocketMQ</th> <th>Kafka</th></tr></thead> <tbody><tr><td>功能</td> <td>MQ功能极其完备</td> <td>MQ功能完备</td> <td>MQ功能较为完善</td> <td>MQ功能较为简单，主要使用在大数据的实时计算和日志采集</td></tr> <tr><td>单机吞吐量</td> <td>万级</td> <td>万级</td> <td>十万级</td> <td>十万级</td></tr> <tr><td>时效性</td> <td>ms级</td> <td>μs级（延迟最低）</td> <td>ms级</td> <td>ms级以内</td></tr> <tr><td>可用性</td> <td>高，基于主从架构</td> <td>高，基于主从架构</td> <td>非常高，分布式架构</td> <td>非常高，分布式架构，一个数据多个副本</td></tr> <tr><td>消息可靠性</td> <td></td> <td></td> <td></td> <td>会丢数据</td></tr> <tr><td>topic数量对吞吐量的影响</td> <td></td> <td></td> <td>topic达到百级时，吞吐量会有小幅度下降</td> <td>topic达到千级时，吞吐量会大幅下降</td></tr></tbody></table> <h1 id="q-消息队列如何保证消息顺序性"><a href="#q-消息队列如何保证消息顺序性" class="header-anchor">#</a> Q：消息队列如何保证消息顺序性？</h1> <h2 id="rocketmq"><a href="#rocketmq" class="header-anchor">#</a> RocketMQ</h2> <p>顺序性的前提都是单线程。</p> <p><strong>局部顺序性</strong></p> <ul><li>queue级别：对某个topic，设n个生产者和消费者，生产者发指定queue，消费者读取同一个queue，queue内肯定是有序的，则每对生产者-消费者的消息流是有序的，前提是<strong>单线程</strong>。</li> <li>topic级别：业务可以hash切分为多topic，每个topic只有一个生产者和一个消费者，则topic内有序，前提是<strong>单线程</strong>。</li></ul> <p>所以一般要求的顺序性都指全局顺序性</p> <p><strong>全局顺序性</strong></p> <p>对某个topic只能是一个生产者，一个消费者，且<strong>单线程</strong>。要求全局顺序性必然无法并发，损失性能。</p> <h2 id="kafka"><a href="#kafka" class="header-anchor">#</a> kafka</h2> <p>每个消费者<strong>只能消费一个</strong>partition，若消费者比partition多，则有消费者拿不到数据，没有意义</p> <p>写入同一个partition的数据一定是有顺序的，因此生产者写入时，可以指定一个key，则相同key一定会分发到同一个partition</p> <p><img src="images%5C%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%5Cimage-20220318015558871.png" alt="image-20220318015558871"></p> <h1 id="q-如何保证消息不丢失"><a href="#q-如何保证消息不丢失" class="header-anchor">#</a> Q：如何保证消息不丢失？</h1> <h2 id="kafka-2"><a href="#kafka-2" class="header-anchor">#</a> Kafka</h2> <p><strong>情形1：消费者丢数据</strong></p> <p>kafka消费者会自动提交offset（记为i），broker就认为i号消息已被消费，若此时消费者出问题，则下次请求broker给的就是i+1号消息了，i号消息丢失。</p> <p>解决：改为手动提交</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>request.required.asks=0
# 0: 相当于异步的，不需要leader给予回复，producer立即返回，发送就是成功，那么发送消息网络超时或broker crash(1、Partition的Leader还没有commit消息 2、Leader与Follower数据不同步)，既有可能丢失也可能会重发
# 1：当leader接收到消息之后发送ack, 丢会重发, 丢的概率很小
# -1：当所有的follower都同步消息成功后发送ack. 不会丢失消息
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><p><strong>情形2：broker丢数据</strong></p> <p>某个broker宕机，重新选举leader，此时follower数据未同步完，leader也挂了，则leader上的数据丢失。</p> <p>解决：给这个topic设置<code>replication.factor</code>大于1，即每个partition至少有2个副本</p> <p>broker设置<code>min.insync.replicas</code>大于1，要求leader至少有一个follower与自己保持同步中</p> <p>生产者设置<code>acks = all</code>，要求每条数据必须写入所有replica后，才认为写成功</p> <p>生产者设置<code>retries = MAX（最大整数）</code>，要求写入失败时，无限重试</p> <p><strong>Q：生产者是否会丢数据？</strong></p> <p>按照情形2的解决办法，能保证生产者一定将数据发送到broker，且存有2个以上副本，若不满足，生产者会不断重试</p> <h2 id="rocketmq-2"><a href="#rocketmq-2" class="header-anchor">#</a> RocketMQ</h2> <h1 id="q-如何保证消息不重复"><a href="#q-如何保证消息不重复" class="header-anchor">#</a> Q：如何保证消息不重复？</h1> <p>kafka消费者会在获取消息后提交offset（相当于序号）给zk，告诉broker消费到哪了，从而保证消费者获取消息的基本顺序性，当消费者宕机重启后，还能从上次消费的地方继续开始</p> <p>然而消费者并不是每条消息都提交offset，而是定时<strong>批量提交</strong>。若消费到中间某个消息（序号i），还未提交offset就宕机，则下次重启时无法继续从消息i开始，而是从i之前的某条开始，这就会出现重复消息</p> <p><strong>解决</strong></p> <ol><li>用redis记录消息id（流水号），消费者每次消费都读redis，遇到重复就跳过</li> <li>用数据库唯一主键约束</li> <li>加分布式锁（实际项目），一条消息从生产到消费全程加锁</li></ol> <h2 id="rocketmq重复消费场景"><a href="#rocketmq重复消费场景" class="header-anchor">#</a> RocketMQ重复消费场景</h2> <p>1、发送阶段</p> <p>当一条消息已被成功发送到Broker并完成持久化，此时出现网络闪断，导致Broker对Producer应答ack失败。Producer等待超时并尝试再次发送消息，则Broker中就可能会出现两条内容相同、并且Message ID也相同的消息，那么后续Consumer就一定会消费两次该消息。</p> <p>2、消费阶段</p> <p>消息已投递到Consumer并完成业务处理，当Consumer向Broker提交offset时网络闪断，Broker未收到offset。为了保证消息<strong>至少被消费一次</strong>的原则，Broker将在网络恢复后再次尝试投递之前已被处理过的消息。此时Consumer就会收到与之前处理过的内容相同、且Message ID也相同的消息。</p> <blockquote><p>至少一次原则：RocketMQ保证每条消息必须要被<strong>成功消费一次</strong>。</p></blockquote> <p>3、Rebalance时</p> <blockquote><p>Rebalance即重新均衡，指的是<strong>集群消费</strong>模式下，同⼀个Consumer Group中的Consumer数量变化时，将⼀个Topic下的多个Queue在多个Consumer间进行重新分配的过程。</p></blockquote> <p>消费者中某个消费者1已经接收queue1的消息，但未提交offset，此时发生Rebalance，queue1的消费者被重新指定为消费者2，则消费者2也可能读到queue1中的消费者1接收但未提交offset的这条消息。</p> <h1 id="q-如何处理消息积压"><a href="#q-如何处理消息积压" class="header-anchor">#</a> Q：如何处理消息积压？</h1> <p>考虑提高消费能力</p> <ul><li>增加消费者：若当前topic的queue数量大于消费者数量，就可以增加消费者来加快积压消息的消费</li> <li>增加消费者线程：每个消费者的线程增加，则消费速度提升</li> <li>消息迁移Queue：若当前topic的queue数量不超过消费者数量，再增加消费者也没用（消费者数不能超过分区数，否则有消费者闲置），此时就应考虑增加queue。把部分积压消息转到<strong>临时topic</strong>，因为不用业务处理，只是单纯转发，因此速度很快。再增加消费者去消费临时topic的消息，消费完后恢复原状。</li></ul> <h1 id="q-kafka为何能做到高性能"><a href="#q-kafka为何能做到高性能" class="header-anchor">#</a> Q：Kafka为何能做到高性能？</h1> <h2 id="_1-顺序写"><a href="#_1-顺序写" class="header-anchor">#</a> 1 顺序写</h2> <p>追加写磁盘，顺序写的性能极高</p> <h2 id="_2-零拷贝"><a href="#_2-零拷贝" class="header-anchor">#</a> 2 零拷贝</h2> <p>先来看看非零拷贝的情况，数据从内存拷贝到kafka服务进程那块，又拷贝到socket缓存那块，整个过程耗费的时间比较高</p> <img src="images/消息队列/640-1679328162013-3.jpeg" alt="图片" style="zoom:50%;"> <p>kafka利用了Linux的sendFile技术（NIO），省去了进程切换和一次数据拷贝，让性能变得更好。</p> <img src="images/消息队列/640-1679328175176-6.png" alt="图片" style="zoom:50%;"> <h1 id="q-客户端和服务端最大的区别是什么"><a href="#q-客户端和服务端最大的区别是什么" class="header-anchor">#</a> Q：客户端和服务端最大的区别是什么？</h1> <p>客户端需要connect操作，不需要启动Netty服务器进行accpet。</p> <p>基于RocketMQ，提供高性能、高可用服务</p> <h1 id="kafka-3"><a href="#kafka-3" class="header-anchor">#</a> Kafka</h1> <h2 id="broker"><a href="#broker" class="header-anchor">#</a> Broker</h2> <p>就是Server。 包含多个 Topic , Partition, 和 Replica. 负责协调 Producer 和 Consumer 主从结构为: 主节点为 Controller, 从节点为从节点 Kafka 启动是会往 Zookeeper 中注册当前 Broker 信息. 谁先注册谁就是 Controller. 读取注册上来的从节点的数据(通过监听机制), 生成集群 的元数据信息, 之后把这些信息都分发给其他的服务器, 让其他服务器能感知到集群中其它成员的 存在</p> <h2 id="topic"><a href="#topic" class="header-anchor">#</a> Topic</h2> <p>标准 MQ模型 中的 Queue。Kafka 中一个 Topic 的消息会保存在不同的 Partition (不同的 Broker)来保证高可用</p> <h2 id="partition-分区"><a href="#partition-分区" class="header-anchor">#</a> Partition （分区）</h2> <p>可以理解为将标准 MQ 的 Queue 的消息进行拆分，来实现高可用 Producer 发送的 Message，根据 key 和 partition 数进行 hash，然后进行投递。</p> <p>一个分区只能被同一个 Consumer Group （消费者组）中的一个 Consumer 消费，分区内消费有序。因此消费者组可用于实现某个topic的并行消费，n个消费者组同时消费某topic的n个分区，且不会互相干扰</p> <h2 id="replica-副本"><a href="#replica-副本" class="header-anchor">#</a> Replica （副本）</h2> <p>每一个 Partition 都可以设置多个副本，但 Replica 的数量应不超过 Broker 的数量</p> <p>Leader：Partition 的所有副本中只能有一个 Leader 节点(Broker)。Producer 写数据只往 Leader 中写。Consumer 读数据也是从 Leader 中读</p> <p>Follower：只用于<strong>备份</strong>Leader，采用 pull 模式</p> <h2 id="producer"><a href="#producer" class="header-anchor">#</a> Producer</h2> <p>标准 MQ 中的发送方，一个Producer通常只发送一类消息（同一个topic）。发送给 Broker 使用<strong>push</strong> (推)模式</p> <h2 id="consumer-group-消费者组"><a href="#consumer-group-消费者组" class="header-anchor">#</a> Consumer Group （消费者组）</h2> <p>一类Consumer的集合名称，这类Consumer通常消费一类消息（同一个topic），且消费逻辑一致。</p> <h2 id="controller"><a href="#controller" class="header-anchor">#</a> Controller</h2> <p>kafka也是主从式的架构，主节点就叫controller，其余的为从节点，controller是需要和zookeeper进行配合管理整个kafka集群。</p> <h2 id="zookeeper"><a href="#zookeeper" class="header-anchor">#</a> Zookeeper</h2> <p>kafka严重依赖于zookeeper集群，所有的broker在启动的时候都会往zookeeper进行注册，目的就是选举出一个controller【先到先得】</p> <p>controller会监听zookeeper里面的多个目录，例如有一个目录/brokers/，其他从节点往这个目录上**注册（就是往这个目录上创建属于自己的子目录而已）**自己，这时命名规则一般是它们的id编号，比如/brokers/0、/brokers/1、/brokers/2</p> <p>注册时各个节点必定会暴露自己的主机名，端口号等等的信息，此时controller就要去<strong>读取注册上来的从节点的数据（通过监听机制），生成集群的元数据信息，之后把这些信息都分发给其他的服务器，让其他服务器能感知到集群中其它成员的存在</strong>。</p> <p>此时模拟一个场景，我们创建一个主题（其实就是在zookeeper上/topics/topicA这样创建一个目录而已），kafka会把分区方案生成在这个目录中，此时controller就监听到了这一改变，它会去同步这个目录的元信息，然后同样下放给它的从节点，通过这个方法让整个集群都得知这个分区方案，此时从节点就各自创建好目录等待创建分区副本即可。这也是整个集群的管理机制。</p> <h2 id="kafka网络设计"><a href="#kafka网络设计" class="header-anchor">#</a> Kafka网络设计</h2> <p>kafka的网络设计和Kafka的调优有关，这也是为什么它能支持高并发的原因</p> <p><img src="images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/640.png" alt="图片"></p> <p>首先客户端发送请求全部会先发送给一个Acceptor，broker里面会存在3个线程（默认是3个），这3个线程都是叫做processor，Acceptor不会对客户端的请求做任何的处理，直接封装成一个个socketChannel发送给这些processor形成一个队列，发送的方式是轮询，就是先给第一个processor发送，然后再给第二个，第三个，然后又回到第一个。消费者线程去消费这些socketChannel时，会获取一个个request请求，这些request请求中就会伴随着数据。</p> <p>线程池里面默认有8个线程，这些线程是用来处理request的，解析请求，如果request是写请求，就写到磁盘里。读的话返回结果。
processor会从response中读取响应数据，然后再返回给客户端。这就是Kafka的网络三层架构。</p> <p>所以如果我们需要对kafka进行增强调优，增加processor并增加线程池里面的处理线程，就可以达到效果。request和response那一块部分其实就是起到了一个缓存的效果，是考虑到processor们生成请求太快，线程数不够不能及时处理的问题。</p> <p>所以这就是一个加强版的reactor网络线程模型。</p> <h1 id="ctg-mq"><a href="#ctg-mq" class="header-anchor">#</a> CTG-MQ</h1> <h2 id="name-server"><a href="#name-server" class="header-anchor">#</a> Name Server</h2> <p>一个几乎无状态节点，可集群部署，节点之间无同步信息。 它主要提供broker注册、Topic路由管理等功能</p> <h2 id="broker-2"><a href="#broker-2" class="header-anchor">#</a> Broker</h2> <p>消息中转角色，负责存储消息，转发消息，一般也称Server。</p> <p>CTG-MQ一般在多个服务器部署broker集群</p> <h3 id="消息存储"><a href="#消息存储" class="header-anchor">#</a> 消息存储</h3> <p>生产者发送的消息并不是瞬间到达消费者（否则就失去了MQ的意义），而是存储在本地文件系统中，这些相关文件默认在当前用户主目录下的store目录中。 目录下的文件：</p> <ul><li>abort：该文件在Broker启动后会自动创建，正常关闭Broker，该文件会自动消失。若在没有启动Broker的情况下，发现这个文件是存在的，则说明之前Broker的关闭是非正常关闭。</li> <li>checkpoint：其中存储着commitlog、consumequeue、index文件的最后刷盘时间戳</li> <li><strong>commitlog</strong>：其中存放着commitlog文件，而消息是写在commitlog文件中的</li> <li>config：存放着Broker运行期间的一些配置数据</li> <li><strong>consumequeue</strong>：其中存放着consumequeue文件，队列就存放在这个目录中</li> <li>index：其中存放着消息索引文件indexFile</li> <li>lock：运行期间使用到的全局资源锁</li></ul> <h4 id="commitlog"><a href="#commitlog" class="header-anchor">#</a> CommitLog</h4> <blockquote><p>说明：在很多资料中commitlog目录中的文件简单就称为commitlog文件。但在源码中，该文件被命名为mappedFile</p></blockquote> <p>存放producer端写入的消息主体内容，消息是不定长的。</p> <p>mappedFile文件大小上限为1G，文件名由<strong>20位</strong>十进制数构成，表示当前文件的第一条消息的起始位移偏移量。比如第⼀个文件名00000000000000000000，表示起始偏移量为0；当第一个文件写满了，写入第⼆个文件，名为00000000001073741824，表示起始偏移量为1073741824（上一个文件大小为1G=1073741824），以此类推。</p> <img src="images/消息队列/image-20230327005920218.png" alt="image-20230327005920218" style="zoom:50%;"> <h4 id="consumequeue"><a href="#consumequeue" class="header-anchor">#</a> ConsumeQueue</h4> <p>消息消费队列，引入的目的主要是<strong>提高消费的性能</strong>。由于RocketMQ是基于主题topic的订阅模式，消息消费是针对topic进行的，如果要遍历commitlog文件，根据topic检索消息非常低效。</p> <p>于是consumer将consumequeue作为消息的<strong>索引</strong>（每个索引20B），保存了消息在commitlog的起始物理偏移量offset（8B）、消息体大小size（4B）和消息tag的hashCode（8B）。</p> <p>每个文件可以包含30W个索引，目录结构：topic/queue/file，按topic、queue来划分</p> <img src="images/消息队列/image-20230327010718368.png" alt="image-20230327010718368" style="zoom:50%;"> <h4 id="indexfile"><a href="#indexfile" class="header-anchor">#</a> IndexFile</h4> <p>除了通过通常的指定Topic进行消息消费外，rocketMQ还提供一种可以通过<strong>key或时间</strong>来查询消息的方法。前提是<strong>消息体中包含key</strong>，且已经发送到broker。</p> <p>文件名以创建的时间戳命名，固定单个IndexFile文件大小为400M，可以保存2000W个索引，底层存储为hashMap结构，因此RocketMQ索引文件底层实现为<strong>hash索引</strong>。</p> <p>总结：RocketMQ采用的是混合型的存储结构，即每个Broker下所有队列共用一个CommitLog文件来存储。并使用consumequeue文件索引，实现数据和索引分离。broker使用同步刷盘或异步刷盘方式将消息持久化。</p> <h2 id="topic-2"><a href="#topic-2" class="header-anchor">#</a> Topic</h2> <p>在ctg-mq中，topic类似于JMS规范中的队列，所有消息都是存放在不同的 topic中，<strong>每个topic都有与之对应的生产者和消费者</strong>。</p> <p>broker与topic是多对多关系，broker里可能有多个topic，一个Topic可以分片（分成多个Queue）存在多个broker上（分布式）。</p> <h2 id="tag"><a href="#tag" class="header-anchor">#</a> Tag</h2> <p>用于区分同一Topic下不同类型的消息。</p> <p>Topic是消息的一级分类，Tag是消息的二级分类。</p> <h2 id="queue"><a href="#queue" class="header-anchor">#</a> Queue</h2> <p>每个Topic由多个队列Queue组成，Queue内有序，（类似kafka的分区）是存放数据的最小单位</p> <p><strong>broker-topic-queue关系</strong></p> <p>broker与topic是多对多关系，一个broker里可以有多个topic，一个topic可以存在多个broker中</p> <p>topic又分为多个queue，即queue分布在不同的broker上，从而实现<strong>分布式</strong>。</p> <p><img src="images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20220426204242838.png" alt="image-20220426204242838"></p> <h2 id="生产者"><a href="#生产者" class="header-anchor">#</a> 生产者</h2> <p>生产组：一类Producer的集合名称，这类Producer通常发送一类消息（同一个topic），且发送逻辑一致，一般由业务系统负责产生消息。</p> <p>生产者实例： 一个生产者实例代表<strong>生产者的一员</strong>，不同的生产者用不同的实例名字创建。</p> <p>发送方式：</p> <ul><li>默认<strong>轮询</strong>topic的所有队列，每个队列接收平均的消息量。</li> <li>CTG-MQ也可以用<code>sendByGroupId(MQMessage message)</code>指定队列，在message中设置groupId，MQ内部按groupId来hash到某个队列</li> <li>最小投递延迟算法：统计每次消息投递的时间延迟，然后根据统计出的结果将消息投递到时间延迟最小的Queue。</li></ul> <h3 id="消息写入过程"><a href="#消息写入过程" class="header-anchor">#</a> 消息写入过程</h3> <p>一条消息进入到Broker后经历了以下几个过程才最终被持久化。</p> <ol><li>Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset</li> <li>将queueId、queueOffset等数据，与消息一起封装为消息单元</li> <li>将消息单元写入到commitlog</li> <li>同时，形成消息索引条目</li> <li>将消息索引条目分发到相应的consumequeue</li></ol> <h2 id="消费者"><a href="#消费者" class="header-anchor">#</a> 消费者</h2> <p>消费组：一类Consumer的集合名称，这类Consumer通常消费一类消息（同一个topic），且消费逻辑一致，一般是后台系统负责异步消费。消费进度由存储在消费组上。</p> <p>消费者实例 ：一个消费者实例代表<strong>消费组的一员</strong>，不同的消费者用不同的实例名字创建。</p> <p>约束：若topic分为n个队列，则消费者数量不能超过n，否则会有消费者无法消费消息。</p> <h3 id="消息读取过程"><a href="#消息读取过程" class="header-anchor">#</a> 消息读取过程</h3> <p>当Consumer来拉取消息时会经历以下几个步骤：</p> <ol><li><p>Consumer获取到其要消费消息所在Queue的消费偏移量offset，计算出其要消费消息的消息offset</p> <blockquote><p>消费<em>offset</em>即消费进度，<em>consumer</em>对某个<em>Queue</em>的消费<em>offset</em>，即消费到了该<em>Queue</em>的第几条消息</p> <p>消息<em>offset =</em> 消费<em>offset + 1</em></p></blockquote></li> <li><p>Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。</p></li> <li><p>Broker计算在该consumequeue中的queueOffset。</p> <blockquote><p><em>queueOffset =</em> 消息<em>offset * 20</em>字节</p></blockquote></li> <li><p>从该queueOffset处开始向后查找第一个指定Tag的索引条目。解析该索引条目的前8个字节，即可定位到该消息在commitlog中的offset</p></li> <li><p>从对应commitlog offset中读取消息单元，并发送给Consumer</p></li></ol> <h3 id="广播消费和集群消费"><a href="#广播消费和集群消费" class="header-anchor">#</a> 广播消费和集群消费</h3> <p><strong>广播消费</strong></p> <p>注意：使用消费模式，在很多使用场景都会带来影响或限制，在CTG-MQ中， 应尽量避免使用此消费模式。</p> <p>在广播消费模式下，一条消息被多个Consumer消费，即使这些 Consumer属于同一个Consumer Group，消息也会被<strong>Consumer Group中 的每个Consumer都消费一次</strong>，广播消费中的Consumer Group概念可以认 为在消息划分方面无意义。</p> <p>V1.x版本由于广播消费的<strong>消费进度，是保存在客户端</strong>的（因为广播模式下consumer group中每个consumer都会
消费所有消息，但它们的消费进度不同 ），对于很多使用场景 会带来影响，在ctg-mq中，并不推荐使用此消费模式。</p> <p>V2.x版本在服务端存储消费状态，不支持此消费模式。推荐通过<strong>多消费组</strong> （订阅组）的方式进行消费。</p> <p><strong>集群消费</strong></p> <p>一个Topic 可以被一个或多个 Consumer Group 消费，即一条消息每个 Consumer Group都能收到，但<strong>一条消息只会被一个 Consumer Group 消费一次</strong>，消费组内具体哪个consumer消费取决于内部分发机制。</p> <p>每个Consumer Group有自己独立的消费进度，<strong>消费进度保存在服务端</strong>（因为同消费组的客户端之间需要共享进度）。</p> <p>负载均衡：一个Consumer Group中的消费者实例可以平均分摊消费消息。例如某个Topic有12条消息，其中一个Consumer Group有3个不同的消费者实例（可能是3个进程，或者3台机器），那么每个实例只消费其中的4条消息。 在此消费模式下，可以做到Point-To-Point的消费，也可以做到JMS里面广播消费，能满足绝大部分场景，推荐使用此消费模式。</p> <h3 id="offset管理"><a href="#offset管理" class="header-anchor">#</a> Offset管理</h3> <ul><li>本地管理：对应广播消费，offset存每个Consumer客户端，默认路径为当前用户主目录下的<code>.rocketmq_offsets/${clientId}/${group}/Offsets.json</code></li> <li>远程管理：对应集群消费，offset存broker，默认路径为当前用户主目录下的<code>store/config/consumerOffset.json</code></li></ul> <h3 id="offset提交方式"><a href="#offset提交方式" class="header-anchor">#</a> offset提交方式</h3> <p>集群消费模式下，comsumer读取消息后会向broker提交消费进度，分为同步提交和异步提交</p> <ul><li>同步提交：comsumer读取完<strong>一批消息</strong>后向broker提交这些消息的offset，然后等待broker响应。若超时没收到响应，则重新提交，收到响应之前阻塞消费。</li> <li>异步提交：comsumer读取完<strong>一批消息</strong>后向broker提交这些消息的offset，无需等待broker响应，就可继续读取下一批消息。</li></ul> <h3 id="重试队列"><a href="#重试队列" class="header-anchor">#</a> 重试队列</h3> <p>当rocketMQ对消息的消费出现异常时，会将发生异常的消息的offset提交到Broker中的一个特殊队列（而不是等待时长后再去重试读取原来offset的消息）。重试队列也是通过延迟消息处理的。</p> <p>重试队列是对于消费组的（因为要保证一条消息只会被一个 Consumer Group 消费一次），因此队列名为<code>%RETRY%{$ConsumerGroup}@{$ConsumerGroup}</code>。</p> <h3 id="死信队列"><a href="#死信队列" class="header-anchor">#</a> 死信队列</h3> <p>当⼀条消息初次消费失败，RocketMQ 会⾃动进⾏消息重试；达到最⼤重试次数后，若消费依然失败，说明消费组在正常情况下⽆法正确地消费该消息，RocketMQ 不会⽴刻将消息丢弃，⽽是将其发送到该消费组对应的特殊队列中，称为死信队列（Dead-Letter Queue，DLQ），而其中的消息则称为死信消息（Dead-Letter Message，DLM）。</p> <ul><li>死信队列中的消息不会再被消费者正常消费，即DLQ对于消费者是不可见的</li> <li>死信存储有效期与正常消息相同，均为 3 天（commitlog文件的过期时间），3 天后会被自动删除</li> <li>死信队列就是一个特殊的Topic，名称为%DLQ%consumerGroup@consumerGroup ，即每个消费者组都有一个死信队列，消费组下所有topic的死信消息都写入同一队列。</li> <li>如果⼀个消费者组未产生死信消息，则不会为其创建相应的死信队列</li></ul> <h2 id="消费模型"><a href="#消费模型" class="header-anchor">#</a> 消费模型</h2> <p>主要有push和pull两种</p> <h3 id="push模型"><a href="#push模型" class="header-anchor">#</a> PUSH模型</h3> <p>推送模型（被动），是一个“<strong>发布-订阅</strong>”模型，由consumer封装了轮询过程，并注册MessageListener监听器，consumer接收消息后，回调监听器接口Listener方法。对用户而言，感觉消息是被推送过来的。</p> <p>优点：<strong>实时性好</strong>。</p> <p>缺点：需要维护一个<strong>长连接</strong>，资源消耗大。</p> <p>适合场景：client数量不多，server数据变化频繁。</p> <p>客户端会自动开启多线程消费消息（线程数可配，默认5~64），即listener里面的方法，会被多线程执行。</p> <p>客户端内部可以根据堆积量进行调整，使用者不需要新启、管理消费线程。并有流控机制，当客户端缓存一定量消息，导致消费不及时，会停止推送新消息。</p> <h3 id="pull模型"><a href="#pull模型" class="header-anchor">#</a> PULL模型</h3> <p>拉取模型（主动），又称队列模型，是一种“发--存--收”模型。应用通常主动调用Consumer的pull方法从Broker拉消息，主动权由应用控制，但实时性取决于应用主动拉取的频率，线程数由应用自主决定。</p> <p>对于无序消费，应用可以多次调用pull并拉到数据，且与是否签收无关。对于有序消费，只要同一Queue的消息被拉出去消费，但未签收，则此Queue无法再拉取消费。</p> <p>consumer在pull的时候，告诉broker自己buffer中可用的容量，整个流程如下：</p> <ol><li>consumer请求broker，告诉broker本地的可承载量，比如500</li> <li>broker在收到消息后，如果没有消息则进入**long polling（长轮询）**状态</li> <li>当有消息的时候，broker直接向consumer进行push，总共push的数据量为500</li> <li>在整个push期间，consumer无需重新pull，即可获取数据</li> <li>由于broker知道最大容量，所以无需担心被冲垮。</li></ol> <h2 id="分布式"><a href="#分布式" class="header-anchor">#</a> 分布式</h2> <p>通过将topic分成多queue，分布在不同的broker上，以实现分布式</p> <h2 id="消息模式"><a href="#消息模式" class="header-anchor">#</a> 消息模式</h2> <h3 id="有序消息"><a href="#有序消息" class="header-anchor">#</a> 有序消息</h3> <p>生产者用<code>sendByGroupId()</code> 发送，以保证消息按序存储。【约束】只能是单生产者实例单线程串行发送。</p> <p>消费者<strong>按序消费</strong>，前一条消息未完成消费，则后续的消费阻塞。若consumer消费失败，会不断<strong>重试</strong>这条消息，直到消费成功。</p> <p>在CTG-MQ中，主要有两种：普通和严格</p> <p><strong>普通有序消息</strong></p> <p>在正常情况下可以保证完全的顺序消息，但是一旦发生通 信异常，Broker重启，由于队列总数发生变化，哈希取模后定位的队列会变 化，产生短暂的消息顺序不一致。 如果业务能容忍在集群异常情况（如某个Broker宕机或者重启）下，消息短 暂的乱序，使用普通顺序方式比较合适。</p> <p><strong>严格有序消息</strong></p> <p>无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集群中只要有一台机器不可用，则整个集群都不可 用（或者影响hash值对应队列的使用），服务可用性大大降低。 如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不 过仍然会存在几分钟的服务不可用。</p> <p>在CTG-MQ中，消息模式选择的优先顺序为：<strong>无序消息&gt;普通有序消息&gt;严格有序消息</strong>。在业务场景允许的情况下，优先选择无序消息，或者 在业务能变通的情况下，将有序消息转化为无序消息。 如果一定要用有序，若业务能容忍短暂乱序，推荐普通有序消费。</p> <p><strong>有序消息的缺点</strong> &amp; 必须注意事项：</p> <ol><li><p>对于生产者，因为要保证顺序，所以一般单线程串行发送， 性能较低。对一个Topic有多个Queue的场景，可增加生产者数，每个生产者发送固定的Queue，提高性能。</p></li> <li><p>对于消费者，因为要保证顺序，所以一般单线程串行消费，消费性能较低。对一个Topic有多个Queue的场景，可以通过增加消费者 实例数，提高性能，但应用必须考虑消息者实例数量变化，由于负载均 衡带来的短时间数据乱序问题。</p></li> <li><p>对于普通有序消息，当节点故障时，由于Queue数的变化，导致hash 值的变化，产生与消费都会出现短暂的消息顺序不一致；对于严格有序 消息，当节点故障时，Queue数不会变化，产生与消费都会出现异常， 直到故障节点恢复。</p></li> <li><p>对于普通有序消息，意味着业务能接受短时间消息乱序，所以一般情 况下可以在线态扩容；对于严格有序消息，需要将所有消息消费完，并且停止服务，才能扩容。</p></li> <li><p>有一种场景，同一Topic所有消息必须是有序生产与有序消费，可以使 用多Queue然后在生产消费端做顺序处理，也可以拆分多个Topic然后 使用单Queue进行处理，但在设计时，应用必须考虑单Queue的处理性 能是否能满足。对于单Queue，只要对应的broker故障，则服务中断。</p></li></ol> <h3 id="无序消息"><a href="#无序消息" class="header-anchor">#</a> 无序消息</h3> <p>普通消息、延时消息、事务消息都是无序的。无序消息的<strong>重试只对集群消费生效</strong>。（广播消费失败不重试）</p> <p>优点：</p> <ol><li><p>生产者可以使用<strong>多进程、多线程</strong>往同一个TOPIC发送，性能较好</p></li> <li><p>消费者可以使用<strong>多进程、多线程</strong>同时消费一个topic，性能较好</p></li> <li><p>可以充分使用集群的 <strong>failover</strong>（故障转移）特点，无须依赖自动主备切换（切换过期服务中断），包括：</p> <ol><li>当集群中某一broker节点故障时，不影响业务消息生产， 消息将failover发送到其它节点</li> <li>当集群中某一broker节点故障时，不影响其它节点数据 消费，故障恢复后既可消费</li> <li>充分利用failover特点，可不部署自动切换组件，减少 部署复杂度和运维难度</li></ol></li> <li><p>动态扩容</p></li></ol> <h3 id="消息过滤"><a href="#消息过滤" class="header-anchor">#</a> 消息过滤</h3> <p>有两种⽅案：</p> <ul><li>Broker 端过滤：在 Broker 端按照 Consumer 的去重逻辑进⾏过滤。这样做的好处是避免了⽆⽤的消息传输到 Consumer 端，提高吞吐量。缺点是加重了 Broker 的负担，实现复杂。</li> <li>Consumer 端过滤：⽐如按照消息的 tag 去重，这样的好处是实现起来简单，缺点是有⼤量 ⽆⽤的消息到达了 Consumer 端只能丢弃不处理。</li></ul> <p>⼀般采⽤Cosumer端过滤。如果希望提⾼吞吐量，可以采⽤Broker过滤</p> <p>消息过滤三种方式：</p> <ol><li><p>根据Tag过滤：这是最常⻅的⼀种，⽤起来⾼效简单</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">DefaultMQPushConsumer</span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DefaultMQPushConsumer</span><span class="token punctuation">(</span><span class="token string">&quot;CID_EXAMPLE&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token string">&quot;TOPIC&quot;</span><span class="token punctuation">,</span> <span class="token string">&quot;TAGA || TAGB || TAGC&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">// 过滤出带TAGA、TAGB、TAGC三个标签，用或运算符</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li> <li><p>SQL 表达式过滤：更加灵活</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token class-name">DefaultMQPushConsumer</span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">DefaultMQPushConsumer</span><span class="token punctuation">(</span>&quot;please_rename_unique_group_
name_4&quot;<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3，才过滤</span>
consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token string">&quot;TopicTest&quot;</span><span class="token punctuation">,</span> <span class="token class-name">MessageSelector</span><span class="token punctuation">.</span><span class="token function">bySql</span><span class="token punctuation">(</span><span class="token string">&quot;a between 0 and 3&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li> <li><p>Filter Server ⽅式：最灵活，也是最复杂的⼀种⽅式，允许⽤户⾃定义函数进⾏过滤</p></li></ol> <h3 id="延时消息"><a href="#延时消息" class="header-anchor">#</a> 延时消息</h3> <p>消息写入到Broker后，在指定的时长后才可被消费的消息。</p> <p>使用：不支持随意时长的延迟，是通过特定的延迟等级来指定的</p> <div class="language-java line-numbers-mode"><pre class="language-java"><code><span class="token comment">// 服务端的MessageStoreConfig类</span>
<span class="token keyword">private</span> <span class="token class-name">String</span> messageDelayLevel <span class="token operator">=</span> <span class="token string">&quot;1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h&quot;</span><span class="token punctuation">;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>实现原理：<strong>缓存 + 定时任务</strong>。Broker收到延时消息，会先发送到topic（加特定开头，如SCHEDULE_TOPIC_XXXX）的对应延迟等级的consumequeue 中，然后通过⼀个定时任务轮询这些队列，到期后再把消息投递到⽬标Topic的队列中。总之就是把延时消息先缓存到临时topic，时间到后再发送到原topic。</p> <h3 id="事务消息"><a href="#事务消息" class="header-anchor">#</a> 事务消息</h3> <p>半消息：是指Producer 成功发送到 Broker 端的消息，但暂时还不能被 Consumer 消费的消息。只有等 Producer 端执⾏完本地事务后经过⼆次确认了之后，Consumer 才能消费此条消息。（因为消息在broker还是可以控制撤回的，但consumer消费后就不容易撤回了。）</p> <p>依赖半消息，可以实现<strong>分布式消息事务</strong>，其中的关键在于<strong>⼆次确认以及消息回查</strong>（保证左半部分完成后才发送消费者）</p> <blockquote><p>分布式事务：一次操作由若干分支操作组成，这些分支操作分属不同应用，分布在不同服务器上。分布式事务需要保证这些分支操作要么全部成功，要么全部失败。分布式事务与普通事务一样，就是为了保证操作结果的一致性。</p></blockquote> <p><img src="images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/image-20230328012056416.png" alt="image-20230328012056416"></p> <p>二次确认：上图的第4步，若broker正常收到确认，立即能操作提交或回滚。若超时就回滚。</p> <p>消息回查：第5步，重新查询本地事务的执行状态</p> <h2 id="数据可靠性"><a href="#数据可靠性" class="header-anchor">#</a> 数据可靠性</h2> <h3 id="_1、刷盘策略"><a href="#_1、刷盘策略" class="header-anchor">#</a> 1、刷盘策略</h3> <p>CTG-MQ的所有消息都是持久化的，到达broker后，先写入系统Page Cache（磁盘缓存），然后刷盘（写磁盘），可以保证内存与磁盘都有一份数据。有同步刷盘和异步刷盘，通过Broker配置文件里的<code>flushDiskType</code>参数设置为SYNC_FLUSH、ASYNC_FLUSH指定</p> <h4 id="异步刷盘"><a href="#异步刷盘" class="header-anchor">#</a> 异步刷盘</h4> <p>消息写入Page Cache后就立刻返回写成功。速度快吞吐量大，但有可能丢数据</p> <h4 id="同步刷盘"><a href="#同步刷盘" class="header-anchor">#</a> 同步刷盘</h4> <p>消息写入磁盘才返回写成功。性能不如异步，但数据一定不会丢。流程：消息写入线程Page Cache后，立刻启动刷盘线程写磁盘并等待，刷盘线程完成后唤醒等待线程，返回生产者写成功。</p> <img src="images/消息队列/1399187-20181126215707430-1696939068.png" alt="img" style="zoom:67%;"> <h3 id="_2、主从复制策略"><a href="#_2、主从复制策略" class="header-anchor">#</a> 2、主从复制策略</h3> <p>若是主从架构，消息需要从Master复制到Slave上，有同步和异步两种复制方式。通过Broker配置文件里的<code>brokerRole</code>参数进行设置的，这个参数可以被设置成ASYNC_MASTER、SYNC_MASTER、SLAVE</p> <h4 id="同步复制"><a href="#同步复制" class="header-anchor">#</a> 同步复制</h4> <p>如果Master出故障，Slave上有全部的备份数据，容易恢复。但是会增大数据写入延迟，降低系统吞吐量</p> <h4 id="异步复制"><a href="#异步复制" class="header-anchor">#</a> 异步复制</h4> <p>系统拥有较低的延迟和较高的吞吐量。但是如果Master出了故障，有些数据因为没有被写入Slave，有可能会丢失</p> <h3 id="_3、不同级别的数据可靠策略"><a href="#_3、不同级别的数据可靠策略" class="header-anchor">#</a> 3、不同级别的数据可靠策略</h3> <ul><li>最高保障：实时刷盘+同步复制</li> <li>中等保障：异步刷盘+同步复制</li> <li>中下级别：异步刷盘+异步复制</li> <li>最低级别：异步刷盘/实时刷盘+单主机</li></ul> <p>推荐设置为<strong>异步刷盘、同步复制</strong>，即brokerRole=SYNC_MASTER，flushDiskType=ASYNC_FLUSH</p> <h3 id="_4、数据清除策略"><a href="#_4、数据清除策略" class="header-anchor">#</a> 4、数据清除策略</h3> <p>消息的数据都存储在Commit Log上，所以数据清除是就是<strong>删除过期的Commit Log</strong>。</p> <p>默认过期时间为72小时。在Broker.config配置消息保留时间：<code>fileReservedTime=xxx</code></p> <h4 id="定时删除"><a href="#定时删除" class="header-anchor">#</a> 定时删除</h4> <p>Broker内部有一定时服务，默认4点开始删除过期的消息数据。数据删除是由<strong>最旧的一个Commit Log</strong>文件开始</p> <h4 id="发送时触发删除"><a href="#发送时触发删除" class="header-anchor">#</a> 发送时触发删除</h4> <p>当磁盘使用空间达到85%以上，有消息生产时触发数据删除，由<strong>最旧的一个Commit Log</strong>文件开始，一次最大删除10个文件</p> <p>触发的删除有两种操作：1）保证数据高可靠：磁盘空间超过85%则拒绝服务；2）保证服务高可用：磁盘空间超过85%则强制删除非过期文件。</p> <h2 id="高性能"><a href="#高性能" class="header-anchor">#</a> 高性能</h2> <h3 id="_1、pagecache-顺序读"><a href="#_1、pagecache-顺序读" class="header-anchor">#</a> 1、PageCache+顺序读</h3> <p>ConsumeQueue逻辑消费队列存储的数据较少，并且是<strong>顺序读</strong>，在PageCache机制的<strong>预读取</strong>作⽤下，ConsumeQueue⽂件的读性能⼏乎接近读内存。</p> <p>⻚缓存（PageCache)是OS对⽂件的缓存，⽤于加速对⽂件的读写。⼀般来说，程序对⽂件进⾏顺序读写的速度⼏ 乎接近于内存的读写速度，主要原因就是由于OS使⽤PageCache机制对读写访问操作进⾏了性能优化，将⼀部分 的内存⽤作PageCache。对于数据的写⼊，OS会先写⼊⾄Cache内，随后通过异步的⽅式由pdflush内核线程将 Cache内的数据刷盘⾄物理磁盘上。对于数据的读取，如果⼀次读取⽂件时出现未命中PageCache的情况，OS从 物理磁盘上访问读取⽂件的同时，会顺序对其他相邻块的数据⽂件进⾏预读取。</p> <h3 id="_2、mappedbytebuffer"><a href="#_2、mappedbytebuffer" class="header-anchor">#</a> 2、MappedByteBuffer</h3> <p>是<strong>零拷贝</strong>的一种java实现方式（mmap机制），是java nio引入的文件内存映射方案，读写性能极高。利⽤了NIO中的FileChannel模型将磁盘上的物理⽂件直接映射到⽤户态的内存地址中（即<strong>将CommitLog映射到内存</strong>）</p> <p>正因为需要使⽤内存映射机制，故RocketMQ的⽂件存储都使⽤<strong>定⻓存储</strong>，⽅便⼀次将整个⽂件映射⾄内存</p> <h3 id="q-什么是零拷贝"><a href="#q-什么是零拷贝" class="header-anchor">#</a> Q：什么是零拷贝？</h3> <p>在操作系统中，使⽤传统IO的⽅式，数据需要经历⼏次拷⻉，还要经历⽤户态/内核态切换。</p> <img src="images/消息队列/image-20230327110830901.png" alt="image-20230327110830901" style="zoom:33%;"> <ol><li>从磁盘复制数据到内核态内存；</li> <li>从内核态内存复制到⽤户态内存；</li> <li>然后从⽤户态内存复制到⽹络驱动的内核态内存；</li> <li>最后是从⽹络驱动的内核态内存复制到⽹卡中进⾏传输。</li></ol> <p>通过零拷⻉的⽅式，减少⽤户态与内核态的上下⽂切换和内存拷⻉的次数，⽤来提升I/O的性能。</p> <img src="images/消息队列/image-20230327110921187.png" alt="image-20230327110921187" style="zoom:33%;"> <h2 id="高可用"><a href="#高可用" class="header-anchor">#</a> 高可用</h2> <h3 id="集群接入高可用-nameserver"><a href="#集群接入高可用-nameserver" class="header-anchor">#</a> 集群接入高可用（NameServer）</h3> <p>多个集群管理服务+故障自动切换，实现集群接入点高可用</p> <h3 id="消息服务高可用-broker"><a href="#消息服务高可用-broker" class="header-anchor">#</a> 消息服务高可用（Broker）</h3> <ul><li>通过生产与消费的自动负载均衡，实现Failover，保证某一组服务在全挂的情况下，不影响整体业务</li> <li>通过自主研发的自动主备切换，实现主机故障自动备升主，保证服务连续性，自动主备切换可剥离</li> <li>通过消息过期删除策略，保证服务的可持续性</li></ul> <h2 id="原生rocketmq的问题"><a href="#原生rocketmq的问题" class="header-anchor">#</a> 原生RocketMQ的问题</h2> <ul><li><p>功能不完善：功能比较单一，针对不同应用场景无法有效支 持，如消息轨迹查询，严格消费机制，数据自动删除策略等。</p></li> <li><p>可维护性差：缺乏配套监控运维能力，难以迅速发现解决如 消息堆积、队列堵塞等问题。</p></li> <li><p>可靠性较低：消息服务不提供主备切换能力，存在单点故障， 无法保证服务高可用</p></li></ul> <h2 id="ctg-mq的改进"><a href="#ctg-mq的改进" class="header-anchor">#</a> CTG-MQ的改进</h2> <p>高可用、高可靠改进：</p> <ul><li><p>实现自动主备切换、自动拉起功能，保证服务高可用</p></li> <li><p>实现消息删除策略，按不同的场景优先保证服务可用性或者 数据安全性。</p></li></ul> <p>可维护性改进：</p> <ul><li>实现按生产者、消费者、数据节点、队列4种维度的运行状态 监控，方便快速发现问题</li> <li>实现可视化的监控、配置、管理界面</li> <li>实现自动化测试，以快速迭代</li></ul> <p>新增功能：</p> <ul><li><p>消息轨迹收集、分析与查询，做到可查可追踪</p></li> <li><p>严格的消费机制，满足消费严格不重复的应用需求</p></li> <li><p>重新封装SDK，简化应用使用，并提供按hash算法实现消息 局部有序生产消费</p></li></ul> <h2 id="使用"><a href="#使用" class="header-anchor">#</a> 使用</h2> <h3 id="消费端"><a href="#消费端" class="header-anchor">#</a> 消费端</h3> <p>创建一个类，继承CtgTopicListener，并实现ApplicationRunner</p> <p>覆写com.eshore.cmp.sync.controller.listener.SaveRecordListener#run()、com.eshore.cmp.sync.controller.listener.SaveRecordListener#onMqMessage()</p> <ol><li><p>run方法在app启动时执行，<strong>工厂模式</strong>创建一个消费组，里面只有一个push型消费者，用IConsumer.pushMessagesByTopic()监听某个topic</p> <p>内部再调IMQPushConsumer.listenTopic()，方法内部为Listener<strong>订阅</strong>topic，并注册Listener</p></li> <li><p>onMqMessage方法，处理消费到消息后的处理逻辑</p></li></ol> <h3 id="生产端"><a href="#生产端" class="header-anchor">#</a> 生产端</h3> <p>工厂模式获取一个生产者，然后用IProducer.sendMsgToTopicSyn()发送一条消息</p> <p>MQMessage说明</p> <table><thead><tr><th>属性</th> <th>类型</th> <th>说明</th></tr></thead> <tbody><tr><td>sourceType</td> <td>int</td> <td>0：主题 1：队列  （cmp中默认0）</td></tr> <tr><td>sourceName</td> <td>String</td> <td>主题或队列名称</td></tr> <tr><td>body</td> <td>byte[]</td> <td>消息体</td></tr> <tr><td>Key</td> <td>String</td> <td>消息体的key</td></tr> <tr><td>Tag</td> <td>String</td> <td>消息的标签</td></tr> <tr><td>groupId</td> <td>Object</td> <td>发往指定分区的关键词，可以为空，如果设置将发往其hash值的分区</td></tr></tbody></table></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.c780e1b6.js" defer></script><script src="/assets/js/2.f44a4f26.js" defer></script><script src="/assets/js/26.f37e9ddb.js" defer></script>
  </body>
</html>
