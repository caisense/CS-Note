声明：本文是对廖雪峰大神的 [Spring Cloud教程](https://www.liaoxuefeng.com/wiki/1252599548343744/1266263401691296) 的学习笔记，仅限于学习交流之用途！

# 0.架构设计

```ascii
           1  ┌───────────┐  2  ┌───────────┐  7  ┌───────────┐
Request  ────>│   User    │────>│  Account  │<────│ Clearing  │
              └───────────┘     └───────────┘     └───────────┘
                                     3│                 ▲
                                      ▼                 │
                                ┌───────────┐           │
                                │   Order   │          6│
                                └───────────┘           │
                                     4│                 │
                                      ▼                 │
                                ┌───────────┐  5  ┌───────────┐
                                │ Sequence  │────>│   Match   │
                                └───────────┘     └───────────┘
                                                        │
                                                        ▼
                                                  ┌───────────┐
Market   <────────────────────────────────────────│ Quotation │
                                                  └───────────┘
```

当一个请求进入交易系统后，首先由用户系统（User）识别用户身份，然后由账户系统（Account）对用户资产进行冻结，买入冻结USD，卖出冻结BTC，冻结如果成功，订单就进入定序系统（Sequence）。

经过定序的订单被送入撮合引擎（Match）。

当撮合引擎输出了成交结果后，该成交记录由清算系统（Clearing）进行清算。清算的工作就是把买单冻结的USD扣掉，并加上买入所得的BTC，同时，把卖单冻结的BTC扣掉，并加上卖出所得的USD。根据taker／maker的费率，向买卖双方收取手续费。

清算系统完成清算后，更新订单状态，再通知用户，用户就可以查询到买卖的成交情况。

在撮合引擎输出成交记录给清算系统的同时，它还把去除用户和订单相关信息的成交记录输出给行情系统（Quotation），由行情系统保存市场的成交价、成交量等信息，并输出实时价格、K线图等技术数据，以便公开市场查询。

## 基于数据库

订单全部存入数据库，并且，每次撮合都基于数据库的订单进行排序，这种完全基于数据库操作，并通过数据库事务保证数据一致性的交易系统，显然性能有限，并且，对数据库的硬件配置有非常高的要求。实际上，这种交易系统的处理能力每秒在100左右，提升系统性能完全依靠数据库服务器的硬件升级

## 基于内存撮合

使用内存撮合的订单处理速度每秒可高达100万，但清算仍然是基于数据库事务，是整个系统的瓶颈，因此，系统的订单处理能力大约能提升到每秒1000单

## 基于内存撮合清算

全内存模型和前面两种设计模型有个很大的区别，就是并不需要多线程并发处理，而是依赖**单线程无锁模型**，让所有计算全部在内存中完成，反而可以轻松获得10万+的量级。

好处是极高的处理速度，此外另一个好处是硬件成本很低，原因是内存非常便宜，单机32G内存就可以轻松实现每秒10万的订单处理速度。注意这里的每秒10万订单是指用户下单到订单撮合、清算全部完毕的整个流程，而不是单独指某个模块的处理速度。

缺点是由于内存的易失性，因为不再通过数据库事务保证数据一致性，如果遭遇宕机、断电等系统故障，交易系统必须能可靠地恢复整个系统的状态

# 1.定序系统

为什么需要设计一个定序系统？因为交易系统的所有订单是一个有序队列。不同的用户在同一时刻下单，也必须由定序系统确定先后顺序。

首先定义要接收的事件消息，它包含一个Sequence ID、上一个Sequence ID以及一个可选的用于去重的全局唯一ID：

```java
public class AbstractEvent extends AbstractMessage {
    // 定序后的Sequence ID:
    public long sequenceId;
    // 定序后的Previous Sequence ID:
    public long previousId;
    // 可选的全局唯一标识:
    @Nullable
    public String uniqueId;
}
```

定序系统接收的事件仅包含可选的`uniqueId`，忽略`sequenceId`和`previousId`。定序完成后，把`sequenceId`和`previousId`设置好，再发送给下游。

`SequenceService`用于接收上游消息、定序、发送消息给下游：

```java
@Component
public class SequenceService {
    @Autowired
    SequenceHandler sequenceHandler;
    // 全局唯一递增ID:
    private AtomicLong sequence;
    // 接收消息并定序再发送:
    synchronized void processMessages(List<AbstractEvent> messages) {
        // 定序后的事件消息:
        List<AbstractEvent> sequenced = null;
        try {
            // 定序:
            sequenced = this.sequenceHandler.sequenceMessages(this.messageTypes, this.sequence, messages);
        } catch (Throwable e) {
            // 定序出错时进程退出:
            logger.error("exception when do sequence", e);
            System.exit(1);
            throw new Error(e);
        }
        // 发送定序后的消息:
        sendMessages(sequenced);
    }
}
```

`SequenceHandler`是真正写入Sequence ID并落库的，在`SequenceService`中调用`SequenceHandler`是因为我们写入数据库时需要利用Spring提供的声明式数据库事务，而消息的接收和发送并不需要被包含在数据库事务中。

## Q：如何在定序器重启后正确初始化下一个序列号？

正确初始化下一个序列号实际上就是要把一个正确的初始值给`AtomicLong sequence`字段。可以读取数据库获得当前最大的Sequence ID，这个Sequence ID就是上次最后一次定序的ID。

## Q：如何在定序器崩溃后自动恢复？

由于任何一个时候都只能有一个定序器工作，这样才能保证Sequence ID的正确性，因此，无法让两个定序器同时工作。

虽然无法让两个定序器同时工作，但可以让两个定序器以主备模式同时运行，仅主定序器工作。当主定序器崩溃后，备用定序器自动切换为主定序器接管后续工作即可。

为了实现主备模式，可以启动两个定序器，然后抢锁的形式确定主备。抢到锁的定序器开始工作，并定期刷新锁，未抢到锁的定序器定期检查锁。可以用数据库锁实现主备模式。

## Q：如何解决定序的性能瓶颈？

通常来说，消息系统的吞吐量远超数据库。定序的性能取决于批量写入数据库的能力。首先要**提高数据库的性能**，其次考虑按Sequence ID进行分库，但分库会提高定序的复杂度，也会使下游从数据库读取消息时复杂度增加。最后，可以考虑使用专门针对时序优化的数据库，但这样就不如MySQL这种数据库通用、易用。

# 2.交易引擎

## 1.1.资产系统

**用户资产**：用户以各种方式将USD、BTC充入交易所后的余额

用户在买入BTC时，需要花费USD，而卖出BTC后，获得USD。当用户下单买入时，系统会先冻结对应的USD金额；当用户下单卖出时，系统会先冻结对应的BTC。

> 之所以需要有**冻结**这一操作，是因为判断能否下单成功，是根据用户的可用资产判断。每下一个新的订单，就会有一部分可用资产被冻结，因此，用户资产本质上是一个由用户ID和资产ID标识的二维表。

使用双层map表示资产： `用户ID -> (资产ID -> Asset)`



在`AssetService`上定义对用户资产的操作。实际上，所有资产操作只有一种操作，即转账。转账类型可用`Transfer`定义为枚举类：

```java
public enum Transfer {
    // 可用转可用:
    AVAILABLE_TO_AVAILABLE,
    // 可用转冻结:
    AVAILABLE_TO_FROZEN,
    // 冻结转可用:
    FROZEN_TO_AVAILABLE;
}
```

转账操作只需要一个`tryTransfer()`方法，实现如下：

```java
public boolean tryTransfer(Transfer type, Long fromUser, Long toUser, AssetEnum assetId, BigDecimal amount, boolean checkBalance) {
    // 转账金额不能为负:
    if (amount.signum() < 0) {
        throw new IllegalArgumentException("Negative amount");
    }
    // 获取源用户资产:
    Asset fromAsset = getAsset(fromUser, assetId);
    if (fromAsset == null) {
        // 资产不存在时初始化用户资产:
        fromAsset = initAssets(fromUser, assetId);
    }
    // 获取目标用户资产:
    Asset toAsset = getAsset(toUser, assetId);
    if (toAsset == null) {
        // 资产不存在时初始化用户资产:
        toAsset = initAssets(toUser, assetId);
    }
    return switch (type) {
        case AVAILABLE_TO_AVAILABLE -> {
            // 需要检查余额且余额不足:
            if (checkBalance && fromAsset.available.compareTo(amount) < 0) {
                // 转账失败:
                yield false;
            }
            // 源用户的可用资产减少:
            fromAsset.available = fromAsset.available.subtract(amount);
            // 目标用户的可用资产增加:
            toAsset.available = toAsset.available.add(amount);
            // 返回成功:
            yield true;
        }
            // 从可用转至冻结:
        case AVAILABLE_TO_FROZEN -> {
            if (checkBalance && fromAsset.available.compareTo(amount) < 0) {
                yield false;
            }
            fromAsset.available = fromAsset.available.subtract(amount);
            toAsset.frozen = toAsset.frozen.add(amount);
            yield true;
        }
            // 从冻结转至可用:
        case FROZEN_TO_AVAILABLE -> {
            if (checkBalance && fromAsset.frozen.compareTo(amount) < 0) {
                yield false;
            }
            fromAsset.frozen = fromAsset.frozen.subtract(amount);
            toAsset.available = toAsset.available.add(amount);
            yield true;
        }
        default -> {
            throw new IllegalArgumentException("invalid type: " + type);
        }
    };
}
```

除了用户存入资产时，需要调用`tryTransfer()`并且不检查余额，因为此操作是从系统负债账户向用户转账，其他常规转账操作均需要检查余额：

```java
public void transfer(Transfer type, Long fromUser, Long toUser, AssetEnum assetId, BigDecimal amount) {
    if (!tryTransfer(type, fromUser, toUser, assetId, amount, true)) {
        throw new RuntimeException("Transfer failed");
    }
}
```

冻结和解冻操作，其实都是在`tryTransfer()`基础上封装。



测试验证：交易所要保证任意操作后，所有用户资产的各余额总和为0（有一个特殊账户--系统账户，用户充值实际上是系统账户对用户账户转账，整个系统无外部金额输入，总和应为0）。

```java
public class AssetServiceTest {
    @Test
    void tryTransfer() {
        // TODO...
    }
}
```



###  Q：为什么不使用数据库？

因为我们要实现的交易引擎是100%全内存交易引擎，因此所有用户资产均存放在内存中，无需访问数据库。

### Q：为什么要使用ConcurrentMap？

**并不是为了让多线程并发写入，而是为了多线程读**

使用`ConcurrentMap`并不是为了让多线程并发写入，因为`AssetService`中并没有任何同步锁。对`AssetService`进行写操作必须是单线程，不支持多线程调用`tryTransfer()`。

但是读取Asset支持多线程并发读取，这也是使用`ConcurrentMap`的原因。如果改成`HashMap`，根据不同JDK版本的实现不同，多线程读取`HashMap`可能造成死循环（注意这不是`HashMap`的bug），必须引入同步机制。

### Q：如何扩展以支持更多的资产类型？

我们在`AssetEnum`中以枚举方式定义了USD和BTC两种资产，如果要扩展到更多资产类型，可以以整型ID作为资产ID，同时需要管理一个资产ID到资产名称的映射，这样可以在业务需要的时候更改资产名称。



## 1.2.订单系统

一个订单由订单ID唯一标识。为简化设计，该对象既作为订单系统的订单对象，也作为数据库映射实体。包含以下重要字段：

- userId：订单关联的用户ID；
- sequenceId：定序ID，相同价格的订单根据定序ID进行排序；
- direction：订单方向：买或卖；
- price：订单价格；
- quantity：订单数量；
- unfilledQuantity：尚未成交的数量；
- status：订单状态，包括等待成交、部分成交、完全成交、部分取消、完全取消。



创建订单：先**冻结**要交易的资产（买入冻结USD，卖出冻结BTC），再创建。一个订单被成功创建后，它后续由撮合引擎处理时，只有`unfilledQuantity`和`status`会发生变化，其他属性均为只读，不会改变。

删除订单：当订单状态变为完全成交、部分取消、完全取消时，订单就已经处理完成。处理完成的订单从订单系统中删除，并写入数据库永久变为历史订单。用户查询活动订单时，需要读取订单系统，用户查询历史订单时，只需从数据库查询，就与订单系统无关了。

 

根据业务需要，订单系统需要支持：

- 根据订单ID查询到订单；
- 根据用户ID查询到该用户的所有活动订单。

因此，`OrderService`需要用两个`Map`存储活动订单：

activeOrders：跟踪所有活动订单`map<OrderID, OrderEntity>`

userOrders：二维map，跟踪用户活动订单`map<UserID, Map<OrderID, OrderEntity>>`

添加和删除Order，要更新这两个map。

```java
/**
 * 创建订单，失败返回null:
 */
public OrderEntity createOrder(long sequenceId, long ts, Long orderId, Long userId, Direction direction, BigDecimal price, BigDecimal quantity) {
    switch (direction) {
    case BUY -> {
        // 买入，需冻结USD：
        if (!assetService.tryFreeze(userId, AssetEnum.USD, price.multiply(quantity))) {
            return null;
        }
    }
    case SELL -> {
        // 卖出，需冻结BTC：
        if (!assetService.tryFreeze(userId, AssetEnum.BTC, quantity)) {
            return null;
        }
    }
    default -> throw new IllegalArgumentException("Invalid direction.");
    }
    // 实例化Order:
    OrderEntity order = new OrderEntity();
    order.id = orderId;
    order.sequenceId = sequenceId;
    order.userId = userId;
    order.direction = direction;
    order.price = price;
    order.quantity = quantity;
    order.unfilledQuantity = quantity;
    order.createdAt = order.updatedAt = ts;
    // 添加到ActiveOrders:
    this.activeOrders.put(order.id, order);
    // 添加到UserOrders:
    ConcurrentMap<Long, OrderEntity> uOrders = this.userOrders.get(userId);
    if (uOrders == null) {
        uOrders = new ConcurrentHashMap<>();
        this.userOrders.put(userId, uOrders);
    }
    uOrders.put(order.id, order);
    return order;
}
```



### Q：Order的id和sequenceId为何不合并使用一个ID？

订单ID是Order.id，是用户看到的订单标识，而Order.sequenceId是系统内部给订单的定序序列号，用于后续撮合时进入订单簿的排序，两者功能不同。

可以使用一个简单的算法来根据Sequence ID计算Order ID：

```
OrderID = SequenceID * 10000 + today("YYmm")
```

因为SequenceID是全局唯一的，我们给SequenceID添加创建日期的"YYmm"部分，可轻松实现按月分库保存和查询。



## 1.3 撮合引擎

撮合引擎是交易系统的核心。本质上就是维护一个**买卖盘**列表，然后按价格优先原则对订单进行撮合，能够成交的就输出成交结果，不能成交的放入买卖盘。这里注意没有时间优先原则，因为经过定序的订单队列已经是一个时间优先的队列了。

### 订单薄OrderBook

用来表示买卖盘

买盘排序：价格高在前，价格相同时间早在前

卖盘排序：价格低在前，价格相同时间早在前

首先考虑list，但插入删除效率低，因此用红黑树（TreeMap实现），以**定序id**比较时间

> 订单上虽然保存了创建时间，但排序时，是根据定序ID即`sequenceId`来排序，以确保全局唯一。时间本身实际上是订单的一个普通属性，仅展示给用户，不参与业务排序。

### 撮合引擎MatchEngine

定义`MatchEngine`核心数据结构如下：

```java
public class MatchEngine {
    public final OrderBook buyBook = new OrderBook(Direction.BUY); // 买盘
    public final OrderBook sellBook = new OrderBook(Direction.SELL); // 卖盘
    public BigDecimal marketPrice = BigDecimal.ZERO; // 最新市场价
    private long sequenceId; // 上次处理的Sequence ID
}
```

一个完整的撮合引擎包含一个买盘、一个卖盘和一个最新成交价（初始值为0）。撮合引擎的输入是一个`OrderEntity`实例，每处理一个订单，就输出撮合结果`MatchResult`。

对于撮合交易来说，如果新订单是一个买单，则首先尝试在卖盘中匹配价格合适的卖单，如果匹配成功则成交。

> 一个大的买单可能会匹配多个较小的卖单。当买单被完全匹配后，说明此买单已完全成交，处理结束，否则，如果存在**未成交的**买单，则将其放入买盘。处理卖单的逻辑是类似的。

已经挂在买卖盘的订单称为挂单（Maker），当前正在处理的订单称为吃单（Taker），一个Taker订单如果**未完全成交**则转为Maker挂在买卖盘。

核心处理方法定义如下：

```java
public MatchResult processOrder(long sequenceId, OrderEntity order) {
    return switch (order.direction) {
            // 买单与sellBook匹配，（如果还有剩）最后放入buyBook:
        case BUY -> processOrder(sequenceId, order, this.sellBook, this.buyBook);
            // 卖单与buyBook匹配，（如果还有剩）最后放入sellBook:
        case SELL -> processOrder(sequenceId, order, this.buyBook, this.sellBook);
        default -> throw new IllegalArgumentException("Invalid direction.");
    };
}
MatchResult processOrder(long sequenceId, OrderEntity takerOrder, OrderBook makerBook, OrderBook anotherBook) {
    ...
}
```

撮合结果记录在`MatchResult`中，它可以用一个Taker订单和一系列撮合匹配记录表示：

```java
public class MatchResult {
    public final Order takerOrder;
    public final List<MatchDetailRecord> MatchDetails = new ArrayList<>();
    // 构造方法略
}
```

 每一笔撮合记录则由成交双方、成交价格与数量表示：

```java
public record MatchDetailRecord(BigDecimal price, BigDecimal quantity, OrderEntity takerOrder, OrderEntity makerOrder) {
}
```

根据价格匹配，直到成交双方有一方完全成交或成交条件不满足时结束处理，`processOrder()`的业务逻辑代码：

```java
/**
     * @param sequenceId 定序id
     * @param takerOrder  当前正在处理的订单
     * @param makerBook   尝试匹配成交的OrderBook（对手盘）
     * @param anotherBook 未能完全成交后挂单的OrderBook
     * @return 成交结果
     */
private MatchResult processOrder(long sequenceId, OrderEntity takerOrder, OrderBook makerBook,
                                 OrderBook anotherBook) {
    this.sequenceId = sequenceId;
    long ts = takerOrder.createdAt;
    MatchResult matchResult = new MatchResult(takerOrder);
    BigDecimal takerUnfilledQuantity = takerOrder.quantity;
    // 一直循环，每次取maker（对手盘）第一个，目标是将taker完全匹配完
    for (;;) {
        OrderEntity makerOrder = makerBook.getFirst();
        if (makerOrder == null) {
            // 对手盘不存在:
            break;
        }
        if (takerOrder.direction == Direction.BUY && takerOrder.price.compareTo(makerOrder.price) < 0) {
            // 买入订单价格比卖盘第一档价格低:
            break;
        } else if (takerOrder.direction == Direction.SELL && takerOrder.price.compareTo(makerOrder.price) > 0) {
            // 卖出订单价格比买盘第一档价格高:
            break;
        }
        // 以Maker价格成交:
        this.marketPrice = makerOrder.price;
        // 待成交数量为两者较小值:
        BigDecimal matchedQuantity = takerUnfilledQuantity.min(makerOrder.unfilledQuantity);
        // 成交记录:（价格、数量、maker
        matchResult.add(makerOrder.price, matchedQuantity, makerOrder);
        // 更新成交后的订单数量:
        // taker数量减去待成交数量
        takerUnfilledQuantity = takerUnfilledQuantity.subtract(matchedQuantity);
        BigDecimal makerUnfilledQuantity = makerOrder.unfilledQuantity.subtract(matchedQuantity);
        // 对手盘完全成交后，从订单簿中删除:
        // 即看成交后的订单数是否为0
        if (makerUnfilledQuantity.signum() == 0) {
            makerOrder.updateOrder(makerUnfilledQuantity, OrderStatus.FULLY_FILLED, ts);
            makerBook.remove(makerOrder);
        } else {
            // 对手盘部分成交:
            makerOrder.updateOrder(makerUnfilledQuantity, OrderStatus.PARTIAL_FILLED, ts);
        }
        // Taker订单完全成交后，退出循环:
        if (takerUnfilledQuantity.signum() == 0) {
            takerOrder.updateOrder(takerUnfilledQuantity, OrderStatus.FULLY_FILLED, ts);
            break;
        }
    } // end for
    // Taker订单未完全成交时，放入买/卖订单簿:
    if (takerUnfilledQuantity.signum() > 0) {
        takerOrder.updateOrder(takerUnfilledQuantity,
                               takerUnfilledQuantity.compareTo(takerOrder.quantity) == 0 ? OrderStatus.PENDING
                               : OrderStatus.PARTIAL_FILLED,
                               ts);
        anotherBook.add(takerOrder);
    }
    return matchResult;
}
```



## 1.4 清算系统

要把撮合结果最终实现为买卖双方的资产交换，就需要清算。清算系统就是处理撮合结果，将买卖双方冻结的USD和BTC分别交换到对方的可用余额，就使得买卖双方真正完成了资产交换。

设计清算系统`ClearingService`，需要引用`AssetService`和`OrderService`：

```java
public class ClearingService {
    final AssetService assetService;
    final OrderService orderService;

    public ClearingService(@Autowired AssetService assetService, @Autowired OrderService orderService) {
        this.assetService = assetService;
        this.orderService = orderService;
    }
}
```

撮合引擎输出`MatchResult`后，`ClearingService`需要处理该结果，，该清算方法代码框架如下：

```java
public void clearMatchResult(MatchResult result) {
    OrderEntity taker = result.takerOrder;
    switch (taker.direction) {
    case BUY -> {
        // TODO
    }
    case SELL -> {
        // TODO
    }
    default -> throw new IllegalArgumentException("Invalid direction.");
    }
}
```

### 买入

买家冻结的USD转入卖方账户，卖方冻结的BTC转入买方账户。

> 对Taker买入成交的订单，处理时需要注意，成交价格是按照Maker的报价成交的，而Taker冻结的金额是按照Taker订单的报价冻结的，因此，解冻后，部分差额要退回至Taker可用余额
>
> 交易资产在哪冻结的？创建订单时。

```java
case BUY -> {
    // 买入时，按Maker的价格成交：
    // 遍历撮合结果的所有匹配记录（taker对应的所有maker）
    for (MatchDetailRecord detail : result.matchDetails) {
        // 从匹配记录中读卖家挂单
        OrderEntity maker = detail.makerOrder();
        // 数量
        BigDecimal matched = detail.quantity();
        /** 【注意】：对Taker买入成交的订单，成交价格是按照Maker的报价成交的，而Taker冻结的金额是按照Taker订单的报价冻结的
                     因此，解冻后，部分差额要退回至Taker可用余额
                 **/
        if (taker.price.compareTo(maker.price) > 0) {
            // 实际买入价比报价低，部分USD退回账户:
            BigDecimal unfreezeQuote = taker.price.subtract(maker.price).multiply(matched);
            logger.debug("unfree extra unused quote {} back to taker user {}", unfreezeQuote, taker.userId);
            assetService.unfreeze(taker.userId, AssetEnum.USD, unfreezeQuote);
        }
        // 买家出USD，换卖家的BTC
        // 买方USD转入卖方账户:
        assetService.transfer(Transfer.FROZEN_TO_AVAILABLE, taker.userId, maker.userId, AssetEnum.USD,
                              maker.price.multiply(matched));
        // 卖方BTC转入买方账户:
        assetService.transfer(Transfer.FROZEN_TO_AVAILABLE, maker.userId, taker.userId, AssetEnum.BTC, matched);
        // 删除完全成交的Maker:
        if (maker.unfilledQuantity.signum() == 0) {
            orderService.removeOrder(maker.id);
        }
    }
    // 删除完全成交的Taker:
    if (taker.unfilledQuantity.signum() == 0) {
        orderService.removeOrder(taker.id);
    }
}
```

### 卖出

**卖家出BTC，换买家的USD**

对Taker卖出成交的订单，只需将冻结的BTC转入Maker，将Maker冻结的USD转入Taker即可：

> 这里不用考虑差价，因为设计下单时，卖单冻结的是BTC，换成USD直接按挂单价换算即可。

```java
case SELL -> {
    // taker是卖单，以maker的价格成交
    for (MatchDetailRecord detail : result.matchDetails) {
        // maker是买家挂单
        OrderEntity maker = detail.makerOrder();
        BigDecimal matched = detail.quantity();
        // 卖家出BTC，换买家的USD
        /**【注意】这里不用考虑差价，因为taker是卖单时，以买单的maker.price成交。
                    设计下单时，卖单冻结的是BTC，换成USD直接按挂单价maker.price换算即可。
                    并不关心taker.price
                    前面买单考虑差价是因为冻结的是USD，最终交易的也是USD，即taker.price与maker.price存在差价
                 **/
        // 卖方BTC转入买方账户:
        assetService.transfer(Transfer.FROZEN_TO_AVAILABLE, taker.userId, maker.userId, AssetEnum.BTC, matched);
        // 买方USD转入卖方账户:
        assetService.transfer(Transfer.FROZEN_TO_AVAILABLE, maker.userId, taker.userId, AssetEnum.USD,
                              maker.price.multiply(matched));
        // 删除完全成交的Maker:
        if (maker.unfilledQuantity.signum() == 0) {
            orderService.removeOrder(maker.id);
        }
    }
    // 删除完全成交的Taker:
    if (taker.unfilledQuantity.signum() == 0) {
        orderService.removeOrder(taker.id);
    }
}
```





## 1.5 完成交易引擎

把上述模块整合，实现一个完整的交易引擎：

```java
public class TradingEngineService {
    @Autowired
    AssetService assetService;

    @Autowired
    OrderService orderService;

    @Autowired
    MatchEngine matchEngine;

    @Autowired
    ClearingService clearingService;
}
```

### 整合定序系统

交易引擎由事件驱动，因此，通过订阅Kafka的Topic实现批量读消息，然后依次处理每个事件。由于【定序系统】的作用，消息的sequenceId应该**严格递增**，考虑消息重复和消息丢失两种情况：

```java
void processMessages(List<AbstractEvent> messages) {
    for (AbstractEvent message : messages) {
        processEvent(message);
    }
}

void processEvent(AbstractEvent event) {
    // 重复消息，丢弃
    if (event.sequenceId <= this.lastSequenceId) {
        logger.warn("skip duplicate event: {}", event);
        return;
    }	
    // 丢失了消息，从数据库读取恢复
    if (event.previousId > this.lastSequenceId) {
        List<AbstractEvent> events = storeService.loadEventsFromDb(this.lastSequenceId);
        if (events.isEmpty()) {    // 读取失败
            System.exit(1);
            return;
        }
        for (AbstractEvent e : events) { // 处理丢失的消息
            this.processEvent(e);
        }
        return;
    }
    // 判断当前消息是否指向上一条消息
    if (event.previousId != lastSequenceId) {
        System.exit(1);  // 不满足说明【系统异常】，退出
        return;
    }
    if (event instanceof OrderRequestEvent) {
        createOrder((OrderRequestEvent) event);
    } else if (event instanceof OrderCancelEvent) {
        cancelOrder((OrderCancelEvent) event);
    } else if (event instanceof TransferEvent) {
        transfer((TransferEvent) event);
    }
}
```

这样，对消息系统的依赖就不是要求它100%可靠，遇到重复消息、丢失消息，交易引擎都可以从这些错误中自己恢复。

目前一共有3种类型的事件：创建订单、取消订单、转账，处理都非常简单。以`createOrder()`为例，核心代码很少：

```java
void createOrder(OrderRequestEvent event) {
    // 生成Order ID:
    long orderId = event.sequenceId * 10000 + (year * 100 + month);
    // 创建Order:
    OrderEntity order = orderService.createOrder(event.sequenceId, event.createdAt, orderId, event.userId, event.direction, event.price, event.quantity);
    if (order == null) {
        logger.warn("create order failed.");
        return;
    }
    // 撮合:
    MatchResult result = matchEngine.processOrder(event.sequenceId, order);
    // 清算:
    clearingService.clearMatchResult(result);
}
```

### 异步处理

核心的业务逻辑并不复杂，只是交易引擎在处理完订单后，仅仅改变自身状态是不够的，它还得向外输出具体的成交信息、订单状态等。

因此，需要根据业务需求，在清算后继续收集撮合结果、已完成订单、准备发送的通知等，通过消息系统或Redis向外输出交易信息。

如果把这些功能放到同一个线程内同步完成是非常耗时的，更好的方法是把它们先存储起来，再**异步处理**。

例如，对于已完成的订单，可以异步落库：

```java
Queue<List<OrderEntity>> orderQueue = new ConcurrentLinkedQueue<>();

void createOrder(OrderRequestEvent event) {
    ...
    // 清算完成后,收集已完成Order:
    if (!result.matchDetails.isEmpty()) {
        List<OrderEntity> closedOrders = new ArrayList<>();
        if (result.takerOrder.status.isFinalStatus) {
            closedOrders.add(result.takerOrder);
        }
        for (MatchDetailRecord detail : result.matchDetails) {
            OrderEntity maker = detail.makerOrder();
            if (maker.status.isFinalStatus) {
                closedOrders.add(maker);
            }
        }
        this.orderQueue.add(closedOrders);
    }
}

// 启动一个线程将orderQueue的Order异步写入数据库:
void saveOrders() {
    // TODO:
}
```

类似的，输出OrderBook、通知用户成交等信息都是异步处理。

### 验证模块

由于资产、订单、撮合、清算都在内存中完成，如何保证交易引擎每处理一个事件，它的内部状态都是正确的呢？我们可以为交易引擎增加一个自验证功能，在debug模式下，每处理一个事件，就自动验证内部状态的完整性，包括：

- 验证资产系统总额为0，且除负债账户外其余账户资产不为负；
- 验证订单系统未成交订单所冻结的资产与资产系统中的冻结一致；
- 验证订单系统的订单与撮合引擎的订单簿一对一存在。

```java
void processEvent(AbstractEvent event) {
    ...
    if (debugMode) {
        this.validate();
    }
    void validate() {
        logger.debug("start validate...");
        validateAssets();
        validateOrders();
        validateMatchEngine();
        logger.debug("validate ok.");
    }
}
```

这样我们就能快速在开发阶段尽可能早地发现问题。

### Q：交易引擎崩溃后如何恢复？

交易引擎如果运行时崩溃，可以重启，然后把现有的**所有交易事件重头开始执行一遍**，即可得到最新的状态。

注意到重头开始执行交易事件，会导致重复发出市场成交、用户订单通知等事件，因此，可根据时间做判断，不再重复发通知。下游系统在处理通知事件时，也要根据通知携带的`sequenceId`做去重判断。

### Q：如果现有的交易事件太多，恢复需要花费几天，怎么办？

可以定期把交易引擎的**状态序列化**至文件系统，例如，每10分钟一次。当交易引擎崩溃时，读取最新的状态文件，即可恢复至约10分钟前的状态，后续追赶只需要执行很少的事件消息。

交易引擎的状态包括：

- 资产系统的状态：即所有用户的资产列表；
- 订单系统的状态：即所有活动订单列表；
- 撮合引擎的状态：即买卖盘和最新市场价；
- 最后一次处理的sequenceId。

序列化时，分别针对每个子系统进行序列化。对资产系统来说，每个用户的资产可序列化为`用户ID: [USD可用, USD冻结, BTC可用, BTC冻结]`的JSON格式，整个资产系统序列化后结构如下：

```json
{
    "1": [-123000, 0, -12.3, 0],
    "100": [60000, 20000, 9, 0],
    "200": [43000, 0, 3, 0.3]
}
```

订单系统可序列化为一系列活动订单列表：

```json
[
    { "id": 10012207, "sequenceId": 1001, "price": 20901, ...},
    { "id": 10022207, "sequenceId": 1002, "price": 20902, ...},
]
```

撮合引擎可序列化为买卖盘列表（仅包含订单ID）：

```json
{
    "BUY": [10012207, 10022207, ...],
    "SELL": [...],
    "marketPrice": 20901
}
```

最后合并为一个交易引擎的状态文件：

```json
{
    "sequenceId": 189000,
    "assets": { ... },
    "orders": [ ... ],
    "match": { ... }
}
```

交易引擎启动时，读取状态文件，然后依次恢复资产系统、订单系统和撮合引擎的状态，就得到了指定`sequenceId`的状态。

写入状态时，如果是异步写入，需要先复制状态、再写入，防止多线程读同一实例导致状态不一致。读写JSON时，要使用JSON库的流式API（例如Jackson的Streaming API），以免内存溢出。对`BigDecimal`进行序列化时，要注意不要误读为`double`类型以免丢失精度。

# 3.API系统

有了交易引擎和定序系统，还需一个API系统，用于接收所有交易员的订单请求。相比事件驱动的交易引擎，API系统就比较简单，因为它就是一个标准的Web应用。

在编写API之前，需要对请求进行认证，即识别出是哪个用户发出的请求。用户认证放在Filter中最合适。认证方式可以是简单粗暴的用户名+口令，也可以是Token，也可以是API Key+API Secret等模式。

先实现一个最简单的用户名+口令的认证方式。需要注意的是，API和Web页面不同，Web页面可以给用户一个登录页，登录成功后设置Session或Cookie，后续请求检查的是Session或Cookie。API不能使用Session，因为Session很难做无状态集群，API也不建议使用Cookie，因为API域名很可能与Web UI的域名不一致，拿不到Cookie。要在API中使用用户名+口令的认证方式，可以用标准的HTTP头[Authorization](https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Authorization)的`Basic`模式：

```
Authorization: Basic 用户名:口令
```

尝试从`Authorization`中获取用户名和口令来认证：

```java
Long parseUserFromAuthorization(String auth) {
    if (auth.startsWith("Basic ")) {
        // 用Base64解码:
        String eap = new String(Base64.getDecoder().decode(auth.substring(6)));
        // 分离email:password
        int pos = eap.indexOf(':');
        String email = eap.substring(0, pos);
        String passwd = eap.substring(pos + 1);
        // 验证:
        UserProfileEntity p = userService.signin(email, passwd);
        return p.userId;
    }
    throw new ApiException(ApiError.AUTH_SIGNIN_FAILED, "Invalid Authorization header.");
}
```

在`ApiFilter`中完成认证后，使用`UserContext`传递用户ID，：

```java
public class ApiFilter  {
    @Override
    public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain)
        throws IOException, ServletException {
        // 尝试认证用户:
        String authHeader = req.getHeader("Authorization");
        Long userId = authHeader == null ? null : parseUserFromAuthorization(authHeader);
        if (userId == null) {
            // 匿名身份:
            chain.doFilter(req, resp);
        } else {
            // 用户身份:
            // ************* ctx未直接使用，仅用来通过ThreadLocal传递用户ID *****************
            try (UserContext ctx = new UserContext(userId)) { 
                chain.doFilter(req, resp);
            }
        }
    }
}

```

**注意**：ApiFilter中创建了UserContext却没使用，是因为将用户ID保存在ThreadLocal，通过线程上下文传递

```java
public class UserContext implements AutoCloseable {
    static final ThreadLocal<Long> THREAD_LOCAL_CTX = new ThreadLocal<>();
}
```

Basic模式很简单，需要注意的是`用户名:口令`使用`:`分隔，然后整个串用Base64编码，因此，读取的时候需要先用Base64解码。

虽然Basic模式并不安全，但是有了一种基本的认证模式，我们就可以把API-定序-交易串起来了。后续我们再继续添加其他认证模式。

## 编写API Controller

对于认证用户的操作，例如，查询资产余额，可通过`UserContext`获取当前用户，然后通过交易引擎查询并返回用户资产余额：

```java
@ResponseBody
@GetMapping(value = "/assets", produces = "application/json")
public String getAssets() throws IOException {
    Long userId = UserContext.getRequiredUserId();
    return tradingEngineApiProxyService.get("/internal/" + userId + "/assets");
}
```

因为交易引擎返回的结果就是JSON字符串，没必要先反序列化再序列化，可以以`String`的方式直接返回给客户端，需要标注`@ResponseBody`表示不要对`String`再进行序列化处理。

对于无需认证的操作，例如，查询公开市场的订单簿，可以直接返回Redis缓存结果：

```java
@ResponseBody
@GetMapping(value = "/orderBook", produces = "application/json")
public String getOrderBook() {
    String data = redisService.get(RedisCache.Key.ORDER_BOOK);
    return data == null ? OrderBookBean.EMPTY : data;
}
```

但是对于创建订单的请求，处理就麻烦一些，因为API收到请求后，仅仅通过消息系统给定序系统发了一条消息。消息系统本身并不是类似HTTP的请求-响应模式，我们拿不到消息处理的结果。这里先借助Spring的异步响应模型`DeferredResult`，再借助Redis的pub/sub模型，当API发送消息时，使用全局唯一`refId`跟踪消息，当交易引擎处理完订单请求后，向Redis发送pub事件，API收到Redis推送的事件后，根据`refId`找到`DeferredResult`，设置结果后由Spring异步返回给客户端：

```ascii
   ┌─────────┐                 ┌─────────┐
──>│   API   │<────────────────│  Redis  │
   └─────────┘                 └─────────┘
        │                           ▲
        ▼                           │
   ┌─────────┐                      │
   │   MQ    │                   pub│
   └─────────┘                      │
        │                           │
        ▼                           │
   ┌─────────┐   ┌─────────┐   ┌─────────┐
   │Sequencer│──>│   MQ    │──>│ Engine  │
   └─────────┘   └─────────┘   └─────────┘
```

代码实现如下：

```java
public class TradingApiController {
    // 消息refId -> DeferredResult:
    Map<String, DeferredResult<ResponseEntity<String>>> deferredResultMap = new ConcurrentHashMap<>();

    @Autowired
    RedisService redisService;

    @PostConstruct
    public void init() {
        // 订阅Redis:
        this.redisService.subscribe(RedisCache.Topic.TRADING_API_RESULT, this::onApiResultMessage);
    }

    @PostMapping(value = "/orders", produces = "application/json")
    @ResponseBody
    public DeferredResult<ResponseEntity<String>> createOrder(@RequestBody OrderRequestBean orderRequest) {
        final Long userId = UserContext.getRequiredUserId();
        // 消息的Reference ID:
        final String refId = IdUtil.generateUniqueId();
        var event = new OrderRequestEvent();
        event.refId = refId;
        event.userId = userId;
        event.direction = orderRequest.direction;
        event.price = orderRequest.price;
        event.quantity = orderRequest.quantity;
        event.createdAt = System.currentTimeMillis();
        // 如果超时则返回:
        ResponseEntity<String> timeout = new ResponseEntity<>(getTimeoutJson(), HttpStatus.BAD_REQUEST);
        // 正常异步返回:
        DeferredResult<ResponseEntity<String>> deferred = new DeferredResult<>(500, timeout); // 0.5秒超时
        deferred.onTimeout(() -> {
            this.deferredResultMap.remove(event.refId);
        });
        // 根据refId跟踪消息处理结果:
        this.deferredResultMap.put(event.refId, deferred);
        // 发送消息:
        sendMessage(event);
        return deferred;
    }

    // 收到Redis的消息结果推送:
    public void onApiResultMessage(String msg) {
        ApiResultMessage message = objectMapper.readValue(msg, ApiResultMessage.class);
        if (message.refId != null) {
            // 根据消息refId查找DeferredResult:
            DeferredResult<ResponseEntity<String>> deferred = this.deferredResultMap.remove(message.refId);
            if (deferred != null) {
                // 找到DeferredResult后设置响应结果:
                ResponseEntity<String> resp = new ResponseEntity<>(JsonUtil.writeJson(message.result), HttpStatus.OK);
                deferred.setResult(resp);
            }
        }
    }
}
```

## 如何实现API Key认证

添加一个`api_auths`表，存储API Key、API Secret并关联至某个用户ID：

| userId | apiKey           | apiSecret        |
| :----- | :--------------- | :--------------- |
| 101    | 5b503947f4f5d34a | e57c677d4ab4c5a4 |
| 102    | 13a867e8da13c7f6 | 92e41573e833ae13 |
| 102    | 341a8e60baf5b824 | 302c9e195826267f |

用户使用API Key认证时，提供API Key，以及用API Secret计算的Hmac哈希，服务器验证Hmac哈希后，就可以确认用户身份，因为其他人不知道该用户的API Secret，无法计算出正确的Hmac。

发送API Key认证时，可以定义如下的HTTP头：

```
API-Key: 5b503947f4f5d34a
API-Timestamp: 20220726T092137Z <- 防止重放攻击的时间戳
API-Signature: d7a567b6cab85bcd
```

计算签名的原始输入可以包括HTTP Method、Path、Timestamp、Body等关键信息，具体格式可参考[AWS API签名方式](https://docs.aws.amazon.com/zh_cn/general/latest/gr/signature-version-4.html)。

一个用户可以关联多个API Key认证，还可以给每个API Key附加特定权限，例如只读权限，这样用API Key认证就更加安全。

### 内部系统调用API如何实现用户认证

很多时候，内部系统也需要调用API，并且需要以特定用户的身份调用API。让内部系统去读用户的口令或者API Key都是不合理的，更好的方式是使用一次性Token，还是利用Authorization头的Bearer模式：

```
Authorization: Bearer 5NPtI6LW...
```

构造一次性Token可以用`userId:expires:hmac`，内部系统和API共享同一个Hmac Key，就可以正确计算并验证签名。外部用户因为无法获得Hmac Key而无法伪造Token。

### 如何跟踪API性能

可以使用Spring提供的`HandlerInterceptor`和`DeferredResultProcessingInterceptor`跟踪API性能，它们分别用于拦截同步API和异步API。

# 4.行情系统

行情系统用来生成公开市场的历史数据，主要是**K线图**。需要按1秒、1分钟、1小时和1天来生成不同类型的K线，因此，行情系统的功能就是不断从消息系统中读取Tick，合并，然后输出不同类型的K线。

> K线图的数据来源是交易引擎成交产生的一个个Tick。一个K线包括OHLC这4个价格数据。在一个时间段内，第一个Tick的价格是Open，最后一个Tick的价格是Close，最高的价格是High，最低的价格是Low：
> 
  ```ascii
       High -> │
               │
             ┌─┴─┐<─ Close
             │   │
     Open -> └─┬─┘
               │
        Low -> │
     ```


给定一组Tick集合，就可以汇总成一个K线，对应一个Bar结构：


```java
public class AbstractBarEntity {
    public long startTime; // 开始时间
    public BigDecimal openPrice; // 开始价格
    public BigDecimal highPrice; // 最高价格
    public BigDecimal lowPrice; // 最低价格
    public BigDecimal closePrice; // 结束价格
    public BigDecimal quantity; // 成交数量
}
```

行情系统是典型的**读多写少**模式，非常适合缓存，因此最近的成交信息和K线图，缓存在**Redis**中，对于较早的K线图，通过**数据库**查询。因此，行情系统需要将生成的K线保存到数据库中，同时负责不断更新Redis的缓存。

## 缓存redis

对于最新成交信息，在Redis中用一个**List**表示，它的每一个元素是一个序列号后的JSON：

```
["{...}", "{...}", "{...}"...]
```

如果有新的Tick产生，就需要把它们追加到列表尾部，同时将最早的Tick删除，以便维护一个**最近成交的列表**（100条）。

**Lua脚本**

直接读取Redis列表，操作后再写回Redis是可以的，但比较麻烦。这里我们直接用**Lua脚本**更新最新Tick列表。

> Redis支持将一个Lua脚本加载后，直接在Redis内部执行脚本

```lua
local KEY_LAST_SEQ = '_TickSeq_' -- 上次更新的SequenceID
local LIST_RECENT_TICKS = KEYS[1] -- 最新Ticks的Key

local seqId = ARGV[1] -- 输入的SequenceID
local jsonData = ARGV[2] -- 输入的JSON字符串表示的tick数组："["{...}","{...}",...]"
local strData = ARGV[3] -- 输入的JSON字符串表示的tick数组："[{...},{...},...]"

-- 获取上次更新的sequenceId:
local lastSeqId = redis.call('GET', KEY_LAST_SEQ)
local ticks, len;

if not lastSeqId or tonumber(seqId) > tonumber(lastSeqId) then
    -- 广播:
    redis.call('PUBLISH', 'notification', '{"type":"tick","sequenceId":' .. seqId .. ',"data":' .. jsonData .. '}')
    -- 保存当前sequence id:
    redis.call('SET', KEY_LAST_SEQ, seqId)
    -- 更新最新tick列表:
    ticks = cjson.decode(strData)
    len = redis.call('RPUSH', LIST_RECENT_TICKS, unpack(ticks))
    if len > 100 then
        -- 裁剪LIST以保存最新的100个Tick:
        redis.call('LTRIM', LIST_RECENT_TICKS, len-100, len-1)
    end
    return true
end
-- 无更新返回false
return false
```

在API中，要获取最新成交信息，直接从Redis缓存取出列表，然后拼接成一个JSON字符串：

```java
@ResponseBody
@GetMapping(value = "/ticks", produces = "application/json")
public String getRecentTicks() {
    List<String> data = redisService.lrange(RedisCache.Key.RECENT_TICKS, 0, -1);
    if (data == null || data.isEmpty()) {
        return "[]";
    }
    StringJoiner sj = new StringJoiner(",", "[", "]");
    for (String t : data) {
        sj.add(t);
    }
    return sj.toString();
}
```

用Lua脚本还有一个好处，就是执行时不但可以更新List，还可以通过**Publish**命令广播事件，后续我们编写基于WebSocket的推送服务器时，直接监听Redis广播，就可以主动向浏览器推送Tick更新的事件。

类似的，针对每一种K线，我们都在Redis中用ZSet存储，用K线的开始时间戳作为Score。更新K线时，从每种ZSet中找出Score最大的Bar结构，就是最后一个Bar，然后尝试更新。如果可以持久化这个Bar就返回，如果可以合并这个Bar就刷新ZSet，用Lua脚本实现如下：

common/src/main/resources/redis/update-bar.lua

## 编写QuotationService

```java
@Component
public class QuotationService {

    @Autowired
    RedisService redisService;

    @Autowired
    MessagingFactory messagingFactory;

    MessageConsumer tickConsumer;

    private String shaUpdateRecentTicksLua = null;
    private String shaUpdateBarLua = null;

    @PostConstruct
    public void init() throws Exception {
        // 加载Redis脚本:
        this.shaUpdateRecentTicksLua = this.redisService.loadScriptFromClassPath("/redis/update-recent-ticks.lua");
        this.shaUpdateBarLua = this.redisService.loadScriptFromClassPath("/redis/update-bar.lua");
        // 接收Tick消息:
        String groupId = Messaging.Topic.TICK.name() + "_" + IpUtil.getHostId();
        this.tickConsumer = messagingFactory.createBatchMessageListener(Messaging.Topic.TICK, groupId,
                this::processMessages);
    }

    // 处理接收的消息:
    public void processMessages(List<AbstractMessage> messages) {
        for (AbstractMessage message : messages) {
            processMessage((TickMessage) message);
        }
    }

    // 处理一个Tick消息:
    void processMessage(TickMessage message) {
        // 对一个Tick消息中的多个Tick先进行合并:
        final long createdAt = message.createdAt;
        StringJoiner ticksStrJoiner = new StringJoiner(",", "[", "]");
        StringJoiner ticksJoiner = new StringJoiner(",", "[", "]");
        BigDecimal openPrice = BigDecimal.ZERO;
        BigDecimal closePrice = BigDecimal.ZERO;
        BigDecimal highPrice = BigDecimal.ZERO;
        BigDecimal lowPrice = BigDecimal.ZERO;
        BigDecimal quantity = BigDecimal.ZERO;
        for (TickEntity tick : message.ticks) {
            String json = tick.toJson();
            ticksStrJoiner.add("\"" + json + "\"");
            ticksJoiner.add(json);
            if (openPrice.signum() == 0) {
                openPrice = tick.price;
                closePrice = tick.price;
                highPrice = tick.price;
                lowPrice = tick.price;
            } else {
                // open price is set:
                closePrice = tick.price;
                highPrice = highPrice.max(tick.price);
                lowPrice = lowPrice.min(tick.price);
            }
            quantity = quantity.add(tick.quantity);
        }
        // 计算应该合并的每种类型的Bar的开始时间:
        long sec = createdAt / 1000;
        long min = sec / 60;
        long hour = min / 60;
        long secStartTime = sec * 1000;
        long minStartTime = min * 60 * 1000;
        long hourStartTime = hour * 3600 * 1000;
        long dayStartTime = Instant.ofEpochMilli(hourStartTime).atZone(zoneId).withHour(0).toEpochSecond() * 1000;
        // ******************** k线数据准备完毕 ***************************
        // 1、更新Redis最近的Ticks缓存:
        // 更新Tick缓存:
        String ticksData = ticksJoiner.toString();
        Boolean tickOk = redisService.executeScriptReturnBoolean(this.shaUpdateRecentTicksLua,
                new String[] { RedisCache.Key.RECENT_TICKS },
                new String[] { String.valueOf(this.sequenceId), ticksData, ticksStrJoiner.toString() });
        if (!tickOk.booleanValue()) {
            logger.warn("ticks are ignored by Redis.");
            return;
        }
         // 2、保存Tick至数据库:
        saveTicks(message.ticks);

        // 3、更新redis各种类型的K线:
        String strCreatedBars = redisService.executeScriptReturnString(this.shaUpdateBarLua,
                new String[] { RedisCache.Key.SEC_BARS, RedisCache.Key.MIN_BARS, RedisCache.Key.HOUR_BARS,
                        RedisCache.Key.DAY_BARS },
                new String[] { // ARGV
                        String.valueOf(this.sequenceId), // sequence id
                        String.valueOf(secStartTime), // sec-start-time
                        String.valueOf(minStartTime), // min-start-time
                        String.valueOf(hourStartTime), // hour-start-time
                        String.valueOf(dayStartTime), // day-start-time
                        String.valueOf(openPrice), // open
                        String.valueOf(highPrice), // high
                        String.valueOf(lowPrice), // low
                        String.valueOf(closePrice), // close
                        String.valueOf(quantity) // quantity
                });
        Map<BarType, BigDecimal[]> barMap = JsonUtil.readJson(strCreatedBars, TYPE_BARS);
        if (!barMap.isEmpty()) {
            // 保存Bar:
            SecBarEntity secBar = createBar(SecBarEntity::new, barMap.get(BarType.SEC));
            MinBarEntity minBar = createBar(MinBarEntity::new, barMap.get(BarType.MIN));
            HourBarEntity hourBar = createBar(HourBarEntity::new, barMap.get(BarType.HOUR));
            DayBarEntity dayBar = createBar(DayBarEntity::new, barMap.get(BarType.DAY));
            saveBars(secBar, minBar, hourBar, dayBar);
        }
    }
}
```

K线是一组Bar按ZSet缓存在Redis中，Score就是Bar的开始时间。更新Bar时，同时广播通知，以便后续推送。要查询某种K线图，在API中，需要传入开始和结束的时间戳，通过ZRANGE命令返回排序后的List：

```java
private String getBars(String key, long start, long end) {
    // k线以时间为score排序，取时间在[start, end]之间的数据
    List<String> data = redisService.zrangebyscore(key, start, end);
    if (data == null || data.isEmpty()) {
        return "[]";
    }
    StringJoiner sj = new StringJoiner(",", "[", "]");
    for (String t : data) {
        sj.add(t);
    }
    return sj.toString();
}
```



# 5.推送系统

推送系统负责将公开市场的实时信息，包括订单簿、最新成交、最新K线等推送给客户端，对于用户的订单，还需要将成交信息推送给指定用户。

和普通Web应用不同的是，基于Servlet的线程池模型不能高效地支持成百上千的WebSocket长连接。Java提供了NIO能充分利用Linux系统的epoll机制高效支持大量的长连接，但是直接使用NIO的接口非常繁琐，通常我们会选择基于NIO的[Netty](https://netty.io/)服务器。直接使用Netty其实仍然比较繁琐，基于Netty开发我们可以选择：

- Spring WebFlux：封装了Netty并实现Reactive接口；
- Vert.x：封装了Netty并提供简单的API接口。

这里我们选择[Vert.x](https://vertx.io/)，因为它的API更简单。

启动类：

```java
@SpringBootApplication
// 禁用数据库自动配置 (无DataSource, JdbcTemplate...)
@EnableAutoConfiguration(exclude = DataSourceAutoConfiguration.class)
public class PushApplication {
    public static void main(String[] args) {
        System.setProperty("vertx.disableFileCPResolving", "true");
        System.setProperty("vertx.logger-delegate-factory-class-name", "io.vertx.core.logging.SLF4JLogDelegateFactory");
        SpringApplication app = new SpringApplication(PushApplication.class);
        // 禁用Spring的Web:
        app.setWebApplicationType(WebApplicationType.NONE);
        app.run(args);
    }
}
```

由于需要利用Spring Cloud Config读取配置，所以推送系统仍然是标准springboot应用。由于不使用Spring自身的Web功能，因此需要禁用Spring的Web功能。推送服务本身并不需要访问数据库，因此禁用数据库自动配置。最后，把`PushApplication`放在`com.itranswarp.exchange.push`包下面，以避免自动扫描到`com.itranswarp.exchange`包下的组件（如RedisService）。

## PushService

然后编写`PushService`，注意它是一个Spring组件，由Spring初始化，目的是注入各种配置。在初始化方法中，就可以启动Vert.x：

```java
@PostConstruct
public void startVertx() {
    // 启动Vert.x:
    this.vertx = Vertx.vertx();

    // 创建一个Vert.x Verticle组件:
    var push = new PushVerticle(this.hmacKey, this.serverPort);
    vertx.deployVerticle(push);

    // 连接到Redis:
    String url = "redis://" + (this.redisPassword.isEmpty() ? "" : ":" + this.redisPassword + "@") + this.redisHost
            + ":" + this.redisPort + "/" + this.redisDatabase;
    Redis redis = Redis.createClient(vertx, url);

    redis.connect().onSuccess(conn -> {
        // 事件处理:
        conn.handler(response -> {
            // 收到Redis的PUSH:
            if (response.type() == ResponseType.PUSH) {
                int size = response.size();
                if (size == 3) {
                    Response type = response.get(2);
                    if (type instanceof BulkType) {
                        // 收到PUBLISH通知:
                        String msg = type.toString();
                        // 由push verticle组件处理该通知:
                        push.broadcast(msg);
                    }
                }
            }
        });
        // 订阅Redis的Topic:
        conn.send(Request.cmd(Command.SUBSCRIBE).arg(RedisCache.Topic.NOTIFICATION)).onSuccess(resp -> {
            logger.info("subscribe ok.");
        }).onFailure(err -> {
            logger.error("subscribe failed.", err);
            System.exit(1);
        });
    }).onFailure(err -> {
        logger.error("connect to redis failed.", err);
        System.exit(1);
    });
}
```

## PushVerticle

Vert.x用`Verticle`表示一个组件，编写`PushVerticle`来处理所有WebSocket连接，重写其`start()`方法，由Vert.x回调。`start()`方法主要逻辑：

1. 创建基于Vert.x的HTTP服务器（内部使用Netty）；
2. 创建路由；
3. 绑定一个路径为`/notification`的GET请求，将其**升级为WebSocket**连接；
4. 绑定其他路径的GET请求；
5. 开始监听指定端口号。

在Vert.x中，每个WebSocket连接都有一个唯一的Handler标识，以`String`表示。用几个`Map`保存Handler和用户ID的映射关系，当关闭连接时，将对应的映射关系删除。

```java
// 所有Handler:
Map<String, Boolean> handlersSet = new ConcurrentHashMap<>(1000);

// 用户ID -> Handlers
Map<Long, Set<String>> userToHandlersMap = new ConcurrentHashMap<>(1000);

// Handler -> 用户ID
Map<String, Long> handlerToUserMap = new ConcurrentHashMap<>(1000);
```

最后一个关键方法`broadcast()`由`PushService`中订阅的Redis推送时触发（前提是向Redis订阅了`notification`这个Topic，使用 [Redis的发布订阅](Redis.md#发布订阅) 功能），用于向用户主动推送通知。当Redis收到`PUBLISH`调用后，自动触发`broadcast()`，将`String`表示的JSON数据推送给所有订阅端（实际上只有一个单例），从而推送给所有WebSocket客户端。

对于一个`NotificationMessage`，如果设置了`userId`，则推送给指定用户，适用于订单成交等针对用户ID的通知；如果没有设置`userId`，则推送给所有用户，适用于公开市场信息的推送。

```java
链路：       广播                 push
      redis -----> PushVerticle ------> Verticle组件管理的所有WebSocket
```

整个推送服务仅包括3个Java文件，我们就实现了基于Redis和WebSocket的高性能推送。



# 6.ui系统

UI系统就是一个标准的Web系统，本质上是一个MVC模型，视图页面都放在`src/main/resources/templates/`目录下。

编写MvcController实现登录，登录成功后，设置一个Cookie代表用户身份，以`userId:expiresAt:hash`表示。由于计算哈希引入了`HmacKey`，因此，客户端无法伪造Cookie。：

```java
@Controller
public class MvcController extends LoggerSupport {
    // 显示登录页
    @GetMapping("/signin")
    public ModelAndView signin(HttpServletRequest request) {
        if (UserContext.getUserId() != null) {
            return redirect("/");
        }
        return prepareModelAndView("signin");
    }

    // 登录
    @PostMapping("/signin")
    public ModelAndView signIn(@RequestParam("email") String email, @RequestParam("password") String password, HttpServletRequest request, HttpServletResponse response) {
        try {
            UserProfileEntity userProfile = userService.signin(email, password);
            // 登录成功后设置Cookie:
            AuthToken token = new AuthToken(userProfile.userId, System.currentTimeMillis() + 1000 * cookieService.getExpiresInSeconds());
            cookieService.setSessionCookie(request, response, token);
        } catch (ApiException e) {
            // 登录失败:
            return prepareModelAndView("signin", Map.of("email", email, "error", "Invalid email or password."));
        } catch (Exception e) {
            // 登录失败:
            return prepareModelAndView("signin", Map.of("email", email, "error", "Internal server error."));
        }
        // 登录成功跳转:
        return redirect("/");
    }
}
```

编写`UIFilter`，用于验证Cookie并把特定用户的身份绑定到`UserContext`中：

```java
public class UIFilter {
    @Override
    public void doFilter(ServletRequest req, ServletResponse resp, FilterChain chain)
            throws IOException, ServletException {
        // 查找Cookie:
        AuthToken auth = cookieService.findSessionCookie(req);
        Long userId = auth == null ? null : auth.userId();
        try (UserContext ctx = new UserContext(userId)) {
            chain.doFilter(request, response);
        }
    }
}
```

编写`ProxyFilter`，将页面JavaScript对API的调用转发给API系统：

```java
public class ProxyFilter {
    @Override
    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)
            throws IOException, ServletException {
        Long userId = UserContext.getUserId();
        // 构造【一次性】Token:
        String authToken = null;
        if (userId != null) {
            AuthToken token = new AuthToken(userId, System.currentTimeMillis() + 60_000);
            authToken = "Bearer " + token.toSecureString(hmacKey);
        }
        // 转发到API并读取响应：
        String responseJson = null;
        try {
            if ("GET".equals(request.getMethod())) {
                Map<String, String[]> params = request.getParameterMap();
                Map<String, String> query = params.isEmpty() ? null : convertParams(params);
                responseJson = tradingApiClient.get(String.class, request.getRequestURI(), authToken, query);
            } else if ("POST".equals(request.getMethod())) {
                responseJson = tradingApiClient.post(String.class, request.getRequestURI(), authToken,
                        readBody(request));
            }
            // 写入响应:
            response.setContentType("application/json;charset=utf-8");
            PrintWriter pw = response.getWriter();
            pw.write(responseJson);
            pw.flush();
        } catch (ApiException e) {
            // 写入错误响应:
            writeApiException(request, response, e);
        } catch (Exception e) {
            // 写入错误响应:
            writeApiException(request, response,
                    new ApiException(ApiError.INTERNAL_SERVER_ERROR, null, e.getMessage()));
        }
    }
}
```

把`ProxyFilter`挂载到`/api/*`，通过UI转发请求的目的是简化页面JavaScript调用API，一是不再需要跨域，二是UI已经经过了登录认证，转发过程中自动生成**一次性**Token来调用API，这样JavaScript不再关心如何生成`Authorization`头。
