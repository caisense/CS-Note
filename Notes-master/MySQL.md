# MySQL笔记

## MySQL架构

### MySQL的基本架构

总体上，MySQL架构可以分为两层：Server层和存储引擎层；

- Server层：负责绝大多数的核心服务、内置函数和所有跨存储引擎的功能，包括存储过程、触发器、视图等；
  - 连接器：管理连接、权限验证；
  - 分析器：词法分析、语法分析；
  - 查询缓存：当缓存命中时直接返回结果；
  - 优化器：生成执行计划、索引选择；
  - 执行器：操作存储引擎、返回结果；
- 存储引擎层：负责数据的存储和提取，架构模型是插件式的，支持InnoDB、MyISAM、Memory等引擎；从MySQL 5.5.5版本开始，默认存储引擎为InnoDB。通过` engine=xxx `语句可手动指定使用的存储引擎。

### 一条MySQL查询语句的执行过程

客户端发起MySQL请求语句后，MySQL执行的流程如下

1. 连接到连接器。连接语句为` mysql -h$ip -P$port -u$user -p `，然后输入密码；连接器负责建立TCP连接，并验证用户身份；若验证通过，则连接器会从权限表中查询用户所拥有的权限，用于此后该连接中的权限判断。

   连接完成后，若客户端没有后续请求，则连接处于空闲状态，连接器在等待一段时间后会自动关闭连接，默认为8h，可通过` wait_timeout `参数控制。

2. 查询缓存。连接建立后，执行逻辑的第二步为查询缓存；执行过的语句可能以key-value的形式保存在查询缓存中，若查询语句匹配到缓存值，则直接返回结果；若查询不到缓存值，则继续后面的步骤，待执行完成后，执行结果会被存入查询缓存中。

3. 分析器处理。若未命中查询缓存，则逻辑进入到分析器，对语句进行解析。首先进行词法分析，对语句中的关键字进行识别，如"select"表示这是一条查询语句，"T"表示表名等；然后进行语法分析，基于词法分析的结果，判断语句是否符合语法规则。

4. 优化器处理。优化器的主要工作有：若表中存在多个索引，决定使用哪个索引；若一个语句中存在表关联（join），决定各个表的连接顺序；等等。

5. 执行器执行语句。执行器处理前首先判断用户是否有对表的操作权限，权限验证通过后，执行器使用引擎提供的接口执行语句。

### MySQL中的长连接和短连接

长连接指在连接成功后，若客户端有持续请求，则会一直使用同一个连接；短连接则是每次执行完查询就断开连接，在下次查询时重新建立。

建立连接的过程相对复杂，需要占用系统开销，因此使用长连接可以减少系统的负担。但长连接也存在缺点，MySQL执行过程中临时使用的内存是保存在连接对象中的，这些资源会在连接断开时被释放，若全部使用长连接，可能会导致内存占用过大，发生OOM错误，从而被系统强行杀死，从现象上看造成了MySQL的异常重启。

避免长连接可能带来的OOM问题有以下措施：

- 定期断开长连接。在指定的时间后，或判断执行过占用较大内存的大查询后，主动断开连接，之后再重新建立；
- MySQL 5.7版本后，可以在每次执行较大内存占用的操作后，通过执行` mysql_reset_connection `重新初始化连接资源，此过程不需要重新建立连接和权限校验，但会将连接恢复到刚创建时的状态。

### 查询缓存的利弊

- 优点：当缓存命中时，MySQL可以跳过后续的分析器、优化器、执行器等操作，无需操作存储引擎，直接返回结果，该操作效率很高。
- 缺点：实际上，查询缓存的失效非常频繁，一旦对一个表进行了更新操作，那么这个表上所有的查询缓存都会被清空。因此对于更新压力较大的数据库，查询缓存的命中率非常低。在这种场景下，查询缓存不能对效率的提升非常有限，且系统增加了维护查询缓存的开销。一般情况下，只有业务使用的是静态表（如系统配置表）时，这个表才适用于使用查询缓存。

MySQL中可通过将` query_cache_type `参数设置为` DEMAND `，默认不使用查询缓存。当需要使用查询缓存时，再通过` SQL_CACHE `显式指定。注意：MySQL 8.0版本后直接删除了查询缓存的功能，彻底不能使用了。

## MySQL中的数据结构

### 日志

MySQL中的日志系统包括两个重要部分：redo log（重做日志）、binlog（归档日志）

#### redo log

redo log工作在引擎层。是一种物理日志。redo log记录的是“在某个数据页上做了某条修改”。

作用：当一条记录需要更新时，InnoDB引擎会先将记录写到redo log中，并更新内存，此时更新就算完成。InnoDB会在适当的时机（系统比较空闲时），再将操作记录更新到磁盘中。

redo log为一组确定大小的循环维护的配置文件，维护一个write pos表示当前记录的位置，一个check point表示当前擦除的位置（已经录入磁盘，且不再需要该记录），在write pos和check point之间的空间可以用来记录新的操作。若write pos追上了check point，则不再能执行新的更新，需要等待check point推进。

redo log为InnoDB引擎提供了**crash-safe**的能力。

#### binlog

binlog工作在server层，所有引擎都可以使用。binlog是一种逻辑日志，记录的是语句的原始逻辑，如“给ID=x这一行的m字段+1”。

不同于redo log的循环维护，binlog采用追加写入的方式，在binlog文件达到一个大小后，会切换到下一个binlog文件，不如覆盖以前的日志。

由于binlog追加写入的特性，因此binlog为数据库提供了**归档**能力。

#### 数据库崩溃后如何恢复？

由于binlog会记录所有的逻辑操作，且采用追加写的方式，因此，一旦数据库崩溃，首先找到最近的全量备份，然后从备份的时间点开始，将备份的binlog依次取出，重放到错误发生之前的状态。

### 一条MySQL更新语句的执行过程

类似查询语句，更新语句同样会经历从连接器到执行器，再调用引擎层接口的过程，重点区别在于执行器的处理：

1. 执行器在存储引擎中寻找满足条件的行。若目标行所在的数据页在内存中，则直接返回给执行器，否则需要先从磁盘中将目标页读入内存，然后返回。
2. 执行器执行更新操作，修改数据，再调用引擎接口写入新数据；
3. 引擎将新数据更新到内存中，同时将记录写入到redo log中，此时redo log处于prepare状态。然后告知执行器更新完成，可以提交事务。
4. 执行器生成这条操作的binlog，将binlog写入磁盘。
5. 执行器调用引擎接口提交事务，引擎将redo log更改为commit状态，更新完成。

其中，步骤3和步骤5，redo log的两次状态变更，即为所谓的“两阶段提交”。两阶段提交保证了数据库在发生错误需要恢复时，能正确地恢复到错误前的状态，若不使用两阶段提交，即redo log完全在binlog之前完成，或binlog在redo log发生之前完成，则可能出现以下情况：

- 先写redo log后写binlog。若在binlog写完之前MySQL发生了异常重启，那么由于引擎已经写完了redo log，那么数据在磁盘上依然会被更新，但由于binlog没有写完，恢复后的数据库中逻辑上丢失了这一次更新。
- 先写binlog后写redo log。若在redo log写完之前系统crash，由于redo log未完成，则该事务无效，数据不会被更新，但恢复后的数据库中逻辑上保存了该更新事务，同样会造成数据不一致。

## 索引

### 常见的索引数据结构

常见的可以用于索引的数据结构有：

- 哈希表：哈希表以key-value的形式存储数据。通过一个哈希函数将key换算为一个确定的位置，然后把value放在数组的这个位置上。当哈希表出现冲突时，常见的处理方式是在该位置拉出一个链表。哈希表的优势在于：1）其查找某个确切的key时速度很快，效率较高；2）插入新的值时，速度很快。但由于哈希表其本身是无序的，因此对区间查找的支持很差，需要遍历查询区间内的每一个待查询的key。因此，哈希表结构只适用于**只有等值查询的场景**，如Memcached等NoSQL引擎。
- 有序数组：有序数组在等值查询和范围查询场景中的性能非常优秀，若只考虑查询性能，则有序数据可以说是最好的数据结构。但在需要更新数据时，如向数组中插入新的值时，必须依次挪动后续的所有记录，成本太高。因此，有序数组只适用于**静态存储引擎**。
- 搜索树：搜索树分为很多类型，其中最基础经典的就是二叉搜索树。
  - 二叉搜索树。二叉搜索树的性质为：父节点的左子树中的所有值都小于父节点维护的值，右子树中的所有值都大于父节点维护的值。因此，二叉搜索树的查询复杂度也是O(log(n))。但为了保障查询复杂度，需要维护二叉树是一颗平衡树，因此插入记录的复杂度也是O(log(n))。相对于多叉树，二叉树的搜索效率是最高的，但实际上大多数数据库的存储并不使用二叉树，原因是：索引不仅存在于内存中，还存在于磁盘上。对内存的访问是相对高效的，而从磁盘读取数据的消耗相对是很大的。二叉树不同节点的数据有可能存在于不同的磁盘页上，因此使用二叉树作为索引的结构，有可能需要大量执行磁盘的读取操作，效率很低。
  - N叉树。相对于二叉树，N叉树可以显著减少对磁盘的访问次数，更适合作为索引的数据结构。

### InnoDB的索引结构

InnoDB采用B+树作为索引的数据结构，所有的数据都存放在B+树中。**每一个索引都对应了一棵B+树**。

B+树是多叉树的一种（平衡多路查找树），所有节点的关键字按照递增顺序排列，左小右大。B+树有以下特点：

- 非叶节点不保存实际的记录，只进行数据索引；
- 叶节点保存了父节点所有的关键字记录的指针，所有的数据地址都必须到叶节点中获取，因此对B+树，其每次查询到效率是固定的；
- B+树叶节点的关键字从小到大排序，左侧的结尾数据会保存右边节点开始的指针；
- B+树所有的叶节点天然形成了一个有序链表，对区间查找的支持度更高；

相对于B树，B+树的非叶节点可以保存的关键字更多，树的层级更少（树形更矮胖），查询效率稳定，区间查找和全表扫描的效率更高。

### 主键索引/非主键索引

主键索引primary key和非主键索引在MySQL中的数据结构是不同的。对主键索引而言，其对应的B+树中的叶节点存储的是**整行数据**；而对于非主键索引，其对应的B+树中的叶节点存储的是**主键的值**。

因此，主键索引在InnoDB中也称为**聚簇索引**，而非主键索引（普通索引）则称为**二级索引**（非聚簇索引）。

当基于这两种索引进行查询时，MySQL的表现存在区别：

- 基于主键索引查询时，只需要搜索主键索引对应的B+树，从叶节点获取数据行；
- 基于普通索引查询时，先搜索普通索引对应的B+树，然后从叶节点中获取数据行对应的主键值；再到主键索引对应的B+树中，基于主键值进行查找，从叶节点获取实际的数据行。该过程称为**回表**；

因此，为了减少扫描索引树的次数，应当尽量使用主键查询。

在MySQL中，很多业务场景要求一定要单独设置主键，且主键应当设置为非空自增` NOT NULL PRIMARY KEY AUTO_INCREMENT `，这样做的好处是，在向B+树插入新的数据时，都是追加操作。新的记录直接插入到树的最后，不涉及挪动其他记录。也不会触发叶节点的分裂。若使用业务逻辑的字段作为主键，则不容易保证有序叉入，写数据的成本会很高。且业务逻辑的字段有可能长度较大，增加了索引树占用的空间大小（对其他每个索引的B+树而言，其叶子节点都要维护主键的值）。因此，使用单独的自增主键，从性能和存储空间的角度来看都有好处。

也存在少量可以不使用自增主键作为索引的场景，如业务要求：只有一个索引，且该索引是唯一索引（典型的K-V场景）。由于不存在其他索引，因此不需要考虑其他索引的索引树的叶节点大小。此时为了避免回表问题，可以直接将该索引设为主键。

### “覆盖索引”

当查询的目标值已经保存在某个索引对应的B+树的叶节点上时，可以直接返回结果，而不需要到主键对应的B+树中进行回表查找。此时可成该索引已经覆盖了我们的查询需求，称为覆盖索引。

覆盖索引可以避免多次回表，对提高查询效率很有帮助。因此，对于高频请求，可以考虑对请求值和其基于的索引建立**联合索引**，这样，在基于该联合索引请求时，其叶节点中直接储存了需要的值，不需要通过主键回表查询整个数据行。缺点是联合索引本身也要占据空间。

### 最左前缀原则

MySQL中索引匹配遵循最左前缀原则，即：

- 对于联合索引，MySQL按照索引定义中出现的字段顺序进行排序。如联合索引“name, age”，可以用于匹配name是“张三”或”张%“的数据行。
- 对于字符串类型的索引，MySQL同样可以按照字符串的前N个字符进行匹配。

总而言之，MySQL的最左前缀原则可以是联合索引的最左前N个字段，也可以是字符串索引的最左M个字符。

在建立联合索引时，应当恰当地安排索引的顺序，如果某种顺序可以使我们少维护一条索引，那么该顺序就应当被考虑。

PS：除了考虑最左前缀原则以维护尽量少的索引外，在建立联合索引时，如业务存在对联合索引中的每个单独字段分别查询的需求，则需要将索引占用空间的大小纳入考虑。

### 索引下推

MySQL 5.6以后，引入了索引下推的优化。

若不使用索引下推优化，则当MySQL根据索引（最左前缀原则）匹配到索引值符合要求的数据行后，需要逐条回表，到主键索引上找出数据行，然后比对剩余的条件是否满足。

在使用索引下推优化后，则MySQL可以在索引的遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 唯一索引和普通索引的性能差异

#### 查询过程的差异

对一条查询语句，例如` select * from t where k=5; `来说，对于普通索引，在查找到满足条件的第一条记录后，还要继续查找下一个记录，直到碰到第一个不满足k=5条件的记录；对于唯一索引，由于索引定义了唯一性，查找到第一个满足条件的记录后就会停止检索。

但是，这一点差异带来的性能差距几乎可以忽略不计，因为InnoDB的数据是按照数据页为单位读写的。当需要读取一条记录时，并不是将记录本身从磁盘中读取出来，而是将其所在的数据页整体读入内存，因此，对普通索引来说，其多出的查找操作，只需要进行指针寻找和计算即可，除非满足条件的记录刚好是数据页的最后一条记录，才需要读取下一个数据页，但出现这种情况的概率很低，因此平均性能差异可以忽略不计。

#### 更新过程的差异

对更新语句来说，首先需要了解change buffer的概念：

**change buffer**

当需要更新一个数据页时，如果数据页在内存中，则直接更新；如果数据页不在内存中，在不影响数据一致性的前提下，InnoDB会将更新操作缓存在change buffer中（减少磁盘读取数据页的次数）。在需要访问数据页的时候，再将数据页读入内存，然后执行change buffer中与该页有关的操作，该过程称为merge。

注：change buffer是可以持久化的数据，即change buffer在内存中有拷贝，也会被写入到磁盘上。change buffer使用的内存空间是buffer pool里的内存，可以通过参数` innodb_change_buffer_max_size `参数进行动态设置，如设置为50表示change buffer最多占用50%的buffer pool空间。

对唯一索引来说，所有的更新操作都要判断其是否违反唯一性约束，必须要将数据页读入内存才能判断，对已经存入内存的数据，不会使用change buffer缓存更新操作。普通索引则可以使用change buffer进行缓存。

因此，当对数据进行更新时，若数据的目标页已经在内存中，则两种索引的性能差异几乎可以忽略；若数据不在内存中，则对于唯一索引，需要将目标页读入内存，而对于普通索引，可以直接将更新记录在change buffer中，因此普通索引对更新性能的提升很明显。

**Tips：redo log 和 change buffer对性能提升的区别**

redo log主要节省的是随机写磁盘的IO消耗（转为顺序写），而change buffer节省的是随机读磁盘的IO消耗。

#### 普通索引一定能提升更新性能吗？

取决于业务场景。对于写多读少的业务而言，页面在写完后立刻被访问的概率较低，因此普通索引使用change buffer的效果较好，如账单、日志类的系统；对于写入后立刻需要查询的业务场景，虽然记录先被存入了change buffer，但由于立刻需要查询，同样需要将数据页读入内存，相反，反而增加了change buffer进行merge的维护代价，因此对这种业务场景来说，change buffer起到了副作用。

## 事务和视图

### 1 事务的ACID特性

事务是一系列操作的集合，它们要么全部完成，要么全部被丢弃。MySQL的事务具备ACID特性：

- A：Atomicity 原子性。事务的操作要么全部成功，要么全部失败并回滚；
- C：Consistency 一致性。事务的发生只会将数据从一个正确的状态更新为另一个正确的状态；
- I：Isolation 隔离性。事务不会被并发的其他事务中的操作干扰；
- D：Durability 持久性。事务对数据库的改变是永久性的。

不是所有的数据库引擎都支持事务，如MySQL原生的MyISAM引擎就不支持事务，这也是它被InnoDB取代的重要原因之一。

### 2 InnoDB中事务的隔离级别

InnoDB支持的事务隔离级别从低到高有：

- read uncommitted：读未提交。允许读取其他事务未提交的数据；
- read committed：读提交。允许读取其他事务已提交的数据；
- repeatable read：可重复读。指一个事务在其执行过程中，对同一条数据读取到的值始终一致；
- serializable：串行化。所有事务串行化处理，隔离级别最高，但效率低。

从实现方式上，事务的隔离级别是通过视图实现的，事务访问数据以视图的逻辑结果为准。对于“读未提交”隔离级别，事务直接获取当前记录上的最新值，没有视图概念；对于“读提交”隔离级别，视图在SQL语句开始执行时创建；对于“可重复读”隔离级别，视图在事务启动时创建；对于“串行化”隔离级别，直接采用加锁的方式避免并行访问。

不同的引擎默认的隔离级别可能不同，InnoDB引擎默认的事务隔离级别为repeatable read，而部分数据库，如Oracle的默认隔离级别为read committed，因为对于从Oracle数据库迁移到MySQL的应用，为保证隔离级别一致，需要通过设置启动参数` transaction-isolation `设置为` READ-COMMITTED `来手动修改隔离级别。

### 3 并发事务可能导致的问题

常见的由于事务并发可能导致的问题有：

- 脏读：事务A读取了事务B未提交的数据，随后事务B发生异常并回滚，事务A读取到的数据是错误的。

  read committed及更高的隔离级别可以防止脏读。

- 不可重复读：同一事务对同一行数据前后两次读取到的值不一致，原因是在两次读取的过程中，其他事务修改了数据的值并提交了更新。

  repeatable read及更高的隔离级别可以防止不可重复读。

- 幻读：事务A两次查询，前一次查询涉及整表数据（如读取表中所有“字段n的值大于x”的行），此时另一个事务B对数据表进行了增加数据行或删除数据行的操作，事务A再次查询整表数据时，第二次的结果中包含了第一次查询结果中没有的值或缺少了部分值。

  serializable隔离级别可以防止幻读。

- 更新丢失：

  更新丢失分为两种：

  1. 第一类更新丢失（回滚丢失，lost update）

     事务A在回滚时，覆盖了事务B已提交的数据。

  2. 第二类更新丢失（覆盖丢失，second lost update）

     事务A的更新提交覆盖了事务B已提交的数据，造成事务B的更新丢失。

  其中，所有隔离级别的事务都不允许第一类更新丢失发生；第二类更新丢失本质上和不可重复读是同一问题，repeatable read及更高的隔离级别可以防止第二类更新丢失。

### 4 事务的启动

#### 事务的启动方式

MySQL中事务的显式启动语句为：` begin/start transaction `，对应的提交语句为` commit `，回滚语句为` rollback `。

自动提交参数` autocommit `：

- 若将该参数配置为1，则MySQL会为输入的任意SQL语句自动创建一个事务，并在语句执行完毕后提交该事务；若在开启了autocommit的情况下，用户使用` begin transaction `显式开启了事务，则MySQL将不会自动为用户提交事务，用户需要手动执行` commit `语句进行提交，若用户未提交便断开了连接，则事务会回滚；
- 若将该参数配置为0，则会将线程的自动提交关闭，此时MySQL依然会为SQL语句自动开启事务，但不会自动关闭。事务会一直持续到主动执行commit或rollback，或断开连接。若用户一直没有主动commit，则有可能造成无意间的长事务。

MySQL中的每条更新操作都会记录一条redo log，redo log会在没有事务使用到它时被删除。如果使用了长事务，意味着系统里会存在很老的事务视图，相关的事务的可能用到的所有redo log都必须保留，从而占用大量的存储空间。此外，长事务还有可能长时间地占用锁资源，有可能拖垮整个数据库。因此，若想尽量减少语句的交互，可以通过使用语句：` commit work and chain `替换` commit `，使当前事务被提交后自动开启下一个事务。

#### 事务实际的启动时机

事实上，事务并非在` begin/start transaction `语句执行时就立即启动，而是在执行到它们之后的第一个操作InnoDB表的语句时，事务才真正启动。如果需要立刻启动事务，应该使用语句` start transaction with consistent snapshot `。

相对的，普通的启动方式中，一致性视图是在执行第一个快照读取语句时创建；第二种启动方式中，一致性视图在执行语句` start transaction with consistent snapshot `时创建（可重复读隔离级别，视图随着事务的启动创建）。

### 5 视图

#### MySQL中的两种视图

1. view。

   view是一个用查询语句定义的虚拟表，调用时执行查询语句并生成结果。语法为` create view ... AS `。视图可以基于单表或多表创建，其查询方法和表一样。

   使用视图时，用户不需要了解基本表的结构，更接触不到实际表中的数据，保证了数据库的安全。

2. InnoDB在实现MVCC时用到的一致性视图，即consistent read view，用于支持Read Commit和Repeatable Read隔离级别的实现。

#### 一致性视图的实现

在RR隔离级别下，事务启动时会创建数据库的快照，该快照是基于**全库**的。该快照不要拷贝全库的数据，其实现方式如下：

1. InnoDB中每个事务有唯一的事务ID（transaction id），在事务开始时向MySQL的事务系统申请，按申请顺序严格递增。
2. 每行数据也有多个版本，每次事务更新数据时，都会生成一个新的数据版本，并将其transaction id赋值给这个数据版本的的事务ID，记为` row trx_id `。

InnoDB为每个事务构造了一个数组，保存在这个事务启动的瞬间，当前正在活跃（启动了但尚未提交）的事务的事务ID。数组中的事务ID的最小值记为“低水位”，当前系统中已创建过的事务ID的最大值+1记为“高水位”。对一个数据版本的` row trx_id `，将其与高低水位的事务ID进行比对，判断其是否可见，若不可见则追溯其历史版本，直到找到可见版本。

因此，在事务启动的瞬间，数据版本对其有三种可能的情况：

- 版本未提交，不可见；
- 版本已提交，但在视图创建后提交，不可见；
- 版本已提交，且在视图创建前提交，可见。

InnoDB利用数据的多版本特性，实现了秒级创建快照的能力，无需拷贝全库数据，只需要比对数据版本和当前活跃的事务ID即可。

### 4 MVCC

MVCC即MySQL数据库的多版本并发控制，即同一条记录在系统中可以同时存在多个不同的版本。是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始时的快照。 MVCC可以为数据库解决以下问题：

- 在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能；
- 同时还可以解决脏读，幻读，不可重复读等事务隔离问题（但不能解决更新丢失问题）；

#### 当前读和快照读

**当前读**即为从系统中读取数据的当前值，包括：

- 更新逻辑（update）中的读：更新数据需要先读后写，不能在历史版本（一致性视图）上操作，否则，其他事务的更新有可能丢失。


- select语句加锁对查询语句进行加锁，也可实现当前读。使用的语句为` lock in share mode `（S锁，共享锁）或` for update `（X锁，排他锁），如：

  ```sql
  select k from t where id = 1 lock in share mode;
  select k from t where id = 1 for update;
  ```

**快照读**即为从事务开始时的快照中读取数据的值。快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读。如：不加锁的select操作就是快照读。

## 锁

### 1 数据库锁的设计目的

处理并发访问，合理控制资源的访问规则。

### 2 MySQL中的锁的级别

全局锁、表级锁、行锁。

#### 2.1 全局锁

对整个数据库实例进行加锁，语句为：` Flush tables with read lock ` **(FTWRL)**。全局锁状态下，其他线程的以下语句会被阻塞：

- 数据更新语句（增删改）
- 数据定义语句（建表、修改表结构等）
- 更新类事务的commit语句

全局锁的使用场景为：**全库逻辑备份**

##### 使用FTWRL进行全库逻辑备份的缺陷？

1）如果在主库上进行备份，则业务会全部停摆；

2）如果在从库上进行备份，则从库在备份期间不能执行从主库同步过来的binlog，导致主从延迟。

MySQL的逻辑备份工具mysqldump可以通过使用参数` -single-transaction `启动事务拿到一致性视图进行备份操作，避免FTWRL的风险。但使用一致性读要求数据库引擎支持事务和对应的隔离级别（可重复读），对于例如MyISAM等不支持事务的引擎，就需要使用FTWRL命令。

##### 为什么不用`set global readonly=true`语句实现全库只读？

- 某些系统中，readonly字段的值有可能被用来做其他逻辑，如判断主库/备库等；


- 如果在FTWRL过程中出现异常，MySQL会释放该全局锁；若设置readonly后发生异常，则整个数据库会长时间处于不可写状态，风险高。
- readonly设置对超级权限（super）用户是无效的；

#### 2.2 表级锁

MySQL中的表级锁有两种：1）表锁 2）元数据锁

##### 表锁

语句为` lock table ... read/write `，类似FTWRL，可以使用unlock语句主动释放，也可以在客户端断开时自动释放。

表锁除了限制其他线程的读写外，也会限制当前线程的操作对象。如语句` lock tables t1 read, t2 write `，则其他线程写 `t1 `和读写` t2 `的语句都会被阻塞，而当前线程也只能执行读` t1 `和读写` t2 `的操作，不允许写 ` t1 `，也不能访问其他表。

表锁的影响仍然太大，不推荐使用，一般在数据库引擎不支持行锁的情况下才被使用。

##### 元数据锁 metadata lock (MDL)

元数据锁不需要显示使用，在访问一个表时会被自动加上。在MySQL 5.5版本中引入，具体加锁逻辑如下：

- 对一个表做增删改查操作（DML）时，加MDL读锁
- 对一个表做表结构变更（DDL）时，加MDL写锁

MDL锁直到事务提交才被释放（而非语句执行完毕），在进行表结构变更（DDL）时，要注意不能导致锁住线上查询和更新。

##### 如何安全地进行表结构变更？

- 避免长事务；事务不提交就会一直占据MDL锁。可在MySQL的` information_schema ` 库的` innodb_trx `表中查询到当前正在执行的长事务。若需要进行表结构变更的表上有长事务正在执行，应当考虑暂停该DDL操作，或kill该事务；
- 若业务请求非常频繁，则可以考虑为DDL操作加上指定的等待时间，若在等待时间内拿不到MDL写锁，则放弃。语句为` ALTER TABLE T WAIT N add column ... `

#### 2.3 行锁

针对数据表中行记录的锁。由数据库引擎实现，若引擎不支持行锁（如MyISAM），则只能使用表锁，影响业务并发度。

InnoDB引擎支持行锁，其加锁和释放锁的逻辑为：行锁在**需要使用**的时候才加上，但并不是不需要了就立刻释放，而是**事务结束**才释放。因此，使用行锁时，需要调整语句顺序，将最有可能造成锁冲突、最可能影响并发度的锁的申请时机尽量往后放。

行锁的加锁方式为：

- 对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加上排他锁；

- 对于普通SELECT语句，InnoDB不会加任何锁；可以手动显式进行加锁（共享锁或排他锁）：

  ```sql
  select * from tableName where ... lock in share more
  select * from tableName where ... for update
  ```

### 3 乐观锁和悲观锁

乐观锁和悲观锁是处理并发冲突的两种不同的思想，并不是物理意义上的锁机制。

- 乐观锁

  乐观锁认为数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。如果发现冲突了，则返回错误信息，让用户决定如何去做。一般通过版本号或时间戳的方式实现。

  - 版本号实现方式：为数据库表增加一个数字类型的 “version” 字段，当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值+1。当提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据，返回更新失败。

  - 时间戳实现方式：在表中增加一个时间戳字段，和version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则予以更新，否则返回更新失败。

- 悲观锁

  悲观锁即对于并发的环境持悲观态度，认为总会发生并发冲突，在整个数据处理过程中，需要将数据锁定。悲观锁的实现，通常依靠数据库提供的锁机制实现，如通过MySQL提供的互斥锁实现。语句为：

  ```sql
  select ... for update
  ```

  使用悲观锁需要注意两点：

  - 需要关闭MySQL的自动提交功能，` set autocommit = 0 `；
  - MySQL中的行级锁是基于索引的，` select ... for update `语句执行中所有扫描过的行都会被锁上，因此在MySQL中用悲观锁务必须确定走了索引，而不是全表扫描，否则将会将整个数据表锁住。虽然MySQL做了优化，对于不满足条件的记录，会在判断后再次释放锁，最终事务持有的是满足条件的记录上的锁。但是，对于不满足条件的记录，其加锁/放锁的动作是不会省略的，这是一个耗时过程。

### 4 间隙锁

间隙锁是一个在索引记录之间的间隙上的锁。其作用为：保证某个间隙内的数据在锁定情况下不会发生任何变化。

#### 间隙锁的使用情形

当使用唯一索引来搜索唯一行的语句时，不需要间隙锁。

- 语句中筛选的列没有建立索引或者是非唯一索引时，语句会产生间隙锁；

- 搜索条件里有多个查询条件（即使每个列都有唯一索引），也会使间隙锁。

#### 间隙锁的锁定范围

根据检索条件向下寻找最靠近检索条件的记录值A作为左区间，向上寻找最靠近检索条件的记录值B作为右区间，即锁定的间隙为（A，B）。

当搜索条件里有多个查询条件是，间隙锁会

### 5 常见的锁相关问题

#### 什么是死锁？

不同线程间出现循环资源依赖，涉及的线程都在等待其他线程释放资源，会造成线程进入无限等待的状态，称为死锁。

#### 死锁的四个条件是？

1. 互斥：资源只能被排他性使用
2. 请求与保持：进程已经保持了一个资源，又请求新的资源
3. 不可剥夺：资源在被使用完之前不可被其他进程夺走
4. 循坏等待

#### InnoDB解决死锁的方案有？

1. 直接进入等待，直到超时。超时等待时间可通过` innodb_lock_wait_timeout `参数来设置；

2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务。将参数` innodb_deadlock_detect `设置为on即可开启。

方法1的缺陷在于，如果超时等待时间长，其他线程需要长时间等待，性能下降无法接受；如果超时等待时间短，如果不是死锁而是普通的锁等待状态，会出现大量误伤。

方法2的缺陷在于，死锁检测会带来额外负担，如果大量事务对同一行热点数据请求锁，则每个被堵塞的线程，都要判断会不会由于自己的加入导致了死锁，时间复杂度为O(n)，会消耗大量CPU资源。

#### 如何解决热点行更新带来的性能问题？

1. 关闭死锁检测。缺点：有可能带来大量超时，对业务是有损的。

2. 控制并发度。并发控制需要在服务端或中间件实现（在客户端控制是没有意义的，最后汇合到服务端并发量依然非常大），基本思路为：对相同行的更新，在进入引擎前排队。

3. 设计优化。将一行改为逻辑上的多行，例如，将一行记录拆成10个记录，对原记录的操作就改为对这10条记录的随机操作，冲突概率就降低为原来的1/10，可减少锁等待个数，降低CPU消耗。缺点是需要根据业务逻辑详细设计，比如当拆分后的某条记录为0时，需要特殊处理。

#### 什么是两阶段锁协议（Two-phase locking, 2PL）?

两段锁协议规定所有的事务应遵守以下规则：

- 在对任何数据进行读、写操作之前，首先要申请并获得对该数据的锁；

- 在释放一个锁之后，事务不再申请和获得其它任何锁。

即事务的执行分为两个阶段：获得锁的阶段，即扩展阶段，和释放锁的阶段，即收缩阶段。

所有的unlock操作都发生在lock操作之后。





## 其他知识点

### join语句

#### 三种不同的join逻辑

join语句用于多表联合查询。按照功能可分为三类：

- join 内连接（等值连接）：获取两个表中字段匹配的记录。
- left join左连接：获取左表的所有记录，即使右表没有对应匹配的记录。
- right join 右连接：获取右表的所有记录，即使左表没有对应匹配的记录。

驱动表（首先被处理的表）的选择：

对于左连接，左表即位驱动表；对于右连接，右表为驱动表；与表中的记录行数无关。

对于内连接，则MySQL优化器会分别对两种情况计算需要的扫描行数，然后选择扫描行数更少的情况，决定驱动表。

#### straight join语句

straight join语句从表现上与inner join一致，区别在于straight join固定使用左表作为驱动表。

straight join的逻辑为，对驱动表做全表扫描，对于每一行数据，根据待匹配的字段从被驱动表中查找对应的行，若被驱动表中的该字段存在索引，则会走树搜索，否则也需要进行全表扫描。

显然，驱动表的行数对整体的扫描行数的影响更大，因此，在使用straight join语句时，应当选择行数更少的表作为驱动表。

#### Index Nested-Loop Join

当被驱动表上做表联合的字段存在索引时，MySQL对join语句的处理逻辑为：对驱动表做全表扫描，对于每一行数据，根据待匹配的字段，利用索引走树搜索，从被驱动表中查找对应的行。

#### Simple Nested-Loop Join

当被驱动表未对查询的字段建立索引时，一种简单的处理方法是直接进行两次全表扫描，对驱动表中的每条数据，都需要到被驱动表中进行全表搜索，时间复杂度是O(N*M)。这种暴力搜索法称为Simple Nested-Loop Join。实际上MySQL并未使用该算法。

#### Block Nested-Loop Join

实际上MySQL在处理被驱动表无索引的情况时，使用的算法为Block Nested-Loop Join，其逻辑为：将驱动表的待查询列和表联合的匹配项读入线程内存，保存在join_buffer中（若语句是select *则读入全部数据），然后扫描被驱动表，把它的每一行数据取出，然后与join_buffer中的数据比对，满足join条件的作为结果返回。

从时间复杂度上，Block Nested-Loop Join同样需要N*M数量级的扫描次数。但Block Nested-Loop Join的判断是内存操作，因此性能上明显强于Simple Nested-Loop Join。

当驱动表不大时，可以整表放入join_buffer，而当驱动表过大时，可以对其分块处理。每次从驱动表中读取一部分内容，直到join_buffer满，处理完毕后再读入剩余的数据，直到处理完毕。由于每次处理join_buffer的内容都需要对被驱动表做全表扫描，因此join_buffer_size越大，分段越少，效率越高。

#### 业务中能否使用join语句？

取决于语句执行的是Index Nested-Loop Join还是Block Nested-Loop Join，即能否利用索引避免被驱动表的全表扫描。可以使用Explain语句查看Extra字段中是否出现"Block Nested Loop"字样。一般如果可以使用Index Nested-Loop Join，则性能上是ok的，否则尽量避免使用。

若需要使用join语句，则当使用Index Nested-Loop Join时，应选择小表作为驱动表；若使用了Block Nested-Loop Join，则当join_buffer_size足够大时，没有区别，若join_buffer_size不够大需要分块处理，则同样需要选择小表作为驱动表。注意，此处的小表并非指表的实际大小，而是按照条件过滤后，参与join的字段的总数据量。

### union语句

**UNION**操作符用于连接两个以上的SELECT语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。

若要保存重复的数据，则可以使用**UNION ALL**操作符。

### explain语句

最初的explain语句只能用于查询一条select语句是如何被MySQL执行的。在select语句前加上explain关键字，则MySQL不会实际地执行这条查询，而是返回执行计划的信息（如果查询语句的from部分存在子查询，则自查询会被执行，结果会被保存到临时表）。explain语句会对查询中的每个表返回一行结果，如果有两个表通过join连结，则会输出两行。

对一条select语句执行explain操作会输出以下信息：

```
1. id //select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序
2. select_type //查询类型，如SIMPLE,PRIMARY,SUBQUERY,UNION等
3. table //正在访问哪个表
4. partitions //匹配的分区
5. type //访问的类型，
6. possible_keys //显示可能应用在这张表中的索引，一个或多个，但不一定实际使用到
7. key //实际使用到的索引，如果为NULL，则没有使用索引
8. key_len //表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度
9. ref //显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值
10. rows //根据表统计信息及索引选用情况，大致估算出找到所需的记录所需读取的行数
11. filtered //查询的表行占表的百分比
12. Extra //包含不适合在其它列中显示但十分重要的额外信息
```

MySQL 5.6版本后，explain语句也可以对增删改操作（DDL）执行了。

### count()语句

在MySQL中，count()的语义为：对于返回的结果集，逐行判断，若count()函数的参数对应的值不是NULL，则累计值+1，最后返回累计值。因此，count(\*)、count(1)、count(主键 id)都表示返回满足条件的结果集的总行数；而count(字段)，则表示返回满足条件的数据行中，字段值不为NULL的总行数。这几种方法的性能差异如下：

- count(主键id)：InnoDB遍历整张表，取出每一行的主键id，返回给server层，判断不为NULL，效果为按行累加；

- count(1)：InnoDB遍历整张表，但无需取出任何值，server层对返回的每一行，放入一个1，判断不为NULL，效果也是按行累加；

显然count(1)比count(主键id)要快，因为InnoDB不会执行解析数据行或拷贝字段值的操作。

- count(字段)：若字段定义为NOT NULL，则InnoDB从记录中取出字段后，判断不可为NULL，按行累加；若字段可以为NULL，则InnoDB还需要将字段值取出，判断是否为NULL，不是才累加；
- count(\*)：InnoDB引擎为count(\*)方法做了优化，并不会将全部的字段取出，而是直接按行累加；

因此，从效率上讲，这几种count方法的排序为：count(字段)<count(主键id)<count(1)近似于count(\*)。因此尽量使用count(\*)即可。

### order by的原理

MySQL会为每个线程分配一块儿内存用于排序，称为sort_buffer。通常情况下order by语句的执行逻辑如下：

1. 初始化sort_buffer，确定要放入的字段；
2. 若不存在索引则全表扫描找到所有符合条件的行；若存在索引则根据索引找到满足条件的行的主键id，回表查询到其数据行；
3. 对每一条符合条件的数据行，取出其中待返回的字段，存入sort_buffer；
4. 对sort_buffer中的值按照待排序的字段进行排序；
5. 取前n行记录返回给客户端；

当sort_buffer_size不够大，不能一次存入所有待排序的数据行时，则MySQL会使用归并排序，将需要排序的数据分为N份儿，每一份单独排序后，保存在临时文件中，然后将所有的有序文件合并为一个有序文件并返回给客户端。

当MySQL认为排序的单行数据太大时，则会采取另一种策略，即rowid排序，这种排序算法下，MySQL不会把整行数据读入sort_buffer，而是只将主键id（若不存在索引则使用MySQL自动生成的rowid）和待排序的字段读入sort_buffer，排序完成后再根据主键id或rowid，到原表中取出所有需要返回的字段，返回给客户端。

### 正确地显示随机消息

一种常见的随机挑选n条满足条件的数据的方式是通过语句` order by RAND() limit n `，但实际上这种方式存在性能问题。该语句执行的逻辑如下：

1. 创建一个临时表，该临时表使用的是memory引擎，表中维护一个double字段用于保存随机数，以及需要作为结果返回的字段；
2. 从被查询的表中，取出所有的满足条件的值，对每条记录，调用rand()函数生成一个0～1的随机小数，然后将其一并存入临时表；
3. 在临时表上按照随机数排序，注意临时表是没有索引的；
4. 初始化sort_buffer，sort_buffer中有两个字段，一个是随机数，一个是**位置信息**；
5. 对临时表执行全表扫描，将随机数和位置信息存入sort_buffer；
6. 在sort_buffer中根据随机数的值进行排序，该操作在内存中进行，不涉及表扫描；
7. 排序完成后，取出前n个结果的位置信息，再到内存中的临时表中取出对应的字段的值；

临时表使用的是memory引擎，其位置信息即为表自动为每条数据生成的rowid。

临时表也有可能不是内存表而是磁盘表，当数据量很大，超过了tmp_table_size的限制时，内存临时表就会转换成磁盘临时表，此时使用的引擎为InnoDB，但同样没有索引。这种情况MySQL会采用优先队列算法选取前n个值。

但无论是哪种类型的临时表，通过` order by RAND() `方式进行随机挑选的操作都会增加大量的表扫描和计算，消耗的资源很大。因此，应当尽量减少该语句的使用，将大部分排序和筛选操作放在客户端执行。如：

**随机选择1条数据：**

1. 取得表的主键id的最大值M和最小值N；
2. 使用随机函数生成一个N～M中间的数X=(M-N+1)*rand() + N；
3. 取id不小于X的第一行数据返回；

语句如下：

```sql
select max(id),min(id) into @M,@N from t;
set @X= floor((@M-@N+1)*rand() + @N);
select * from t where id >= @X limit 1;
```

但此算法存在缺点，由于id之间可能存在空洞，因此选择数据行并不是真正的随机；且在一些极端情况下算法有可能出现接近bug的情况，如数据表中只有4条数据1，2，100000，100001，则在绝大多数情况下算法都不会选择到id为1或2的行。

一种改进的算法为：

1. 取得整个表的行数，记为C；
2. 取得Y = floor(C * rand())，floor函数的作用为取整；
3. limit Y, 1取得1行；

语句如下：

```sql
select count(*) int @C from t;
set @Y = floor(@C * rand());
select * from t limit @Y, 1;  //注意limit后其实不可以直接跟变量，因此这里需要在客户端应用程序里先拼接好sql语句再执行。
```

### 如何处理MySQL的慢查询

- 开启MySQL慢查询功能，语句为` set global slow_query_log=ON `；
- 筛选慢查询日志，如将1分钟以上执行时间的查询定义为慢查询，语句为：` set global long_query_time=3600 `

