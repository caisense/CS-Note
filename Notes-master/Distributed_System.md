## CAP原则

CAP对应了分布式系统的三大性能标准：

- Consistency：一致性
- Availability：可用性
- Partition Tolerance：分区容错性

任何分布式系统(Distributed System)中，最多具有一致性、可用性、分区容错这三个特性中的两个。 也就是说，三个特性无法兼顾，必须有所取舍。 

### Consistency

一致性：各节点的数据保证一致（每次成功写入之后，无论从哪个节点读取，都能读取到最新数据），相当于向所有节点的写操作是原子操作（要么全部失败要么全部成功）。一致性有三种策略：

- 强一致性：写操作完成后，后续的读操作都能看到最新数据；
- 弱一致性：能容忍部分或全部都看不到最新数据；
- 最终一致性：经过一段时间后，都能看到最新数据。

CAP原则指的是强一致性。

### Availability

可用性：每次向未崩溃的节点发送请求，总能保证收到响应数据（允许不是最新数据）。 一致性和可用性在分布式环境下是无法兼顾的

- 若要保证一致性：则必须进行节点间数据同步，同步期间数据锁定，导致期间的读取失败或超时，破坏了可用性；
- 若要保证可用性：则不允许节点间同步期间锁定，这又破坏了一致性。

### Partition tolerance

分区容错性：容许节点 G1/G2 间传递消息的差错（延迟或丢失），而不影响系统继续运行。 分布式系统中，必须满足CAP中的P，此时只能在C和A之间作出取舍。

### 典型的AP系统

常见的AP系统有：

- SpringCloud Eureka

### 典型的CP系统

常见的CP系统有：

- Zookeeper
- Redis Cluster



## 分布式锁

分布式锁同样是为了实现资源的互斥访问，但其需要工作在分布式环境下。

- 分布式与单机情况下最大的不同在于其不是多线程而是多进程；

- 多线程由于可以共享堆内存，因此可以简单的采取内存作为标记存储位置。而进程之间甚至可能都不在同一台物理机上，因此需要将标记存储在一个所有进程都能看到的地方；

- 此外还需要考虑分布式环境下的网络延时和不可靠问题。

分布式锁的设计思路有如下几种：

### 基于乐观锁的实现

- **基于表主键唯一做分布式锁**

  利用主键唯一的特性，如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，当方法执行完毕之后，想要释放锁的话，删除这条数据库记录即可。

  该方法实现简单，但存在问题：

  - 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。

  - 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。

  - 这把锁只能是非阻塞的。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。

  - 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

  - 这把锁是非公平锁，所有等待锁的线程凭运气去争夺锁。

  对应的解决方法有：

  - 设置备份库。

  - 使用定时任务每隔一定时间清理数据库中的超时数据。

  - 使用while循环，直到insert成功。

  - 在数据库表中增加字段，记录当前获得锁的机器的主机信息和线程信息。获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库中，直接分配锁。

  - 建一张中间表，将等待锁的线程全记录下来，并根据创建时间排序，只有最先创建的允许获取锁。

  在高并发的情景下，该方法会占用大量的系统的开销，造成性能的下降，并不推荐使用。

- **基于表版本号字段做分布式锁**

  策略源于MySQL的MVCC机制，策略存在的问题是对数据表的侵入较大。我们要为每个表设计一个版本号字段，然后写一条判断的sql语句每次进行判断，增加了数据库操作的次数，在高并发的要求下，对数据库连接的开销也是无法忍受的。

### 基于悲观锁的实现

- **基于数据库排他锁做分布式锁**

  在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁，当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。可以认为获得排他锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，通过connection.commit()操作来释放锁。

  这种方法可以有效的解决无法释放锁和阻塞锁的问题。

  - 阻塞锁： for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。

  - 无法释放锁：使用这种方式，服务宕机之后数据库会自己把锁释放掉。

  但无法直接解决数据库单点和可重入问题。还有一个问题就是如果一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接太多，就可能把数据库连接池撑爆。

### 基于Redis的实现

- **基于Redis的setnx()、expire()方法做分布式锁**

  - setnx()：SET if Not Exists。其主要有两个参数setnx(key, value)。该方法是原子的，如果key不存在，则设置当前key成功，返回 1；如果当前key已经存在，则设置当前key失败，返回 0。

  - expire()：设置过期时间。setnx命令不能设置key的超时时间，只能通过expire()来设置。

  具体操作步骤为：

  - setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功

  - expire() 命令对 lockkey 设置超时时间，为的是避免死锁问题。

  - 执行完业务代码后，可以通过 delete 命令删除 key。

  该方法基本上可以满足业务需要，但也有可能出现问题：

  如果在第一步setnx执行成功后，在expire()命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题。可以使用Redis的setnx()、get()和getset()方法来实现分布式锁。

- **基于Redis的setnx()、get()、getset()方法做分布式锁**

  getset()：主要有两个参数getset(key，newValue)。该方法是原子的，对key设置newValue值，并且返回key原来的旧值。假设key原来是不存在的，那么多次执行这个命令，会出现下边的效果：

  - getset(key, "value1") 返回 null 此时 key 的值会被设置为 value1

  - getset(key, "value2") 返回 value1 此时 key 的值会被设置为 value2

  - 依次类推

  具体操作步骤为：

  1. setnx(lockkey, 当前时间+过期超时时间)，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。

  2. get(lockkey) 获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。

  3. 计算 newExpireTime = 当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值currentExpireTime。

  4. 判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前 getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。

  5. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行 delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。

## 一致性哈希

一致性哈希（Consistent Hash）是分布式哈希（Distributed Hash Table，DHT）的一种实现，本质上还是一个哈希算法。一致性哈希算法的设计目的包括以下几点：

- Balance：平衡性。哈希结果尽可能地平均分散到各个节点上，使每个节点能得到充分利用；

- Monotonicity：单调性。节点变更尽量不改变整个网络的映射关系；

- Spread：分散性。由于每个终端能看到/访问到的节点范围有可能是不一致的，有可能出现同样的数据被映射到不同的节点的情况。好的一致性hash算法应当尽量避免这种情况，减少系统冗余度。

- Load：负载分散。数据在整个网络上的存储是均衡的。尽量避免同一个节点被各个终端映射为不同的内容导致其负载过重的情况。

Chord是一种经典的一致性hash算法，其大致的设计思路是：

通过某个哈希算法（如SHA-1）为每个server node或所存储的key计算出一个m位的哈希值，统称为identifier。对于server node，其identifier通过hashing IP address得到。

所有identifiers（不论是node还是key）都在取模2的m次方后按顺序排列在一个环上，该环称为identifier space。对于一个identifier为k的key（即哈希值为k），它由环上第一个identifier不小于k的node负责维护。该node叫做identifier k的successor node，记作successor(k)。再直观一点的讲，successor(k)是环上从k顺时针起（包括k本身）第一个遇到的node。