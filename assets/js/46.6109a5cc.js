(window.webpackJsonp=window.webpackJsonp||[]).push([[46],{329:function(t,e,s){"use strict";s.r(e);var a=s(14),r=Object(a.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("p",[t._v("消息队列")]),t._v(" "),e("h1",{attrs:{id:"比较"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#比较"}},[t._v("#")]),t._v(" 比较")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th"),t._v(" "),e("th",[t._v("ActiveMQ")]),t._v(" "),e("th",[t._v("RabbitMQ")]),t._v(" "),e("th",[t._v("RocketMQ")]),t._v(" "),e("th",[t._v("Kafka")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("功能")]),t._v(" "),e("td",[t._v("MQ功能极其完备")]),t._v(" "),e("td",[t._v("MQ功能完备")]),t._v(" "),e("td",[t._v("MQ功能较为完善")]),t._v(" "),e("td",[t._v("MQ功能较为简单，主要使用在大数据的实时计算和日志采集")])]),t._v(" "),e("tr",[e("td",[t._v("单机吞吐量")]),t._v(" "),e("td",[t._v("万级")]),t._v(" "),e("td",[t._v("万级")]),t._v(" "),e("td",[t._v("十万级")]),t._v(" "),e("td",[t._v("十万级")])]),t._v(" "),e("tr",[e("td",[t._v("时效性")]),t._v(" "),e("td",[t._v("ms级")]),t._v(" "),e("td",[t._v("μs级（延迟最低）")]),t._v(" "),e("td",[t._v("ms级")]),t._v(" "),e("td",[t._v("ms级以内")])]),t._v(" "),e("tr",[e("td",[t._v("可用性")]),t._v(" "),e("td",[t._v("高，基于主从架构")]),t._v(" "),e("td",[t._v("高，基于主从架构")]),t._v(" "),e("td",[t._v("非常高，分布式架构")]),t._v(" "),e("td",[t._v("非常高，分布式架构，一个数据多个副本")])]),t._v(" "),e("tr",[e("td",[t._v("消息可靠性")]),t._v(" "),e("td"),t._v(" "),e("td"),t._v(" "),e("td"),t._v(" "),e("td",[t._v("会丢数据")])]),t._v(" "),e("tr",[e("td",[t._v("topic数量对吞吐量的影响")]),t._v(" "),e("td"),t._v(" "),e("td"),t._v(" "),e("td",[t._v("topic达到百级时，吞吐量会有小幅度下降")]),t._v(" "),e("td",[t._v("topic达到千级时，吞吐量会大幅下降")])])])]),t._v(" "),e("h1",{attrs:{id:"q-消息队列如何保证消息顺序性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-消息队列如何保证消息顺序性"}},[t._v("#")]),t._v(" Q：消息队列如何保证消息顺序性？")]),t._v(" "),e("h2",{attrs:{id:"rocketmq"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq"}},[t._v("#")]),t._v(" RocketMQ")]),t._v(" "),e("p",[t._v("顺序性的前提都是单线程。")]),t._v(" "),e("p",[e("strong",[t._v("局部顺序性")])]),t._v(" "),e("ul",[e("li",[t._v("queue级别：对某个topic，设n个生产者和消费者，生产者发指定queue，消费者读取同一个queue，queue内肯定是有序的，则每对生产者-消费者的消息流是有序的，前提是"),e("strong",[t._v("单线程")]),t._v("。")]),t._v(" "),e("li",[t._v("topic级别：业务可以hash切分为多topic，每个topic只有一个生产者和一个消费者，则topic内有序，前提是"),e("strong",[t._v("单线程")]),t._v("。")])]),t._v(" "),e("p",[t._v("所以一般要求的顺序性都指全局顺序性")]),t._v(" "),e("p",[e("strong",[t._v("全局顺序性")])]),t._v(" "),e("p",[t._v("对某个topic只能是一个生产者，一个消费者，且"),e("strong",[t._v("单线程")]),t._v("。要求全局顺序性必然无法并发，损失性能。")]),t._v(" "),e("h2",{attrs:{id:"kafka"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka"}},[t._v("#")]),t._v(" kafka")]),t._v(" "),e("p",[t._v("每个消费者"),e("strong",[t._v("只能消费一个")]),t._v("partition，若消费者比partition多，则有消费者拿不到数据，没有意义")]),t._v(" "),e("p",[t._v("写入同一个partition的数据一定是有顺序的，因此生产者写入时，可以指定一个key，则相同key一定会分发到同一个partition")]),t._v(" "),e("img",{attrs:{src:"images\\消息队列\\image-20220318015558871.png",alt:"image-20220318015558871"}}),t._v(" "),e("h1",{attrs:{id:"q-如何保证消息不丢失"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-如何保证消息不丢失"}},[t._v("#")]),t._v(" Q：如何保证消息不丢失？")]),t._v(" "),e("h2",{attrs:{id:"kafka-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-2"}},[t._v("#")]),t._v(" Kafka")]),t._v(" "),e("p",[e("strong",[t._v("情形1：消费者丢数据")])]),t._v(" "),e("p",[t._v("kafka消费者会自动提交offset（记为i），broker就认为i号消息已被消费，若此时消费者出问题，则下次请求broker给的就是i+1号消息了，i号消息丢失。")]),t._v(" "),e("p",[t._v("解决：改为手动提交")]),t._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("request.required.asks=0\n# 0: 相当于异步的，不需要leader给予回复，producer立即返回，发送就是成功，那么发送消息网络超时或broker crash(1、Partition的Leader还没有commit消息 2、Leader与Follower数据不同步)，既有可能丢失也可能会重发\n# 1：当leader接收到消息之后发送ack, 丢会重发, 丢的概率很小\n# -1：当所有的follower都同步消息成功后发送ack. 不会丢失消息\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br")])]),e("p",[e("strong",[t._v("情形2：broker丢数据")])]),t._v(" "),e("p",[t._v("某个broker宕机，重新选举leader，此时follower数据未同步完，leader也挂了，则leader上的数据丢失。")]),t._v(" "),e("p",[t._v("解决：给这个topic设置"),e("code",[t._v("replication.factor")]),t._v("大于1，即每个partition至少有2个副本")]),t._v(" "),e("p",[t._v("broker设置"),e("code",[t._v("min.insync.replicas")]),t._v("大于1，要求leader至少有一个follower与自己保持同步中")]),t._v(" "),e("p",[t._v("生产者设置"),e("code",[t._v("acks = all")]),t._v("，要求每条数据必须写入所有replica后，才认为写成功")]),t._v(" "),e("p",[t._v("生产者设置"),e("code",[t._v("retries = MAX（最大整数）")]),t._v("，要求写入失败时，无限重试")]),t._v(" "),e("p",[e("strong",[t._v("Q：生产者是否会丢数据？")])]),t._v(" "),e("p",[t._v("按照情形2的解决办法，能保证生产者一定将数据发送到broker，且存有2个以上副本，若不满足，生产者会不断重试")]),t._v(" "),e("h2",{attrs:{id:"rocketmq-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq-2"}},[t._v("#")]),t._v(" RocketMQ")]),t._v(" "),e("p",[t._v("需要生产者、消费者以及Broker的共同努力，缺一不可。")]),t._v(" "),e("p",[e("strong",[t._v("1、生产者端")])]),t._v(" "),e("p",[t._v("消息发送分同步和异步")]),t._v(" "),e("p",[t._v("其中同步发送，生产者会阻塞等待broker的返回结果，但broker返回成功其实必不会立即写磁盘，有同步刷盘和异步刷盘两种模式。如果是异步刷盘，可能返回成功后落盘失败。因此需要使用"),e("strong",[t._v("同步刷盘")]),t._v("模式保证消息落盘。")]),t._v(" "),e("p",[t._v("对于异步发送，要通过集群方式，broker采用"),e("strong",[t._v("一主多从")]),t._v("部署，且采用"),e("strong",[t._v("主从同步复制")]),t._v("策略，该配置能保证消息到达主broker，且数据同步到从broker后，才向生产者返回成功。当主broker收到消息后突然宕机时，从broker接替；若主broker接受消息后同步给从broker过程失败，向生产者返回失败。")]),t._v(" "),e("p",[e("strong",[t._v("2、消费者端")])]),t._v(" "),e("p",[t._v("确保消息拉取并消费成功之后再向broker返回ACK，并且确保broker收到ACK，否则消费者重试。")]),t._v(" "),e("p",[t._v("例如在代码业务逻辑最后一步"),e("code",[t._v("return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;")]),t._v("或者先消费消息，立即落库，返回ACK，后续再处理业务。")]),t._v(" "),e("blockquote",[e("p",[t._v("注意：RocketMQ和Kafka一样，只能最大限度的保证消息不丢失，但是没办法做到100%保证不丢失。")])]),t._v(" "),e("h1",{attrs:{id:"q-如何保证消息不重复"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-如何保证消息不重复"}},[t._v("#")]),t._v(" Q：如何保证消息不重复？")]),t._v(" "),e("p",[t._v("kafka消费者会在获取消息后提交offset（相当于序号）给zk，告诉broker消费到哪了，从而保证消费者获取消息的基本顺序性，当消费者宕机重启后，还能从上次消费的地方继续开始")]),t._v(" "),e("p",[t._v("然而消费者并不是每条消息都提交offset，而是定时"),e("strong",[t._v("批量提交")]),t._v("。若消费到中间某个消息（序号i），还未提交offset就宕机，则下次重启时无法继续从消息i开始，而是从i之前的某条开始，这就会出现重复消息")]),t._v(" "),e("p",[e("strong",[t._v("解决")])]),t._v(" "),e("ol",[e("li",[t._v("用redis记录消息id（流水号），消费者每次消费都读redis，遇到重复就跳过")]),t._v(" "),e("li",[t._v("用数据库唯一主键约束")]),t._v(" "),e("li",[t._v("加分布式锁（实际项目），一条消息从生产到消费全程加锁")])]),t._v(" "),e("h2",{attrs:{id:"rocketmq重复消费场景"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#rocketmq重复消费场景"}},[t._v("#")]),t._v(" RocketMQ重复消费场景")]),t._v(" "),e("p",[t._v("1、发送阶段")]),t._v(" "),e("p",[t._v("当一条消息已被成功发送到Broker并完成持久化，此时出现网络闪断，导致Broker对Producer应答ack失败。Producer等待超时并尝试再次发送消息，则Broker中就可能会出现两条内容相同、并且Message ID也相同的消息，那么后续Consumer就一定会消费两次该消息。")]),t._v(" "),e("p",[t._v("2、消费阶段")]),t._v(" "),e("p",[t._v("消息已投递到Consumer并完成业务处理，当Consumer向Broker提交offset时网络闪断，Broker未收到offset。为了保证消息"),e("strong",[t._v("至少被消费一次")]),t._v("的原则，Broker将在网络恢复后再次尝试投递之前已被处理过的消息。此时Consumer就会收到与之前处理过的内容相同、且Message ID也相同的消息。")]),t._v(" "),e("blockquote",[e("p",[t._v("至少一次原则：RocketMQ保证每条消息必须要被"),e("strong",[t._v("成功消费一次")]),t._v("。")])]),t._v(" "),e("p",[t._v("3、Rebalance时")]),t._v(" "),e("blockquote",[e("p",[t._v("Rebalance即重新均衡，指的是"),e("strong",[t._v("集群消费")]),t._v("模式下，同⼀个Consumer Group中的Consumer数量变化时，将⼀个Topic下的多个Queue在多个Consumer间进行重新分配的过程。")])]),t._v(" "),e("p",[t._v("消费者中某个消费者1已经接收queue1的消息，但未提交offset，此时发生Rebalance，queue1的消费者被重新指定为消费者2，则消费者2也可能读到queue1中的消费者1接收但未提交offset的这条消息。")]),t._v(" "),e("h1",{attrs:{id:"q-如何处理消息积压"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-如何处理消息积压"}},[t._v("#")]),t._v(" Q：如何处理消息积压？")]),t._v(" "),e("p",[t._v("考虑提高消费能力")]),t._v(" "),e("ul",[e("li",[t._v("增加消费者：若当前topic的queue数量大于消费者数量，就可以增加消费者来加快积压消息的消费")]),t._v(" "),e("li",[t._v("提升消费速度：每个消费者的线程增加，则消费速度提升")]),t._v(" "),e("li",[t._v("降低生产速度：道理同上")]),t._v(" "),e("li",[t._v("消息迁移Queue：若当前topic的queue数量不超过消费者数量，再增加消费者也没用（消费者数不能超过分区数，否则有消费者闲置），此时就应考虑增加queue。把部分积压消息转到"),e("strong",[t._v("临时topic")]),t._v("，因为不用业务处理，只是单纯转发，因此速度很快。再增加消费者去消费临时topic的消息，消费完后恢复原状。")]),t._v(" "),e("li",[t._v("调整配置参数：例如消息消费模式、消息拉取时间间隔")])]),t._v(" "),e("h1",{attrs:{id:"q-kafka为何能做到高性能"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-kafka为何能做到高性能"}},[t._v("#")]),t._v(" Q：Kafka为何能做到高性能？")]),t._v(" "),e("h2",{attrs:{id:"_1-顺序写"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-顺序写"}},[t._v("#")]),t._v(" 1 顺序写")]),t._v(" "),e("p",[t._v("追加写磁盘，顺序写的性能极高")]),t._v(" "),e("h2",{attrs:{id:"_2-零拷贝"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-零拷贝"}},[t._v("#")]),t._v(" 2 零拷贝")]),t._v(" "),e("p",[t._v("先来看看非零拷贝的情况，数据从内存拷贝到kafka服务进程那块，又拷贝到socket缓存那块，整个过程耗费的时间比较高")]),t._v(" "),e("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/消息队列/640-1679328162013-3.jpeg",alt:"图片"}}),t._v(" "),e("p",[t._v("kafka利用了Linux的sendFile技术（NIO），省去了进程切换和一次数据拷贝，让性能变得更好。")]),t._v(" "),e("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/消息队列/640-1679328175176-6.png",alt:"图片"}}),t._v(" "),e("h1",{attrs:{id:"q-客户端和服务端最大的区别是什么"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-客户端和服务端最大的区别是什么"}},[t._v("#")]),t._v(" Q：客户端和服务端最大的区别是什么？")]),t._v(" "),e("p",[t._v("客户端需要connect操作，不需要启动Netty服务器进行accpet。")]),t._v(" "),e("p",[t._v("基于RocketMQ，提供高性能、高可用服务")]),t._v(" "),e("h1",{attrs:{id:"kafka-3"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-3"}},[t._v("#")]),t._v(" Kafka")]),t._v(" "),e("h2",{attrs:{id:"broker"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#broker"}},[t._v("#")]),t._v(" Broker")]),t._v(" "),e("p",[t._v("其实就是Server。包含多个Topic、Partition和Replica，负责协调Producer和Consumer。")]),t._v(" "),e("p",[t._v("主从结构：主节点为 Controller, 从节点为从节点 Kafka 启动是会往 Zookeeper 中注册当前 Broker 信息. 谁先注册谁就是 Controller。读取注册上来的从节点的数据(通过监听机制), 生成集群的元数据信息, 之后把这些信息都分发给其他的服务器, 让其他服务器能感知到集群中其它成员的存在。")]),t._v(" "),e("h2",{attrs:{id:"topic"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#topic"}},[t._v("#")]),t._v(" Topic")]),t._v(" "),e("p",[t._v("标准MQ模型中的Queue。Kafka中一个Topic的消息会保存在不同的Partition(不同的 Broker)来保证高可用。")]),t._v(" "),e("h2",{attrs:{id:"partition-分区"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#partition-分区"}},[t._v("#")]),t._v(" Partition（分区）")]),t._v(" "),e("p",[t._v("可以理解为将标准 MQ 的 Queue 的消息进行拆分，来实现高可用 Producer 发送的 Message，根据 key 和 partition 数进行 hash，然后进行投递。")]),t._v(" "),e("p",[t._v("一个分区只能被同一个 Consumer Group （消费者组）中的一个 Consumer 消费，分区内消费有序。因此消费者组可用于实现某个topic的并行消费，n个消费者组同时消费某topic的n个分区，且不会互相干扰")]),t._v(" "),e("h2",{attrs:{id:"replica-副本"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#replica-副本"}},[t._v("#")]),t._v(" Replica（副本）")]),t._v(" "),e("p",[t._v("每一个 Partition 都可以设置多个副本，但 Replica 的数量应不超过 Broker 的数量")]),t._v(" "),e("p",[t._v("Leader：Partition 的所有副本中只能有一个 Leader 节点(Broker)。Producer 写数据只往 Leader 中写。Consumer 读数据也是从 Leader 中读")]),t._v(" "),e("p",[t._v("Follower：只用于"),e("strong",[t._v("备份")]),t._v("Leader，采用 pull 模式")]),t._v(" "),e("h2",{attrs:{id:"producer"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#producer"}},[t._v("#")]),t._v(" Producer")]),t._v(" "),e("p",[t._v("标准 MQ 中的发送方，一个Producer通常只发送一类消息（同一个topic）。发送给 Broker 使用"),e("strong",[t._v("push")]),t._v(" (推)模式")]),t._v(" "),e("h2",{attrs:{id:"consumer-group-消费者组"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#consumer-group-消费者组"}},[t._v("#")]),t._v(" Consumer Group（消费者组）")]),t._v(" "),e("p",[t._v("一类Consumer的集合名称，这类Consumer通常消费一类消息（同一个topic），且消费逻辑一致。")]),t._v(" "),e("h2",{attrs:{id:"controller"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#controller"}},[t._v("#")]),t._v(" Controller")]),t._v(" "),e("p",[t._v("kafka也是主从式的架构，主节点就叫controller，其余的为从节点，controller是需要和zookeeper进行配合管理整个kafka集群。")]),t._v(" "),e("h2",{attrs:{id:"zookeeper"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#zookeeper"}},[t._v("#")]),t._v(" Zookeeper")]),t._v(" "),e("p",[t._v("kafka严重依赖于zookeeper集群，所有的broker在启动的时候都会往zookeeper进行注册，目的就是选举出一个controller【先到先得】")]),t._v(" "),e("p",[t._v("controller会监听zookeeper里面的多个目录，例如有一个目录/brokers/，其他从节点往这个目录上**注册（就是往这个目录上创建属于自己的子目录而已）**自己，这时命名规则一般是它们的id编号，比如/brokers/0、/brokers/1、/brokers/2")]),t._v(" "),e("p",[t._v("注册时各个节点必定会暴露自己的主机名，端口号等等的信息，此时controller就要去"),e("strong",[t._v("读取注册上来的从节点的数据（通过监听机制），生成集群的元数据信息，之后把这些信息都分发给其他的服务器，让其他服务器能感知到集群中其它成员的存在")]),t._v("。")]),t._v(" "),e("p",[t._v("此时模拟一个场景，我们创建一个主题（其实就是在zookeeper上/topics/topicA这样创建一个目录而已），kafka会把分区方案生成在这个目录中，此时controller就监听到了这一改变，它会去同步这个目录的元信息，然后同样下放给它的从节点，通过这个方法让整个集群都得知这个分区方案，此时从节点就各自创建好目录等待创建分区副本即可。这也是整个集群的管理机制。")]),t._v(" "),e("h2",{attrs:{id:"kafka网络设计"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka网络设计"}},[t._v("#")]),t._v(" Kafka网络设计")]),t._v(" "),e("p",[t._v("kafka的网络设计和Kafka的调优有关，这也是为什么它能支持高并发的原因")]),t._v(" "),e("img",{attrs:{src:"images/消息队列/640.png",alt:"图片"}}),t._v(" "),e("p",[t._v("首先客户端发送请求全部会先发送给一个Acceptor，broker里面会存在3个线程（默认是3个），这3个线程都是叫做processor，Acceptor不会对客户端的请求做任何的处理，直接封装成一个个socketChannel发送给这些processor形成一个队列，发送的方式是轮询，就是先给第一个processor发送，然后再给第二个，第三个，然后又回到第一个。消费者线程去消费这些socketChannel时，会获取一个个request请求，这些request请求中就会伴随着数据。")]),t._v(" "),e("p",[t._v("线程池里面默认有8个线程，这些线程是用来处理request的，解析请求，如果request是写请求，就写到磁盘里。读的话返回结果。\nprocessor会从response中读取响应数据，然后再返回给客户端。这就是Kafka的网络三层架构。")]),t._v(" "),e("p",[t._v("所以如果我们需要对kafka进行增强调优，增加processor并增加线程池里面的处理线程，就可以达到效果。request和response那一块部分其实就是起到了一个缓存的效果，是考虑到processor们生成请求太快，线程数不够不能及时处理的问题。")]),t._v(" "),e("p",[t._v("所以这就是一个加强版的reactor网络线程模型。")]),t._v(" "),e("h1",{attrs:{id:"ctg-mq"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ctg-mq"}},[t._v("#")]),t._v(" CTG-MQ")]),t._v(" "),e("h2",{attrs:{id:"name-server"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#name-server"}},[t._v("#")]),t._v(" Name Server")]),t._v(" "),e("p",[t._v("一个几乎无状态节点，可集群部署，节点之间无同步信息。 它主要提供broker注册、Topic路由管理等功能")]),t._v(" "),e("h2",{attrs:{id:"broker-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#broker-2"}},[t._v("#")]),t._v(" Broker")]),t._v(" "),e("p",[t._v("消息中转角色，负责存储消息，转发消息，一般也称Server。")]),t._v(" "),e("p",[t._v("CTG-MQ一般在多个服务器部署broker集群")]),t._v(" "),e("h3",{attrs:{id:"消息存储"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消息存储"}},[t._v("#")]),t._v(" 消息存储")]),t._v(" "),e("p",[t._v("生产者发送的消息并不是瞬间到达消费者（否则就失去了MQ的意义），而是存储在本地文件系统中，这些相关文件默认在当前用户主目录下的store目录中。 目录下的文件：")]),t._v(" "),e("ul",[e("li",[t._v("abort：该文件在Broker启动后会自动创建，正常关闭Broker，该文件会自动消失。若在没有启动Broker的情况下，发现这个文件是存在的，则说明之前Broker的关闭是非正常关闭。")]),t._v(" "),e("li",[t._v("checkpoint：其中存储着commitlog、consumequeue、index文件的最后刷盘时间戳")]),t._v(" "),e("li",[e("strong",[t._v("commitlog")]),t._v("：其中存放着commitlog文件，而消息是写在commitlog文件中的")]),t._v(" "),e("li",[t._v("config：存放着Broker运行期间的一些配置数据")]),t._v(" "),e("li",[e("strong",[t._v("consumequeue")]),t._v("：其中存放着consumequeue文件，队列就存放在这个目录中")]),t._v(" "),e("li",[t._v("index：其中存放着消息索引文件indexFile")]),t._v(" "),e("li",[t._v("lock：运行期间使用到的全局资源锁")])]),t._v(" "),e("h4",{attrs:{id:"commitlog"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#commitlog"}},[t._v("#")]),t._v(" CommitLog")]),t._v(" "),e("blockquote",[e("p",[t._v("说明：在很多资料中commitlog目录中的文件简单就称为commitlog文件。但在源码中，该文件被命名为mappedFile")])]),t._v(" "),e("p",[t._v("存放producer端写入的消息主体内容，消息是不定长的。")]),t._v(" "),e("p",[t._v("mappedFile文件大小上限为1G，文件名由"),e("strong",[t._v("20位")]),t._v("十进制数构成，表示当前文件的第一条消息的起始位移偏移量。比如第⼀个文件名00000000000000000000，表示起始偏移量为0；当第一个文件写满了，写入第⼆个文件，名为00000000001073741824，表示起始偏移量为1073741824（上一个文件大小为1G=1073741824），以此类推。")]),t._v(" "),e("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/消息队列/image-20230327005920218.png",alt:"image-20230327005920218"}}),t._v(" "),e("h4",{attrs:{id:"consumequeue"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#consumequeue"}},[t._v("#")]),t._v(" ConsumeQueue")]),t._v(" "),e("p",[t._v("消息消费队列，引入的目的主要是"),e("strong",[t._v("提高消费的性能")]),t._v("。由于RocketMQ是基于主题topic的订阅模式，消息消费是针对topic进行的，如果要遍历commitlog文件，根据topic检索消息非常低效。")]),t._v(" "),e("p",[t._v("于是consumer将consumequeue作为消息的"),e("strong",[t._v("索引")]),t._v("（每个索引20B），保存了消息在commitlog的起始物理偏移量offset（8B）、消息体大小size（4B）和消息tag的hashCode（8B）。")]),t._v(" "),e("p",[t._v("每个文件可以包含30W个索引，目录结构：topic/queue/file，按topic、queue来划分")]),t._v(" "),e("img",{staticStyle:{zoom:"50%"},attrs:{src:"images/消息队列/image-20230327010718368.png",alt:"image-20230327010718368"}}),t._v(" "),e("h4",{attrs:{id:"indexfile"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#indexfile"}},[t._v("#")]),t._v(" IndexFile")]),t._v(" "),e("p",[t._v("除了通过通常的指定Topic进行消息消费外，rocketMQ还提供一种可以通过"),e("strong",[t._v("key或时间")]),t._v("来查询消息的方法。前提是"),e("strong",[t._v("消息体中包含key")]),t._v("，且已经发送到broker。")]),t._v(" "),e("p",[t._v("文件名以创建的时间戳命名，固定单个IndexFile文件大小为400M，可以保存2000W个索引，底层存储为hashMap结构，因此RocketMQ索引文件底层实现为"),e("strong",[t._v("hash索引")]),t._v("。")]),t._v(" "),e("p",[t._v("总结：RocketMQ采用的是混合型的存储结构，即每个Broker下所有队列共用一个CommitLog文件来存储。并使用consumequeue文件索引，实现数据和索引分离。broker使用同步刷盘或异步刷盘方式将消息持久化。")]),t._v(" "),e("h2",{attrs:{id:"topic-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#topic-2"}},[t._v("#")]),t._v(" Topic")]),t._v(" "),e("p",[t._v("在ctg-mq中，topic类似于JMS规范中的队列，所有消息都是存放在不同的 topic中，"),e("strong",[t._v("每个topic都有与之对应的生产者和消费者")]),t._v("。")]),t._v(" "),e("p",[t._v("broker与topic是多对多关系，broker里可能有多个topic，一个Topic可以分片（分成多个Queue）存在多个broker上（分布式）。")]),t._v(" "),e("h2",{attrs:{id:"tag"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#tag"}},[t._v("#")]),t._v(" Tag")]),t._v(" "),e("p",[t._v("用于区分同一Topic下不同类型的消息。")]),t._v(" "),e("p",[t._v("Topic是消息的一级分类，Tag是消息的二级分类。")]),t._v(" "),e("h2",{attrs:{id:"queue"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#queue"}},[t._v("#")]),t._v(" Queue")]),t._v(" "),e("p",[t._v("每个Topic由多个队列Queue组成，Queue内有序，（类似kafka的分区）是存放数据的最小单位")]),t._v(" "),e("p",[e("strong",[t._v("broker-topic-queue关系")])]),t._v(" "),e("p",[t._v("broker与topic是多对多关系，一个broker里可以有多个topic，一个topic可以存在多个broker中")]),t._v(" "),e("p",[t._v("topic又分为多个queue，即queue分布在不同的broker上，从而实现"),e("strong",[t._v("分布式")]),t._v("。")]),t._v(" "),e("img",{attrs:{src:"images/消息队列/image-20220426204242838.png",alt:"image-20220426204242838"}}),t._v(" "),e("h2",{attrs:{id:"生产者"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#生产者"}},[t._v("#")]),t._v(" 生产者")]),t._v(" "),e("p",[t._v("生产组：一类Producer的集合名称，这类Producer通常发送一类消息（同一个topic），且发送逻辑一致，一般由业务系统负责产生消息。")]),t._v(" "),e("p",[t._v("生产者实例： 一个生产者实例代表"),e("strong",[t._v("生产者的一员")]),t._v("，不同的生产者用不同的实例名字创建。")]),t._v(" "),e("p",[t._v("发送方式：")]),t._v(" "),e("ul",[e("li",[t._v("默认"),e("strong",[t._v("轮询")]),t._v("topic的所有队列，每个队列接收平均的消息量。")]),t._v(" "),e("li",[t._v("CTG-MQ也可以用"),e("code",[t._v("sendByGroupId(MQMessage message)")]),t._v("指定队列，在message中设置groupId，MQ内部按groupId来hash到某个队列")]),t._v(" "),e("li",[t._v("最小投递延迟算法：统计每次消息投递的时间延迟，然后根据统计出的结果将消息投递到时间延迟最小的Queue。")])]),t._v(" "),e("h3",{attrs:{id:"消息写入过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消息写入过程"}},[t._v("#")]),t._v(" 消息写入过程")]),t._v(" "),e("p",[t._v("一条消息进入到Broker后经历了以下几个过程才最终被持久化。")]),t._v(" "),e("ol",[e("li",[t._v("Broker根据queueId，获取到该消息对应索引条目要在consumequeue目录中的写入偏移量，即QueueOffset")]),t._v(" "),e("li",[t._v("将queueId、queueOffset等数据，与消息一起封装为消息单元")]),t._v(" "),e("li",[t._v("将消息单元写入到commitlog")]),t._v(" "),e("li",[t._v("同时，形成消息索引条目")]),t._v(" "),e("li",[t._v("将消息索引条目分发到相应的consumequeue")])]),t._v(" "),e("h2",{attrs:{id:"消费者"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消费者"}},[t._v("#")]),t._v(" 消费者")]),t._v(" "),e("p",[t._v("消费组：一类Consumer的集合名称，这类Consumer通常消费一类消息（同一个topic），且消费逻辑一致，一般是后台系统负责异步消费。消费进度由存储在消费组上。")]),t._v(" "),e("p",[t._v("消费者实例 ：一个消费者实例代表"),e("strong",[t._v("消费组的一员")]),t._v("，不同的消费者用不同的实例名字创建。")]),t._v(" "),e("p",[t._v("约束：若topic分为n个队列，则消费者数量不能超过n，否则会有消费者无法消费消息。")]),t._v(" "),e("h3",{attrs:{id:"消息读取过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消息读取过程"}},[t._v("#")]),t._v(" 消息读取过程")]),t._v(" "),e("p",[t._v("当Consumer来拉取消息时会经历以下几个步骤：")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("Consumer获取到其要消费消息所在Queue的消费偏移量offset，计算出其要消费消息的消息offset")]),t._v(" "),e("blockquote",[e("p",[t._v("消费"),e("em",[t._v("offset")]),t._v("即消费进度，"),e("em",[t._v("consumer")]),t._v("对某个"),e("em",[t._v("Queue")]),t._v("的消费"),e("em",[t._v("offset")]),t._v("，即消费到了该"),e("em",[t._v("Queue")]),t._v("的第几条消息")]),t._v(" "),e("p",[t._v("消息"),e("em",[t._v("offset =")]),t._v(" 消费"),e("em",[t._v("offset + 1")])])])]),t._v(" "),e("li",[e("p",[t._v("Consumer向Broker发送拉取请求，其中会包含其要拉取消息的Queue、消息offset及消息Tag。")])]),t._v(" "),e("li",[e("p",[t._v("Broker计算在该consumequeue中的queueOffset。")]),t._v(" "),e("blockquote",[e("p",[e("em",[t._v("queueOffset =")]),t._v(" 消息"),e("em",[t._v("offset * 20")]),t._v("字节")])])]),t._v(" "),e("li",[e("p",[t._v("从该queueOffset处开始向后查找第一个指定Tag的索引条目。解析该索引条目的前8个字节，即可定位到该消息在commitlog中的offset")])]),t._v(" "),e("li",[e("p",[t._v("从对应commitlog offset中读取消息单元，并发送给Consumer")])])]),t._v(" "),e("h3",{attrs:{id:"广播消费和集群消费"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#广播消费和集群消费"}},[t._v("#")]),t._v(" 广播消费和集群消费")]),t._v(" "),e("p",[e("strong",[t._v("广播消费")])]),t._v(" "),e("blockquote",[e("p",[t._v("注意：使用消费模式，在很多使用场景都会带来影响或限制，在CTG-MQ中， 应尽量避免使用此消费模式。")])]),t._v(" "),e("p",[t._v("在广播消费模式下，一条消息被多个Consumer消费，即使这些 Consumer属于同一个Consumer Group，消息也会被"),e("strong",[t._v("Consumer Group中 的每个Consumer都消费一次")]),t._v("，广播消费中的Consumer Group概念可以认 为在消息划分方面无意义。")]),t._v(" "),e("p",[t._v("V1.x版本由于广播消费的"),e("strong",[t._v("消费进度，是保存在客户端")]),t._v("的（因为广播模式下consumer group中每个consumer都会\n消费所有消息，但它们的消费进度不同 ），对于很多使用场景 会带来影响，在ctg-mq中，并不推荐使用此消费模式。")]),t._v(" "),e("p",[t._v("V2.x版本在服务端存储消费状态，不支持此消费模式。推荐通过"),e("strong",[t._v("多消费组")]),t._v(" （订阅组）的方式进行消费。")]),t._v(" "),e("p",[e("strong",[t._v("集群消费")])]),t._v(" "),e("p",[t._v("一个Topic 可以被一个或多个 Consumer Group 消费，即一条消息每个 Consumer Group都能收到，但"),e("strong",[t._v("一条消息只会被一个 Consumer Group 消费一次")]),t._v("，消费组内具体哪个consumer消费取决于内部分发机制。")]),t._v(" "),e("p",[t._v("每个Consumer Group有自己独立的消费进度，"),e("strong",[t._v("消费进度保存在服务端")]),t._v("（因为同消费组的客户端之间需要共享进度）。")]),t._v(" "),e("p",[t._v("负载均衡：一个Consumer Group中的消费者实例可以平均分摊消费消息。例如某个Topic有12条消息，其中一个Consumer Group有3个不同的消费者实例（可能是3个进程，或者3台机器），那么每个实例只消费其中的4条消息。 在此消费模式下，可以做到Point-To-Point的消费，也可以做到JMS里面广播消费，能满足绝大部分场景，推荐使用此消费模式。")]),t._v(" "),e("h3",{attrs:{id:"offset管理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#offset管理"}},[t._v("#")]),t._v(" Offset管理")]),t._v(" "),e("ul",[e("li",[t._v("本地管理：对应广播消费，offset存每个Consumer客户端，默认路径为当前用户主目录下的"),e("code",[t._v(".rocketmq_offsets/${clientId}/${group}/Offsets.json")])]),t._v(" "),e("li",[t._v("远程管理：对应集群消费，offset存broker，默认路径为当前用户主目录下的"),e("code",[t._v("store/config/consumerOffset.json")])])]),t._v(" "),e("h3",{attrs:{id:"offset提交方式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#offset提交方式"}},[t._v("#")]),t._v(" offset提交方式")]),t._v(" "),e("p",[t._v("集群消费模式下，comsumer读取消息后会向broker提交消费进度，分为同步提交和异步提交")]),t._v(" "),e("ul",[e("li",[t._v("同步提交：comsumer读取完"),e("strong",[t._v("一批消息")]),t._v("后向broker提交这些消息的offset，然后等待broker响应。若超时没收到响应，则重新提交，收到响应之前阻塞消费。")]),t._v(" "),e("li",[t._v("异步提交：comsumer读取完"),e("strong",[t._v("一批消息")]),t._v("后向broker提交这些消息的offset，无需等待broker响应，就可继续读取下一批消息。")])]),t._v(" "),e("h3",{attrs:{id:"重试队列"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#重试队列"}},[t._v("#")]),t._v(" 重试队列")]),t._v(" "),e("p",[t._v("当rocketMQ对消息的消费出现异常时，会将发生异常的消息的offset提交到Broker中的一个特殊队列（而不是等待时长后再去重试读取原来offset的消息）。重试队列也是通过延迟消息处理的。")]),t._v(" "),e("p",[t._v("重试队列是对于消费组的（因为要保证一条消息只会被一个 Consumer Group 消费一次），因此队列名为"),e("code",[t._v("%RETRY%{$ConsumerGroup}@{$ConsumerGroup}")]),t._v("。")]),t._v(" "),e("h3",{attrs:{id:"死信队列"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#死信队列"}},[t._v("#")]),t._v(" 死信队列")]),t._v(" "),e("p",[t._v("当⼀条消息初次消费失败，RocketMQ 会⾃动进⾏消息重试；达到"),e("strong",[t._v("最大重试次数")]),t._v("后，若消费依然失败，说明消费组在正常情况下⽆法正确地消费该消息，RocketMQ 不会⽴刻将消息丢弃，⽽是将其发送到该消费组对应的特殊队列中，称为"),e("strong",[t._v("死信队列")]),t._v("（Dead-Letter Queue，DLQ），而其中的消息则称为"),e("strong",[t._v("死信消息")]),t._v("（Dead-Letter Message，DLM）。")]),t._v(" "),e("ul",[e("li",[t._v("死信队列中的消息不会再被消费者正常消费，即DLQ对于消费者是不可见的")]),t._v(" "),e("li",[t._v("死信存储有效期与正常消息相同，均为 3 天（commitlog文件的过期时间），3 天后会被自动删除")]),t._v(" "),e("li",[t._v("死信队列就是一个特殊的Topic，名称为%DLQ%consumerGroup@consumerGroup ，即每个消费者组都有一个死信队列，消费组下所有topic的死信消息都写入同一队列。")]),t._v(" "),e("li",[t._v("如果⼀个消费者组未产生死信消息，则不会为其创建相应的死信队列")])]),t._v(" "),e("h2",{attrs:{id:"消费模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消费模型"}},[t._v("#")]),t._v(" 消费模型")]),t._v(" "),e("p",[t._v("主要有push和pull两种")]),t._v(" "),e("h3",{attrs:{id:"push模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#push模型"}},[t._v("#")]),t._v(" PUSH模型")]),t._v(" "),e("p",[t._v("推送模型（被动），是一个“"),e("strong",[t._v("发布-订阅")]),t._v("”模型，由consumer封装了轮询过程，并注册MessageListener监听器，consumer接收消息后，回调监听器接口Listener方法。对用户而言，感觉消息是被推送过来的。")]),t._v(" "),e("p",[t._v("优点："),e("strong",[t._v("实时性好")]),t._v("。")]),t._v(" "),e("p",[t._v("缺点：需要维护一个"),e("strong",[t._v("长连接")]),t._v("，资源消耗大。")]),t._v(" "),e("p",[t._v("适合场景：client数量不多，server数据变化频繁。")]),t._v(" "),e("p",[t._v("客户端会自动开启多线程消费消息（线程数可配，默认5~64），即listener里面的方法，会被多线程执行。")]),t._v(" "),e("p",[t._v("客户端内部可以根据堆积量进行调整，使用者不需要新启、管理消费线程。并有流控机制，当客户端缓存一定量消息，导致消费不及时，会停止推送新消息。")]),t._v(" "),e("h3",{attrs:{id:"pull模型"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#pull模型"}},[t._v("#")]),t._v(" PULL模型")]),t._v(" "),e("p",[t._v("拉取模型（主动），又称队列模型，是一种“发--存--收”模型。应用通常主动调用Consumer的pull方法从Broker拉消息，主动权由应用控制，但实时性取决于应用主动拉取的频率，线程数由应用自主决定。")]),t._v(" "),e("p",[t._v("对于无序消费，应用可以多次调用pull并拉到数据，且与是否签收无关。对于有序消费，只要同一Queue的消息被拉出去消费，但未签收，则此Queue无法再拉取消费。")]),t._v(" "),e("p",[t._v("consumer在pull的时候，告诉broker自己buffer中可用的容量，整个流程如下：")]),t._v(" "),e("ol",[e("li",[t._v("consumer请求broker，告诉broker本地的可承载量，比如500")]),t._v(" "),e("li",[t._v("broker在收到消息后，如果没有消息则进入**long polling（长轮询）**状态")]),t._v(" "),e("li",[t._v("当有消息的时候，broker直接向consumer进行push，总共push的数据量为500")]),t._v(" "),e("li",[t._v("在整个push期间，consumer无需重新pull，即可获取数据")]),t._v(" "),e("li",[t._v("由于broker知道最大容量，所以无需担心被冲垮。")])]),t._v(" "),e("h2",{attrs:{id:"分布式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#分布式"}},[t._v("#")]),t._v(" 分布式")]),t._v(" "),e("p",[t._v("通过将topic分成多queue，分布在不同的broker上，以实现分布式")]),t._v(" "),e("h2",{attrs:{id:"消息模式"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消息模式"}},[t._v("#")]),t._v(" 消息模式")]),t._v(" "),e("h3",{attrs:{id:"有序消息"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#有序消息"}},[t._v("#")]),t._v(" 有序消息")]),t._v(" "),e("p",[t._v("生产者用"),e("code",[t._v("sendByGroupId()")]),t._v(" 发送，以保证消息按序存储。")]),t._v(" "),e("blockquote",[e("p",[t._v("【约束】只能是单生产者实例单线程串行发送。")])]),t._v(" "),e("p",[t._v("消费者"),e("strong",[t._v("按序消费")]),t._v("，前一条消息未完成消费，则后续的消费阻塞。若consumer消费失败，会不断"),e("strong",[t._v("重试")]),t._v("这条消息，直到消费成功。")]),t._v(" "),e("p",[t._v("在CTG-MQ中，主要有两种：普通有序和严格有序。")]),t._v(" "),e("p",[e("strong",[t._v("普通有序消息")])]),t._v(" "),e("p",[t._v("在正常情况下可以保证完全的顺序消息，但是一旦发生通 信异常，Broker重启，由于队列总数发生变化，哈希取模后定位的队列会变 化，产生短暂的消息顺序不一致。 如果业务能容忍在集群异常情况（如某个Broker宕机或者重启）下，消息短 暂的乱序，使用普通顺序方式比较合适。")]),t._v(" "),e("p",[e("strong",[t._v("严格有序消息")])]),t._v(" "),e("p",[t._v("无论正常异常情况都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集群中只要有一台机器不可用，则整个集群都不可 用（或者影响hash值对应队列的使用），服务可用性大大降低。 如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不 过仍然会存在几分钟的服务不可用。")]),t._v(" "),e("p",[t._v("在CTG-MQ中，消息模式选择的优先顺序为："),e("strong",[t._v("无序消息>普通有序消息>严格有序消息")]),t._v("。在业务场景允许的情况下，优先选择无序消息，或者 在业务能变通的情况下，将有序消息转化为无序消息。 如果一定要用有序，若业务能容忍短暂乱序，推荐普通有序消费。")]),t._v(" "),e("p",[e("strong",[t._v("有序消息的缺点")]),t._v(" & 必须注意事项：")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("对于生产者，因为要保证顺序，所以一般单线程串行发送， 性能较低。对一个Topic有多个Queue的场景，可增加生产者数，每个生产者发送固定的Queue，提高性能。")])]),t._v(" "),e("li",[e("p",[t._v("对于消费者，因为要保证顺序，所以一般单线程串行消费，消费性能较低。对一个Topic有多个Queue的场景，可以通过增加消费者 实例数，提高性能，但应用必须考虑消息者实例数量变化，由于负载均 衡带来的短时间数据乱序问题。")])]),t._v(" "),e("li",[e("p",[t._v("对于普通有序消息，当节点故障时，由于Queue数的变化，导致hash 值的变化，产生与消费都会出现短暂的消息顺序不一致；对于严格有序 消息，当节点故障时，Queue数不会变化，产生与消费都会出现异常， 直到故障节点恢复。")])]),t._v(" "),e("li",[e("p",[t._v("对于普通有序消息，意味着业务能接受短时间消息乱序，所以一般情 况下可以在线态扩容；对于严格有序消息，需要将所有消息消费完，并且停止服务，才能扩容。")])]),t._v(" "),e("li",[e("p",[t._v("有一种场景，同一Topic所有消息必须是有序生产与有序消费，可以使 用多Queue然后在生产消费端做顺序处理，也可以拆分多个Topic然后 使用单Queue进行处理，但在设计时，应用必须考虑单Queue的处理性 能是否能满足。对于单Queue，只要对应的broker故障，则服务中断。")])])]),t._v(" "),e("h3",{attrs:{id:"无序消息"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#无序消息"}},[t._v("#")]),t._v(" 无序消息")]),t._v(" "),e("p",[t._v("普通消息、延时消息、事务消息都是无序的。无序消息的"),e("strong",[t._v("重试只对集群消费生效")]),t._v("。（广播消费失败不重试）")]),t._v(" "),e("p",[t._v("优点：")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("生产者可以使用"),e("strong",[t._v("多进程、多线程")]),t._v("往同一个TOPIC发送，性能较好")])]),t._v(" "),e("li",[e("p",[t._v("消费者可以使用"),e("strong",[t._v("多进程、多线程")]),t._v("同时消费一个topic，性能较好")])]),t._v(" "),e("li",[e("p",[t._v("可以充分使用集群的 "),e("strong",[t._v("failover")]),t._v("（故障转移）特点，无须依赖自动主备切换（切换过期服务中断），包括：")]),t._v(" "),e("ol",[e("li",[t._v("当集群中某一broker节点故障时，不影响业务消息生产， 消息将failover发送到其它节点")]),t._v(" "),e("li",[t._v("当集群中某一broker节点故障时，不影响其它节点数据 消费，故障恢复后既可消费")]),t._v(" "),e("li",[t._v("充分利用failover特点，可不部署自动切换组件，减少 部署复杂度和运维难度")])])]),t._v(" "),e("li",[e("p",[t._v("动态扩容")])])]),t._v(" "),e("h3",{attrs:{id:"消息过滤"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消息过滤"}},[t._v("#")]),t._v(" 消息过滤")]),t._v(" "),e("p",[t._v("有两种⽅案：")]),t._v(" "),e("ul",[e("li",[t._v("Broker 端过滤：在 Broker 端按照 Consumer 的去重逻辑进⾏过滤。这样做的好处是避免了⽆⽤的消息传输到 Consumer 端，提高吞吐量。缺点是加重了 Broker 的负担，实现复杂。")]),t._v(" "),e("li",[t._v("Consumer 端过滤：⽐如按照消息的 tag 去重，这样的好处是实现起来简单，缺点是有⼤量 ⽆⽤的消息到达了 Consumer 端只能丢弃不处理。")])]),t._v(" "),e("p",[t._v("⼀般采⽤Cosumer端过滤。如果希望提⾼吞吐量，可以采⽤Broker过滤")]),t._v(" "),e("p",[t._v("消息过滤三种方式：")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("根据Tag过滤：这是最常⻅的⼀种，⽤起来⾼效简单")]),t._v(" "),e("div",{staticClass:"language-java line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-java"}},[e("code",[e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultMQPushConsumer")]),t._v(" consumer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultMQPushConsumer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"CID_EXAMPLE"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nconsumer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("subscribe")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TOPIC"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TAGA || TAGB || TAGC"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 过滤出带TAGA、TAGB、TAGC三个标签，用或运算符")]),t._v("\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br")])])]),t._v(" "),e("li",[e("p",[t._v("SQL 表达式过滤：更加灵活")]),t._v(" "),e("div",{staticClass:"language-java line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-java"}},[e("code",[e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultMQPushConsumer")]),t._v(" consumer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultMQPushConsumer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v('"please_rename_unique_group_\nname_4"'),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 只有订阅的消息有这个属性a, a >=0 and a <= 3，才过滤")]),t._v("\nconsumer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("subscribe")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TopicTest"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("MessageSelector")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("bySql")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a between 0 and 3"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br")])])]),t._v(" "),e("li",[e("p",[t._v("Filter Server ⽅式：最灵活，也是最复杂的⼀种⽅式，允许⽤户⾃定义函数进⾏过滤")])])]),t._v(" "),e("h3",{attrs:{id:"延时消息"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#延时消息"}},[t._v("#")]),t._v(" 延时消息")]),t._v(" "),e("p",[t._v("消息写入到Broker后，在指定的时长后才可被消费的消息。")]),t._v(" "),e("p",[t._v("使用：不支持随意时长的延迟，是通过特定的延迟等级来指定的")]),t._v(" "),e("div",{staticClass:"language-java line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-java"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 服务端的MessageStoreConfig类")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("private")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),t._v(" messageDelayLevel "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br")])]),e("p",[t._v("实现原理："),e("strong",[t._v("缓存 + 定时任务")]),t._v("。Broker收到延时消息，会先发送到topic（加特定开头，如SCHEDULE_TOPIC_XXXX）的对应延迟等级的consumequeue 中，然后通过⼀个定时任务轮询这些队列，到期后再把消息投递到⽬标Topic的队列中。总之就是把延时消息先缓存到临时topic，时间到后再发送到原topic。")]),t._v(" "),e("p",[t._v("缺点：大量延时消息，需要多个计时器，导致CPU性能下降。")]),t._v(" "),e("p",[t._v("RocketMQ5.0改进：基于时间轮算法，能高效处理大量定时任务，在O(1)时间内找到下一个即将要执行的任务。且支持更高的时间精度（毫秒级）。")]),t._v(" "),e("blockquote",[e("p",[t._v("时间轮算法：本质上是将多个延时消息的计时器，整合到一个时间轮中")]),t._v(" "),e("ol",[e("li",[t._v("时间轮每个槽位（slot）间隔相等，槽位的精度也就决定了延时的精度。")]),t._v(" "),e("li",[t._v("计算每个延时消息的到期时间，将其放在不同槽位。")]),t._v(" "),e("li",[t._v("用一个当前时针的指针向前移动，到达哪个槽位，就将其中存放的所有消息发送。")])]),t._v(" "),e("p",[e("img",{attrs:{src:"images/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/07103861e70ffefab292a5f0f4b27404.png",alt:"img"}})])]),t._v(" "),e("p",[t._v("用法：")]),t._v(" "),e("div",{staticClass:"language-java line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-java"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//创建一个消息生产者")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultMQProducer")]),t._v(" producer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DefaultMQProducer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"ProducerGroupName"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nproducer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("setNamesrvAddr")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9876"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\nproducer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("start")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Message")]),t._v(" message "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Message")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TopicTest"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TagA"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"Hello RocketMQ"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("getBytes")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("RemotingHelper")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token constant"}},[t._v("DEFAULT_CHARSET")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 设置消息的延迟级别为3，即延迟10s")]),t._v("\nmessage"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("setDelayTimeLevel")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 消息发送")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SendResult")]),t._v(" sendResult "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" producer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("send")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("message"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("System")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("out"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("printf")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"%s%n"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sendResult"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br"),e("span",{staticClass:"line-number"},[t._v("5")]),e("br"),e("span",{staticClass:"line-number"},[t._v("6")]),e("br"),e("span",{staticClass:"line-number"},[t._v("7")]),e("br"),e("span",{staticClass:"line-number"},[t._v("8")]),e("br"),e("span",{staticClass:"line-number"},[t._v("9")]),e("br"),e("span",{staticClass:"line-number"},[t._v("10")]),e("br"),e("span",{staticClass:"line-number"},[t._v("11")]),e("br")])]),e("h3",{attrs:{id:"事务消息"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#事务消息"}},[t._v("#")]),t._v(" 事务消息")]),t._v(" "),e("p",[t._v("半消息：是指Producer 成功发送到 Broker 端的消息，但暂时还不能被 Consumer 消费的消息。只有等 Producer 端执⾏完本地事务后经过⼆次确认了之后，Consumer 才能消费此条消息。（因为消息在broker还是可以控制撤回的，但consumer消费后就不容易撤回了。）")]),t._v(" "),e("p",[t._v("依赖半消息，可以实现"),e("strong",[t._v("分布式消息事务")]),t._v("，其中的关键在于"),e("strong",[t._v("⼆次确认以及消息回查")]),t._v("（保证左半部分完成后才发送消费者）")]),t._v(" "),e("blockquote",[e("p",[t._v("分布式事务：一次操作由若干分支操作组成，这些分支操作分属不同应用，分布在不同服务器上。分布式事务需要保证这些分支操作要么全部成功，要么全部失败。分布式事务与普通事务一样，就是为了保证操作结果的一致性。")])]),t._v(" "),e("img",{attrs:{src:"images/消息队列/image-20230328012056416.png",alt:"image-20230328012056416"}}),t._v(" "),e("p",[t._v("二次确认：上图的第4步，若broker正常收到确认，立即能操作提交或回滚。若超时就回滚。")]),t._v(" "),e("p",[t._v("消息回查：第5步，重新查询本地事务的执行状态")]),t._v(" "),e("h2",{attrs:{id:"数据可靠性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据可靠性"}},[t._v("#")]),t._v(" 数据可靠性")]),t._v(" "),e("h3",{attrs:{id:"_1、刷盘策略"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1、刷盘策略"}},[t._v("#")]),t._v(" 1、刷盘策略")]),t._v(" "),e("p",[t._v("CTG-MQ的所有消息都是持久化的，到达broker后，先写入系统Page Cache（磁盘缓存），然后刷盘（写磁盘），可以保证内存与磁盘都有一份数据。有同步刷盘和异步刷盘，通过Broker配置文件里的"),e("code",[t._v("flushDiskType")]),t._v("参数设置为SYNC_FLUSH、ASYNC_FLUSH指定")]),t._v(" "),e("h4",{attrs:{id:"异步刷盘"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#异步刷盘"}},[t._v("#")]),t._v(" 异步刷盘")]),t._v(" "),e("p",[t._v("消息写入Page Cache后就立刻返回写成功。速度快吞吐量大，但有可能丢数据")]),t._v(" "),e("h4",{attrs:{id:"同步刷盘"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#同步刷盘"}},[t._v("#")]),t._v(" 同步刷盘")]),t._v(" "),e("p",[t._v("消息写入磁盘才返回写成功。性能不如异步，但数据一定不会丢。流程：消息写入线程Page Cache后，立刻启动刷盘线程写磁盘并等待，刷盘线程完成后唤醒等待线程，返回生产者写成功。")]),t._v(" "),e("img",{staticStyle:{zoom:"67%"},attrs:{src:"images/消息队列/1399187-20181126215707430-1696939068.png",alt:"img"}}),t._v(" "),e("h3",{attrs:{id:"_2、主从复制策略"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2、主从复制策略"}},[t._v("#")]),t._v(" 2、主从复制策略")]),t._v(" "),e("p",[t._v("若是主从架构，消息需要从Master复制到Slave上，有同步和异步两种复制方式。通过Broker配置文件里的"),e("code",[t._v("brokerRole")]),t._v("参数进行设置的，这个参数可以被设置成ASYNC_MASTER、SYNC_MASTER、SLAVE")]),t._v(" "),e("h4",{attrs:{id:"同步复制"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#同步复制"}},[t._v("#")]),t._v(" 同步复制")]),t._v(" "),e("p",[t._v("如果Master出故障，Slave上有全部的备份数据，容易恢复。但是会增大数据写入延迟，降低系统吞吐量")]),t._v(" "),e("h4",{attrs:{id:"异步复制"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#异步复制"}},[t._v("#")]),t._v(" 异步复制")]),t._v(" "),e("p",[t._v("系统拥有较低的延迟和较高的吞吐量。但是如果Master出了故障，有些数据因为没有被写入Slave，有可能会丢失")]),t._v(" "),e("h3",{attrs:{id:"_3、不同级别的数据可靠策略"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3、不同级别的数据可靠策略"}},[t._v("#")]),t._v(" 3、不同级别的数据可靠策略")]),t._v(" "),e("ul",[e("li",[t._v("最高保障：实时刷盘+同步复制")]),t._v(" "),e("li",[t._v("中等保障：异步刷盘+同步复制")]),t._v(" "),e("li",[t._v("中下级别：异步刷盘+异步复制")]),t._v(" "),e("li",[t._v("最低级别：异步刷盘/实时刷盘+单主机")])]),t._v(" "),e("p",[t._v("推荐设置为"),e("strong",[t._v("异步刷盘、同步复制")]),t._v("，即brokerRole=SYNC_MASTER，flushDiskType=ASYNC_FLUSH")]),t._v(" "),e("h3",{attrs:{id:"_4、数据清除策略"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_4、数据清除策略"}},[t._v("#")]),t._v(" 4、数据清除策略")]),t._v(" "),e("p",[t._v("消息的数据都存储在Commit Log上，所以数据清除是就是"),e("strong",[t._v("删除过期的Commit Log")]),t._v("。")]),t._v(" "),e("p",[t._v("默认过期时间为72小时。在Broker.config配置消息保留时间："),e("code",[t._v("fileReservedTime=xxx")])]),t._v(" "),e("h4",{attrs:{id:"定时删除"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#定时删除"}},[t._v("#")]),t._v(" 定时删除")]),t._v(" "),e("p",[t._v("Broker内部有一定时服务，默认4点开始删除过期的消息数据。数据删除是由"),e("strong",[t._v("最旧的一个Commit Log")]),t._v("文件开始")]),t._v(" "),e("h4",{attrs:{id:"发送时触发删除"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#发送时触发删除"}},[t._v("#")]),t._v(" 发送时触发删除")]),t._v(" "),e("p",[t._v("当磁盘使用空间达到85%以上，有消息生产时触发数据删除，由"),e("strong",[t._v("最旧的一个Commit Log")]),t._v("文件开始，一次最大删除10个文件")]),t._v(" "),e("p",[t._v("触发的删除有两种操作：1）保证数据高可靠：磁盘空间超过85%则拒绝服务；2）保证服务高可用：磁盘空间超过85%则强制删除非过期文件。")]),t._v(" "),e("h2",{attrs:{id:"高性能"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#高性能"}},[t._v("#")]),t._v(" 高性能")]),t._v(" "),e("h3",{attrs:{id:"_1、pagecache-顺序读"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1、pagecache-顺序读"}},[t._v("#")]),t._v(" 1、PageCache+顺序读")]),t._v(" "),e("p",[t._v("ConsumeQueue逻辑消费队列存储的数据较少，并且是"),e("strong",[t._v("顺序读")]),t._v("，在PageCache机制的"),e("strong",[t._v("预读取")]),t._v("作⽤下，ConsumeQueue⽂件的读性能⼏乎接近读内存。")]),t._v(" "),e("p",[t._v("⻚缓存（PageCache)是OS对⽂件的缓存，⽤于加速对⽂件的读写。⼀般来说，程序对⽂件进⾏顺序读写的速度⼏ 乎接近于内存的读写速度，主要原因就是由于OS使⽤PageCache机制对读写访问操作进⾏了性能优化，将⼀部分 的内存⽤作PageCache。对于数据的写⼊，OS会先写⼊⾄Cache内，随后通过异步的⽅式由pdflush内核线程将 Cache内的数据刷盘⾄物理磁盘上。对于数据的读取，如果⼀次读取⽂件时出现未命中PageCache的情况，OS从 物理磁盘上访问读取⽂件的同时，会顺序对其他相邻块的数据⽂件进⾏预读取。")]),t._v(" "),e("h3",{attrs:{id:"_2、mappedbytebuffer"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2、mappedbytebuffer"}},[t._v("#")]),t._v(" 2、MappedByteBuffer")]),t._v(" "),e("p",[t._v("是"),e("strong",[t._v("零拷贝")]),t._v("的一种java实现方式（mmap机制），是java nio引入的文件内存映射方案，读写性能极高。利⽤了NIO中的FileChannel模型将磁盘上的物理⽂件直接映射到⽤户态的内存地址中（即"),e("strong",[t._v("将CommitLog映射到内存")]),t._v("）")]),t._v(" "),e("p",[t._v("正因为需要使⽤内存映射机制，故RocketMQ的⽂件存储都使⽤"),e("strong",[t._v("定⻓存储")]),t._v("，⽅便⼀次将整个⽂件映射⾄内存")]),t._v(" "),e("h3",{attrs:{id:"q-什么是零拷贝"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#q-什么是零拷贝"}},[t._v("#")]),t._v(" Q：什么是零拷贝？")]),t._v(" "),e("p",[t._v("在操作系统中，使⽤传统IO的⽅式，数据需要经历⼏次拷⻉，还要经历⽤户态/内核态切换。")]),t._v(" "),e("img",{staticStyle:{zoom:"33%"},attrs:{src:"images/消息队列/image-20230327110830901.png",alt:"image-20230327110830901"}}),t._v(" "),e("ol",[e("li",[t._v("从磁盘复制数据到内核态内存；")]),t._v(" "),e("li",[t._v("从内核态内存复制到⽤户态内存；")]),t._v(" "),e("li",[t._v("然后从⽤户态内存复制到⽹络驱动的内核态内存；")]),t._v(" "),e("li",[t._v("最后是从⽹络驱动的内核态内存复制到⽹卡中进⾏传输。")])]),t._v(" "),e("p",[t._v("通过零拷⻉的⽅式，减少⽤户态与内核态的上下⽂切换和内存拷⻉的次数，⽤来提升I/O的性能。")]),t._v(" "),e("img",{staticStyle:{zoom:"33%"},attrs:{src:"images/消息队列/image-20230327110921187.png",alt:"image-20230327110921187"}}),t._v(" "),e("h2",{attrs:{id:"高可用"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#高可用"}},[t._v("#")]),t._v(" 高可用")]),t._v(" "),e("h3",{attrs:{id:"集群接入高可用-nameserver"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#集群接入高可用-nameserver"}},[t._v("#")]),t._v(" 集群接入高可用（NameServer）")]),t._v(" "),e("p",[t._v("多个集群管理服务+故障自动切换，实现集群接入点高可用")]),t._v(" "),e("h3",{attrs:{id:"消息服务高可用-broker"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消息服务高可用-broker"}},[t._v("#")]),t._v(" 消息服务高可用（Broker）")]),t._v(" "),e("ul",[e("li",[t._v("通过生产与消费的自动负载均衡，实现Failover，保证某一组服务在全挂的情况下，不影响整体业务")]),t._v(" "),e("li",[t._v("通过自主研发的自动主备切换，实现主机故障自动备升主，保证服务连续性，自动主备切换可剥离")]),t._v(" "),e("li",[t._v("通过消息过期删除策略，保证服务的可持续性")])]),t._v(" "),e("h2",{attrs:{id:"原生rocketmq的问题"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#原生rocketmq的问题"}},[t._v("#")]),t._v(" 原生RocketMQ的问题")]),t._v(" "),e("ul",[e("li",[e("p",[t._v("功能不完善：功能比较单一，针对不同应用场景无法有效支 持，如消息轨迹查询，严格消费机制，数据自动删除策略等。")])]),t._v(" "),e("li",[e("p",[t._v("可维护性差：缺乏配套监控运维能力，难以迅速发现解决如 消息堆积、队列堵塞等问题。")])]),t._v(" "),e("li",[e("p",[t._v("可靠性较低：消息服务不提供主备切换能力，存在单点故障， 无法保证服务高可用")])])]),t._v(" "),e("h2",{attrs:{id:"ctg-mq的改进"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ctg-mq的改进"}},[t._v("#")]),t._v(" CTG-MQ的改进")]),t._v(" "),e("p",[t._v("高可用、高可靠改进：")]),t._v(" "),e("ul",[e("li",[e("p",[t._v("实现自动主备切换、自动拉起功能，保证服务高可用")])]),t._v(" "),e("li",[e("p",[t._v("实现消息删除策略，按不同的场景优先保证服务可用性或者 数据安全性。")])])]),t._v(" "),e("p",[t._v("可维护性改进：")]),t._v(" "),e("ul",[e("li",[t._v("实现按生产者、消费者、数据节点、队列4种维度的运行状态 监控，方便快速发现问题")]),t._v(" "),e("li",[t._v("实现可视化的监控、配置、管理界面")]),t._v(" "),e("li",[t._v("实现自动化测试，以快速迭代")])]),t._v(" "),e("p",[t._v("新增功能：")]),t._v(" "),e("ul",[e("li",[e("p",[t._v("消息轨迹收集、分析与查询，做到可查可追踪")])]),t._v(" "),e("li",[e("p",[t._v("严格的消费机制，满足消费严格不重复的应用需求")])]),t._v(" "),e("li",[e("p",[t._v("重新封装SDK，简化应用使用，并提供按hash算法实现消息 局部有序生产消费")])])]),t._v(" "),e("h2",{attrs:{id:"使用"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#使用"}},[t._v("#")]),t._v(" 使用")]),t._v(" "),e("h3",{attrs:{id:"消费端"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#消费端"}},[t._v("#")]),t._v(" 消费端")]),t._v(" "),e("p",[t._v("创建一个类，继承CtgTopicListener，并实现ApplicationRunner")]),t._v(" "),e("p",[t._v("覆写com.eshxxx.cmp.sync.controller.listener.SaveRecordListener#run()、com.eshxxx.cmp.sync.controller.listener.SaveRecordListener#onMqMessage()")]),t._v(" "),e("ol",[e("li",[e("p",[t._v("run方法在app启动时执行，"),e("strong",[t._v("工厂模式")]),t._v("创建一个消费组，里面只有一个push型消费者，用IConsumer.pushMessagesByTopic()监听某个topic")]),t._v(" "),e("p",[t._v("内部再调IMQPushConsumer.listenTopic()，方法内部为Listener"),e("strong",[t._v("订阅")]),t._v("topic，并注册Listener")])]),t._v(" "),e("li",[e("p",[t._v("onMqMessage方法，处理消费到消息后的处理逻辑")])])]),t._v(" "),e("h3",{attrs:{id:"生产端"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#生产端"}},[t._v("#")]),t._v(" 生产端")]),t._v(" "),e("p",[t._v("工厂模式获取一个生产者，然后用IProducer.sendMsgToTopicSyn()发送一条消息")]),t._v(" "),e("p",[t._v("MQMessage说明")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("属性")]),t._v(" "),e("th",[t._v("类型")]),t._v(" "),e("th",[t._v("说明")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("sourceType")]),t._v(" "),e("td",[t._v("int")]),t._v(" "),e("td",[t._v("0：主题 1：队列  （cmp中默认0）")])]),t._v(" "),e("tr",[e("td",[t._v("sourceName")]),t._v(" "),e("td",[t._v("String")]),t._v(" "),e("td",[t._v("主题或队列名称")])]),t._v(" "),e("tr",[e("td",[t._v("body")]),t._v(" "),e("td",[t._v("byte[]")]),t._v(" "),e("td",[t._v("消息体")])]),t._v(" "),e("tr",[e("td",[t._v("Key")]),t._v(" "),e("td",[t._v("String")]),t._v(" "),e("td",[t._v("消息体的key")])]),t._v(" "),e("tr",[e("td",[t._v("Tag")]),t._v(" "),e("td",[t._v("String")]),t._v(" "),e("td",[t._v("消息的标签")])]),t._v(" "),e("tr",[e("td",[t._v("groupId")]),t._v(" "),e("td",[t._v("Object")]),t._v(" "),e("td",[t._v("发往指定分区的关键词，可以为空，如果设置将发往其hash值的分区")])])])])])}),[],!1,null,null,null);e.default=r.exports}}]);